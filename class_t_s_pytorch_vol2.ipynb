{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification showing and telling with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with tensors\n",
    "import torch   \n",
    "\n",
    "#handling text data\n",
    "from torchtext import data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2019\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['walked', 'forest', 'already', 'fall', 'getting', 'cold']}\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
    "\n",
    "fields = [(None, None), ('text',TEXT),('label', LABEL)]\n",
    "\n",
    "\n",
    "#loading custom dataset\n",
    "training_data=data.TabularDataset(path = 'datasets/train_datasets.csv',format = 'csv',fields = fields,skip_header = True)\n",
    "\n",
    "#print preprocessed text\n",
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b4e44148fd0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#initialize glove embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.100d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#No. of unique tokens in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[1;32m    308\u001b[0m             if tok is not None))\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    181\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gz'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "#initialize glove embeddings\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 205\n",
      "테스트 샘플의 개수 : 51\n"
     ]
    }
   ],
   "source": [
    "from torchtext import data # torchtext.data 임포트\n",
    "\n",
    "# 필드 정의\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=20)\n",
    "\n",
    "\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='datasets/', train='train_datasets.csv', test='test_datasets.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('text', TEXT)], skip_header=True)\n",
    "\n",
    "\n",
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))\n",
    "\n",
    "#ref: https://wikidocs.net/60314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a8cc0f3a9a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.50d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[1;32m    308\u001b[0m             if tok is not None))\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    181\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gz'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "#initialize glove embeddings\n",
    "\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.50d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = train_data.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9e2d4059e33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#initialize glove embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.100d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#No. of unique tokens in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[1;32m    308\u001b[0m             if tok is not None))\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    181\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gz'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "#initialize glove embeddings\n",
    "TEXT.build_vocab(train_data,min_freq=3, vectors = \"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = 1\n",
    "num_layers = 2\n",
    "bidirection = True\n",
    "dropout = 0.2\n",
    "\n",
    "#instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
    "                   bidirectional = True, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n",
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n",
    "#push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    #initialize every epoch \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #set the model in training phase\n",
    "    model.train()  \n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        #retrieve text and no. of words\n",
    "        text, text_lengths = batch.text   \n",
    "        \n",
    "        #convert to 1D tensor\n",
    "        predictions = model(text, text_lengths).squeeze()  \n",
    "        \n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, batch.label)        \n",
    "        \n",
    "        #compute the binary accuracy\n",
    "        acc = binary_accuracy(predictions, batch.label)   \n",
    "        \n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "        \n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "        \n",
    "        #loss and accuracy\n",
    "        epoch_loss += loss.item()  \n",
    "        epoch_acc += acc.item()    \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            #retrieve text and no. of words\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            #convert to 1d tensor\n",
    "            predictions = model(text, text_lengths).squeeze()\n",
    "            \n",
    "            #compute loss and accuracy\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            #keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weights\n",
    "path='/content/saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path));\n",
    "model.eval();\n",
    "\n",
    "#inference \n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    prediction = model(tensor, length_tensor)                  #prediction \n",
    "    return prediction.item()                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predict(model, \"Are there any sports that you don't like?\")\n",
    "\n",
    "#insincere question\n",
    "predict(model, \"Why Indian girls go crazy about marrying Shri. Rahul Gandhi ji?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The house was creepy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I heard footsteps creeping behind me and it ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>She was my best friend. I could tell her almos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>She hated it there because it smelled bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>When they embraced she could tell he had been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2</td>\n",
       "      <td>Her hand reached for the massive, iron door ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "      <td>The way the door decisively slammed behind her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2</td>\n",
       "      <td>Dust coated every last surface. He ran his fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>The lime green patio umbrella flapped happily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2</td>\n",
       "      <td>\"And after all the weather was ideal. They cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                               text\n",
       "index                                                         \n",
       "0         1                              The house was creepy.\n",
       "1         1  I heard footsteps creeping behind me and it ma...\n",
       "2         1  She was my best friend. I could tell her almos...\n",
       "3         1         She hated it there because it smelled bad.\n",
       "4         1  When they embraced she could tell he had been ...\n",
       "...     ...                                                ...\n",
       "253       2  Her hand reached for the massive, iron door ha...\n",
       "254       2  The way the door decisively slammed behind her...\n",
       "255       2  Dust coated every last surface. He ran his fin...\n",
       "256       2  The lime green patio umbrella flapped happily ...\n",
       "257       2  \"And after all the weather was ideal. They cou...\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/showingTelling_csv.csv', delimiter = ',')\n",
    "\n",
    "data.index.name = \"index\"\n",
    "data.columns = [\"type\", \"text\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "def shuffle(df, n=1, axis=0): #데이터가 1111 0000이라 잘 섞어주자. \n",
    "    df = data.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "    return df\n",
    "\n",
    "shuffle(data)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>Tiffany felt afraid. He pounded on the door, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2</td>\n",
       "      <td>For ten or fifteen minutes Elroy held a course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>I woke up and wanted to be active today. Then,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>championships, sings lead vocals in a rock ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>₩gOh my God, I am five minutes late!₩h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                               text\n",
       "index                                                         \n",
       "83        1  Tiffany felt afraid. He pounded on the door, d...\n",
       "222       2  For ten or fifteen minutes Elroy held a course...\n",
       "39        1  I woke up and wanted to be active today. Then,...\n",
       "125       2  championships, sings lead vocals in a rock ban...\n",
       "205       2             ₩gOh my God, I am five minutes late!₩h"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # 잘 섞였군만! 하지만 데이터 전처리가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>I had a great conversation with Tim over dinne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2</td>\n",
       "      <td>AND THEN, one day all foreign Jews were expell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2</td>\n",
       "      <td>Mushrooms and pepperoni sausage were layered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Dominique gives candy to her customers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>She was so angry that she threw a rock into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                               text\n",
       "index                                                         \n",
       "9         1  I had a great conversation with Tim over dinne...\n",
       "229       2  AND THEN, one day all foreign Jews were expell...\n",
       "191       2  Mushrooms and pepperoni sausage were layered t...\n",
       "27        1            Dominique gives candy to her customers.\n",
       "11        1  She was so angry that she threw a rock into th..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, remove_stopwords=False):\n",
    "        \n",
    "    # 영어가 아닌 특수문자들을 공백(\" \")으로 바꾸기\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "\n",
    "    # 대문자들을 소문자로 바꾸고 공백단위로 텍스트들 나눠서 리스트로 만든다.\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    if remove_stopwords: \n",
    "        # 불용어들을 제거\n",
    "    \n",
    "        #영어에 관련된 불용어 불러오기\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        # 불용어가 아닌 단어들로 이루어진 새로운 리스트 생성\n",
    "        words = [w for w in words if not w in stops]\n",
    "        # 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\n",
    "        clean_review = ' '.join(words)\n",
    "\n",
    "    else: # 불용어 제거하지 않을 때\n",
    "        clean_review = ' '.join(words)\n",
    "\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiffany felt afraid pounded door demanding let'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_ = []\n",
    "for review in train['text']:\n",
    "    clean_train_.append(preprocessing(review, remove_stopwords=True))\n",
    "\n",
    "# 전처리된 데이터 확인. 잘됨 !! ㅎ\n",
    "clean_train_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiffany felt afraid pounded door demanding let',\n",
       " 'ten fifteen minutes elroy held course upstream river choppy silver gray turned straight north put engine full throttle felt bow lift beneath remember wind ears',\n",
       " 'woke wanted active today heard amy cooking downstairs kitchen making lots noise kitchenware',\n",
       " 'championships sings lead vocals rock band speaks five languages',\n",
       " 'goh god five minutes late h']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great conversation tim dinner loved hearing stories'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_ = []\n",
    "for review in test['text']:\n",
    "    clean_test_.append(preprocessing(review, remove_stopwords=True))\n",
    "    \n",
    "# 전처리된 데이터 확인. 잘됨 !! ㅎ\n",
    "clean_test_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great conversation tim dinner loved hearing stories',\n",
       " 'one day foreign jews expelled sighet moishe beadle foreigner crammed cattle cars hungarian police cried silently standing station platform crying',\n",
       " 'mushrooms pepperoni sausage layered thickly top one another white mozzarella cheese bubbled bright red tomato sauce',\n",
       " 'dominique gives candy customers',\n",
       " 'angry threw rock house broke glass']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "83     1\n",
      "222    2\n",
      "39     1\n",
      "125    2\n",
      "205    2\n",
      "      ..\n",
      "107    1\n",
      "68     1\n",
      "2      1\n",
      "76     1\n",
      "199    2\n",
      "Name: type, Length: 206, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"type\"]) #showing telling 컬럽값을 확인해보고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>Tiffany felt afraid. He pounded on the door, d...</td>\n",
       "      <td>tiffany felt afraid pounded door demanding let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2</td>\n",
       "      <td>For ten or fifteen minutes Elroy held a course...</td>\n",
       "      <td>ten fifteen minutes elroy held course upstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>I woke up and wanted to be active today. Then,...</td>\n",
       "      <td>woke wanted active today heard amy cooking dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>championships, sings lead vocals in a rock ban...</td>\n",
       "      <td>championships sings lead vocals rock band spea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>₩gOh my God, I am five minutes late!₩h</td>\n",
       "      <td>goh god five minutes late h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                               text  \\\n",
       "index                                                            \n",
       "83        1  Tiffany felt afraid. He pounded on the door, d...   \n",
       "222       2  For ten or fifteen minutes Elroy held a course...   \n",
       "39        1  I woke up and wanted to be active today. Then,...   \n",
       "125       2  championships, sings lead vocals in a rock ban...   \n",
       "205       2             ₩gOh my God, I am five minutes late!₩h   \n",
       "\n",
       "                                            cleaned_text  \n",
       "index                                                     \n",
       "83        tiffany felt afraid pounded door demanding let  \n",
       "222    ten fifteen minutes elroy held course upstream...  \n",
       "39     woke wanted active today heard amy cooking dow...  \n",
       "125    championships sings lead vocals rock band spea...  \n",
       "205                          goh god five minutes late h  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleaned_text'] = clean_train_ # 이제 전처리된 내용을 한눈에 비교해 볼 수 있다.\n",
    "train[:5] #데이터 앞부분 5개반 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>I had a great conversation with Tim over dinne...</td>\n",
       "      <td>great conversation tim dinner loved hearing st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2</td>\n",
       "      <td>AND THEN, one day all foreign Jews were expell...</td>\n",
       "      <td>one day foreign jews expelled sighet moishe be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2</td>\n",
       "      <td>Mushrooms and pepperoni sausage were layered t...</td>\n",
       "      <td>mushrooms pepperoni sausage layered thickly to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Dominique gives candy to her customers.</td>\n",
       "      <td>dominique gives candy customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>She was so angry that she threw a rock into th...</td>\n",
       "      <td>angry threw rock house broke glass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                               text  \\\n",
       "index                                                            \n",
       "9         1  I had a great conversation with Tim over dinne...   \n",
       "229       2  AND THEN, one day all foreign Jews were expell...   \n",
       "191       2  Mushrooms and pepperoni sausage were layered t...   \n",
       "27        1            Dominique gives candy to her customers.   \n",
       "11        1  She was so angry that she threw a rock into th...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "index                                                     \n",
       "9      great conversation tim dinner loved hearing st...  \n",
       "229    one day foreign jews expelled sighet moishe be...  \n",
       "191    mushrooms pepperoni sausage layered thickly to...  \n",
       "27                       dominique gives candy customers  \n",
       "11                    angry threw rock house broke glass  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['cleaned_text'] = clean_test_\n",
    "test[:5] #test 데이터셋도 전처리된 결과를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>tiffany felt afraid pounded door demanding let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2</td>\n",
       "      <td>ten fifteen minutes elroy held course upstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>woke wanted active today heard amy cooking dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>championships sings lead vocals rock band spea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>goh god five minutes late h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                       cleaned_text\n",
       "index                                                         \n",
       "83        1     tiffany felt afraid pounded door demanding let\n",
       "222       2  ten fifteen minutes elroy held course upstream...\n",
       "39        1  woke wanted active today heard amy cooking dow...\n",
       "125       2  championships sings lead vocals rock band spea...\n",
       "205       2                        goh god five minutes late h"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train[['type', 'cleaned_text']] #전처리 1차 끝!\n",
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>great conversation tim dinner loved hearing st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2</td>\n",
       "      <td>one day foreign jews expelled sighet moishe be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2</td>\n",
       "      <td>mushrooms pepperoni sausage layered thickly to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>dominique gives candy customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>angry threw rock house broke glass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                       cleaned_text\n",
       "index                                                         \n",
       "9         1  great conversation tim dinner loved hearing st...\n",
       "229       2  one day foreign jews expelled sighet moishe be...\n",
       "191       2  mushrooms pepperoni sausage layered thickly to...\n",
       "27        1                    dominique gives candy customers\n",
       "11        1                 angry threw rock house broke glass"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test[['type', 'cleaned_text']]  #전처리 1차 끝!\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_test = test_dataset.astype(str)\n",
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train = train_dataset.astype(str)\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset.values #train_dataset의 df를 numpy array로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_dataset.values #역시 이것도 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('datasets/train_datasets.csv', index=False, header=False, sep=',')\n",
    "test_dataset.to_csv('datasets/test_datasets.csv', index=False, header=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 205\n",
      "테스트 샘플의 개수 : 51\n"
     ]
    }
   ],
   "source": [
    "from torchtext import data # torchtext.data 임포트\n",
    "\n",
    "# 필드 정의\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=20)\n",
    "\n",
    "\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='datasets/', train='train_datasets.csv', test='test_datasets.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('text', TEXT)], skip_header=True)\n",
    "\n",
    "\n",
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))\n",
    "\n",
    "#ref: https://wikidocs.net/60314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '2', 'text': ['championships', 'sings', 'lead', 'vocals', 'rock', 'band', 'speaks', 'five', 'languages']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[2])) # text, label이 구분됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 1542\n",
      "Size of LABEL vocabulary: 3\n",
      "[('h', 21), ('ft', 21), ('fs', 18), ('could', 15), ('like', 14), ('behind', 12), ('one', 12), ('cold', 11), ('face', 10), ('looked', 10)]\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1a4b03a110>>, {'<unk>': 0, '<pad>': 1, 'ft': 2, 'h': 3, 'fs': 4, 'could': 5, 'like': 6, 'behind': 7, 'one': 8, 'cold': 9, 'door': 10, 'face': 11, 'long': 12, 'looked': 13, 'see': 14, 'felt': 15, 'garden': 16, 'never': 17, 'said': 18, 'black': 19, 'c': 20, 'first': 21, 'hands': 22, 'night': 23, 'sun': 24, 'time': 25, 'day': 26, 'eyes': 27, 'front': 28, 'got': 29, 'hand': 30, 'late': 31, 'little': 32, 'stairs': 33, 'walked': 34, 'would': 35, 'back': 36, 'blood': 37, 'breath': 38, 'came': 39, 'every': 40, 'f': 41, 'far': 42, 'father': 43, 'house': 44, 'knew': 45, 'light': 46, 'made': 47, 'man': 48, 'nervous': 49, 'old': 50, 'reached': 51, 'red': 52, 'saw': 53, 'sweat': 54, 'tree': 55, 'two': 56, 'us': 57, 'village': 58, 'wind': 59, 'window': 60, 'already': 61, 'another': 62, 'away': 63, 'beautiful': 64, 'clouds': 65, 'dark': 66, 'darkness': 67, 'engine': 68, 'feet': 69, 'give': 70, 'glass': 71, 'go': 72, 'hair': 73, 'head': 74, 'held': 75, 'hot': 76, 'james': 77, 'last': 78, 'left': 79, 'lights': 80, 'lost': 81, 'mother': 82, 'page': 83, 'rain': 84, 'room': 85, 'seemed': 86, 'smell': 87, 'someone': 88, 'still': 89, 'stood': 90, 'streets': 91, 'took': 92, 'town': 93, 'wall': 94, 'walls': 95, 'weather': 96, 'went': 97, 'white': 98, 'alvin': 99, 'angry': 100, 'arms': 101, 'around': 102, 'boat': 103, 'bright': 104, 'cheek': 105, 'city': 106, 'dirty': 107, 'dress': 108, 'even': 109, 'fallen': 110, 'find': 111, 'five': 112, 'floor': 113, 'get': 114, 'gi': 115, 'good': 116, 'jim': 117, 'joey': 118, 'leaves': 119, 'life': 120, 'making': 121, 'minutes': 122, 'mr': 123, 'newspaper': 124, 'open': 125, 'pool': 126, 'river': 127, 'second': 128, 'show': 129, 'side': 130, 'slammed': 131, 'slowly': 132, 'small': 133, 'smoke': 134, 'steps': 135, 'thought': 136, 'thoughts': 137, 'toward': 138, 'turned': 139, 'way': 140, 'across': 141, 'afraid': 142, 'always': 143, 'among': 144, 'anyone': 145, 'anything': 146, 'asked': 147, 'bad': 148, 'bar': 149, 'bite': 150, 'blair': 151, 'blue': 152, 'books': 153, 'bottom': 154, 'box': 155, 'brother': 156, 'busy': 157, 'carl': 158, 'castle': 159, 'catch': 160, 'cheerful': 161, 'clara': 162, 'clear': 163, 'close': 164, 'closer': 165, 'crunched': 166, 'damp': 167, 'deep': 168, 'drew': 169, 'dry': 170, 'ears': 171, 'elroy': 172, 'enough': 173, 'favorite': 174, 'fear': 175, 'fingers': 176, 'found': 177, 'full': 178, 'girl': 179, 'grass': 180, 'green': 181, 'gripped': 182, 'ground': 183, 'gyou': 184, 'hated': 185, 'hear': 186, 'heard': 187, 'heart': 188, 'high': 189, 'hit': 190, 'home': 191, 'hoofbeats': 192, 'horse': 193, 'hours': 194, 'ice': 195, 'jay': 196, 'katie': 197, 'keep': 198, 'kept': 199, 'know': 200, 'lonely': 201, 'look': 202, 'looking': 203, 'looks': 204, 'love': 205, 'luke': 206, 'many': 207, 'meet': 208, 'mike': 209, 'mountains': 210, 'mouth': 211, 'must': 212, 'orias': 213, 'outside': 214, 'pale': 215, 'party': 216, 'people': 217, 'pictures': 218, 'pizza': 219, 'place': 220, 'pulled': 221, 'ran': 222, 'reading': 223, 'remember': 224, 'right': 225, 'running': 226, 'sally': 227, 'says': 228, 'school': 229, 'seen': 230, 'set': 231, 'shadow': 232, 'shaking': 233, 'sheet': 234, 'sky': 235, 'smile': 236, 'sometimes': 237, 'spilled': 238, 'storm': 239, 'summer': 240, 'sword': 241, 'table': 242, 'tell': 243, 'thick': 244, 'things': 245, 'though': 246, 'three': 247, 'tired': 248, 'today': 249, 'trembling': 250, 'veins': 251, 'want': 252, 'war': 253, 'warm': 254, 'well': 255, 'whole': 256, 'wooden': 257, 'work': 258, 'worked': 259, 'worry': 260, 'year': 261, 'yellow': 262, 'afternoon': 263, 'air': 264, 'alone': 265, 'amy': 266, 'anna': 267, 'anxiously': 268, 'archie': 269, 'arrive': 270, 'author': 271, 'barely': 272, 'beach': 273, 'became': 274, 'belt': 275, 'beneath': 276, 'bit': 277, 'book': 278, 'born': 279, 'bowen': 280, 'branch': 281, 'breakfast': 282, 'brick': 283, 'burning': 284, 'bus': 285, 'canadian': 286, 'canopy': 287, 'carefully': 288, 'carried': 289, 'cat': 290, 'center': 291, 'chan': 292, 'chapter': 293, 'cheese': 294, 'chilled': 295, 'church': 296, 'circus': 297, 'class': 298, 'climbed': 299, 'climbing': 300, 'clock': 301, 'commander': 302, 'complete': 303, 'cut': 304, 'cynthia': 305, 'dazzling': 306, 'decorated': 307, 'delicious': 308, 'described': 309, 'dog': 310, 'downstairs': 311, 'dresser': 312, 'earth': 313, 'eating': 314, 'elected': 315, 'emily': 316, 'fall': 317, 'family': 318, 'fast': 319, 'fd': 320, 'fence': 321, 'fern': 322, 'fifteen': 323, 'filled': 324, 'fire': 325, 'fish': 326, 'flowers': 327, 'fm': 328, 'footsteps': 329, 'forehead': 330, 'forest': 331, 'frost': 332, 'gabilan': 333, 'gate': 334, 'gibson': 335, 'going': 336, 'grandfather': 337, 'handle': 338, 'hard': 339, 'healthy': 340, 'heave': 341, 'heavy': 342, 'hoghouse': 343, 'hug': 344, 'hung': 345, 'imagine': 346, 'impossible': 347, 'ink': 348, 'insurance': 349, 'iron': 350, 'isolated': 351, 'jack': 352, 'jacket': 353, 'kicked': 354, 'kill': 355, 'knowing': 356, 'knuckles': 357, 'languages': 358, 'leather': 359, 'leaving': 360, 'let': 361, 'letting': 362, 'lightning': 363, 'liked': 364, 'london': 365, 'loved': 366, 'lucy': 367, 'madam': 368, 'malcolm': 369, 'mary': 370, 'massive': 371, 'mayor': 372, 'met': 373, 'metal': 374, 'metres': 375, 'might': 376, 'milk': 377, 'mind': 378, 'miss': 379, 'molly': 380, 'morning': 381, 'moved': 382, 'music': 383, 'name': 384, 'needs': 385, 'next': 386, 'noise': 387, 'north': 388, 'nose': 389, 'nothing': 390, 'nurse': 391, 'ocean': 392, 'october': 393, 'oliver': 394, 'onto': 395, 'opened': 396, 'orchestra': 397, 'palms': 398, 'paper': 399, 'patio': 400, 'peace': 401, 'peaceful': 402, 'pepperoni': 403, 'perfect': 404, 'person': 405, 'pigs': 406, 'pine': 407, 'ping': 408, 'pomfrey': 409, 'pong': 410, 'popped': 411, 'pounding': 412, 'public': 413, 'puppy': 414, 'purple': 415, 'put': 416, 'quickly': 417, 'raced': 418, 'rattling': 419, 'really': 420, 'rifles': 421, 'ring': 422, 'rock': 423, 'roger': 424, 'rolling': 425, 'run': 426, 'say': 427, 'sea': 428, 'sent': 429, 'several': 430, 'sewers': 431, 'sheets': 432, 'shirt': 433, 'signals': 434, 'silver': 435, 'since': 436, 'sister': 437, 'skin': 438, 'smelled': 439, 'smoking': 440, 'soldiers': 441, 'somehow': 442, 'sound': 443, 'speak': 444, 'speech': 445, 'sports': 446, 'spray': 447, 'spread': 448, 'squirrel': 449, 'staircase': 450, 'stale': 451, 'standing': 452, 'steam': 453, 'steep': 454, 'step': 455, 'stepped': 456, 'stomach': 457, 'stone': 458, 'straight': 459, 'stroke': 460, 'strong': 461, 'sure': 462, 'susie': 463, 'taking': 464, 'taste': 465, 'teeth': 466, 'temperature': 467, 'threw': 468, 'times': 469, 'tiny': 470, 'top': 471, 'touched': 472, 'train': 473, 'trunk': 474, 'trying': 475, 'twenty': 476, 'twisted': 477, 'used': 478, 'usual': 479, 'voices': 480, 'warmed': 481, 'watching': 482, 'water': 483, 'waters': 484, 'waves': 485, 'weak': 486, 'wearing': 487, 'weight': 488, 'whipped': 489, 'wife': 490, 'without': 491, 'woman': 492, 'wood': 493, 'wrapped': 494, 'young': 495, 'aaron': 496, 'abandoned': 497, 'accelerating': 498, 'ached': 499, 'active': 500, 'address': 501, 'adze': 502, 'afterward': 503, 'ago': 504, 'aim': 505, 'aimed': 506, 'allowed': 507, 'almost': 508, 'also': 509, 'amount': 510, 'animal': 511, 'anymore': 512, 'anytime': 513, 'appear': 514, 'applying': 515, 'appointment': 516, 'arable': 517, 'arm': 518, 'arrived': 519, 'ashes': 520, 'attention': 521, 'attractive': 522, 'autumn': 523, 'avoided': 524, 'aware': 525, 'ax': 526, 'bachelor': 527, 'backpack': 528, 'backward': 529, 'bag': 530, 'baking': 531, 'band': 532, 'bang': 533, 'banging': 534, 'barcel': 535, 'bathroom': 536, 'beads': 537, 'bearings': 538, 'beatty': 539, 'become': 540, 'becomes': 541, 'bedecked': 542, 'beg': 543, 'began': 544, 'bending': 545, 'beside': 546, 'best': 547, 'bill': 548, 'biting': 549, 'bitter': 550, 'blackened': 551, 'blackout': 552, 'blades': 553, 'blank': 554, 'bleached': 555, 'blessing': 556, 'blind': 557, 'blinding': 558, 'blinked': 559, 'blond': 560, 'bloodied': 561, 'blotting': 562, 'blushing': 563, 'boarded': 564, 'bobber': 565, 'bodies': 566, 'body': 567, 'bolts': 568, 'boots': 569, 'boring': 570, 'bouncing': 571, 'bow': 572, 'bowed': 573, 'boxes': 574, 'branches': 575, 'break': 576, 'breathe': 577, 'breeze': 578, 'brenda': 579, 'bricks': 580, 'brighter': 581, 'brightly': 582, 'bring': 583, 'bringing': 584, 'broadsword': 585, 'brought': 586, 'brushed': 587, 'brushwood': 588, 'bubbled': 589, 'buckets': 590, 'bud': 591, 'buds': 592, 'building': 593, 'bulbs': 594, 'bulging': 595, 'bullied': 596, 'bunches': 597, 'burned': 598, 'burrowed': 599, 'busied': 600, 'butterfly': 601, 'cab': 602, 'calcium': 603, 'calle': 604, 'calm': 605, 'canal': 606, 'candles': 607, 'canuda': 608, 'caps': 609, 'car': 610, 'carpenter': 611, 'carriage': 612, 'carry': 613, 'carrying': 614, 'cars': 615, 'casserole': 616, 'cast': 617, 'caught': 618, 'celebrated': 619, 'chain': 620, 'chair': 621, 'champagne': 622, 'championships': 623, 'changed': 624, 'chapel': 625, 'chased': 626, 'cheeks': 627, 'chest': 628, 'child': 629, 'children': 630, 'chill': 631, 'chocolate': 632, 'choked': 633, 'choking': 634, 'choppy': 635, 'christmas': 636, 'cigarette': 637, 'cjoey': 638, 'clammy': 639, 'clap': 640, 'classroom': 641, 'clatter': 642, 'clattering': 643, 'clean': 644, 'clearly': 645, 'click': 646, 'cliff': 647, 'cloud': 648, 'clung': 649, 'clutched': 650, 'cneither': 651, 'coat': 652, 'cobblestone': 653, 'cobblestones': 654, 'cocktail': 655, 'cocktails': 656, 'coffee': 657, 'colds': 658, 'collar': 659, 'collect': 660, 'collection': 661, 'college': 662, 'colorful': 663, 'colour': 664, 'come': 665, 'comes': 666, 'competes': 667, 'complaining': 668, 'confused': 669, 'congealed': 670, 'connect': 671, 'consumed': 672, 'containers': 673, 'content': 674, 'continued': 675, 'conveyance': 676, 'cookies': 677, 'cooking': 678, 'correct': 679, 'cottages': 680, 'county': 681, 'course': 682, 'courtyard': 683, 'coveralls': 684, 'covered': 685, 'covering': 686, 'covers': 687, 'crack': 688, 'crashed': 689, 'crawled': 690, 'creaky': 691, 'creditors': 692, 'creek': 693, 'creeping': 694, 'creepy': 695, 'crepe': 696, 'crept': 697, 'crisscrossed': 698, 'crop': 699, 'crossed': 700, 'crossword': 701, 'crow': 702, 'crowd': 703, 'crowded': 704, 'crumpling': 705, 'crunching': 706, 'crystal': 707, 'crystals': 708, 'cubes': 709, 'culinary': 710, 'cupboard': 711, 'cupboards': 712, 'curly': 713, 'cursing': 714, 'curtain': 715, 'customers': 716, 'dairy': 717, 'daisy': 718, 'dangled': 719, 'dashed': 720, 'dave': 721, 'dawn': 722, 'dead': 723, 'dearly': 724, 'deathly': 725, 'debated': 726, 'decent': 727, 'decide': 728, 'decided': 729, 'decisively': 730, 'delicately': 731, 'descended': 732, 'desert': 733, 'desperately': 734, 'destroyed': 735, 'diagilo': 736, 'different': 737, 'diligent': 738, 'diligently': 739, 'ding': 740, 'disappeared': 741, 'discerned': 742, 'discover': 743, 'distance': 744, 'distorted': 745, 'dividing': 746, 'doctor': 747, 'dodging': 748, 'donuts': 749, 'downwards': 750, 'drawer': 751, 'drawn': 752, 'drenched': 753, 'dressing': 754, 'drink': 755, 'drinker': 756, 'drinks': 757, 'drive': 758, 'driver': 759, 'droppings': 760, 'drove': 761, 'dug': 762, 'dull': 763, 'dumb': 764, 'dye': 765, 'early': 766, 'easily': 767, 'eevery': 768, 'effort': 769, 'eh': 770, 'ei': 771, 'eight': 772, 'ekaterina': 773, 'elephant': 774, 'eligible': 775, 'embrace': 776, 'emitted': 777, 'empty': 778, 'encouragement': 779, 'end': 780, 'energy': 781, 'eno': 782, 'entirely': 783, 'enveloped': 784, 'especially': 785, 'evening': 786, 'evinrude': 787, 'ewhat': 788, 'exhaustion': 789, 'expect': 790, 'expensive': 791, 'explosion': 792, 'eyed': 793, 'eyelashes': 794, 'fabric': 795, 'faces': 796, 'faded': 797, 'faint': 798, 'false': 799, 'fam': 800, 'familiar': 801, 'fan': 802, 'fancy': 803, 'feather': 804, 'feature': 805, 'feel': 806, 'feeling': 807, 'fell': 808, 'fetid': 809, 'fight': 810, 'figuring': 811, 'fingernail': 812, 'fiona': 813, 'fireplace': 814, 'fishing': 815, 'fishtail': 816, 'flaking': 817, 'flame': 818, 'flames': 819, 'flapped': 820, 'flares': 821, 'flat': 822, 'flattened': 823, 'flesh': 824, 'flew': 825, 'flickered': 826, 'fll': 827, 'floating': 828, 'flooding': 829, 'floorboard': 830, 'florentine': 831, 'flower': 832, 'flowing': 833, 'flying': 834, 'fog': 835, 'fogged': 836, 'foggy': 837, 'folded': 838, 'food': 839, 'football': 840, 'foothold': 841, 'forbidden': 842, 'forced': 843, 'foreign': 844, 'form': 845, 'formed': 846, 'forward': 847, 'fought': 848, 'frames': 849, 'freeze': 850, 'friend': 851, 'frightened': 852, 'frigid': 853, 'frozen': 854, 'fullness': 855, 'fully': 856, 'fur': 857, 'furs': 858, 'fve': 859, 'ga': 860, 'game': 861, 'gardener': 862, 'gardens': 863, 'gave': 864, 'gdarlene': 865, 'gdo': 866, 'gents': 867, 'georgie': 868, 'getting': 869, 'gget': 870, 'ggood': 871, 'gholy': 872, 'ghostly': 873, 'ginny': 874, 'girls': 875, 'given': 876, 'giving': 877, 'glet': 878, 'glided': 879, 'glistened': 880, 'glowing': 881, 'glumly': 882, 'glutinous': 883, 'gnice': 884, 'gnot': 885, 'god': 886, 'goh': 887, 'gold': 888, 'gotten': 889, 'gpiccadilly': 890, 'gpoint': 891, 'grabbed': 892, 'grabbing': 893, 'graceful': 894, 'grand': 895, 'grasping': 896, 'gravity': 897, 'gray': 898, 'grazing': 899, 'great': 900, 'grew': 901, 'grimace': 902, 'gritted': 903, 'gritty': 904, 'groaned': 905, 'grounds': 906, 'grow': 907, 'gsit': 908, 'gslice': 909, 'gstop': 910, 'guards': 911, 'guessing': 912, 'gun': 913, 'gushed': 914, 'gutters': 915, 'hail': 916, 'half': 917, 'halfway': 918, 'halls': 919, 'hallway': 920, 'halted': 921, 'hammer': 922, 'hammering': 923, 'hanging': 924, 'hansom': 925, 'happily': 926, 'harsh': 927, 'haze': 928, 'heaps': 929, 'heaven': 930, 'help': 931, 'hem': 932, 'hidden': 933, 'higher': 934, 'hill': 935, 'hills': 936, 'hilltops': 937, 'hinges': 938, 'hockey': 939, 'holt': 940, 'homework': 941, 'hooked': 942, 'horizon': 943, 'horsepower': 944, 'horses': 945, 'houses': 946, 'huddled': 947, 'human': 948, 'humming': 949, 'hungry': 950, 'hunk': 951, 'hurled': 952, 'hurry': 953, 'husband': 954, 'ideal': 955, 'ignited': 956, 'ill': 957, 'impenetrable': 958, 'impression': 959, 'incorrect': 960, 'increased': 961, 'increasing': 962, 'ing': 963, 'ingredient': 964, 'inhale': 965, 'inside': 966, 'instantly': 967, 'instead': 968, 'intensity': 969, 'interrupted': 970, 'invisible': 971, 'iona': 972, 'ireland': 973, 'itched': 974, 'jerked': 975, 'jews': 976, 'job': 977, 'joy': 978, 'juli': 979, 'jump': 980, 'jumped': 981, 'junkyard': 982, 'key': 983, 'kind': 984, 'kindergarten': 985, 'kinds': 986, 'kiosk': 987, 'kitchen': 988, 'kitchenware': 989, 'knee': 990, 'knight': 991, 'knowledge': 992, 'known': 993, 'lady': 994, 'latin': 995, 'lawns': 996, 'lay': 997, 'layers': 998, 'lead': 999, 'leaden': 1000, 'leader': 1001, 'leaned': 1002, 'leapt': 1003, 'leave': 1004, 'led': 1005, 'leg': 1006, 'lemonade': 1007, 'library': 1008, 'lifetime': 1009, 'lift': 1010, 'lifting': 1011, 'lifts': 1012, 'lighting': 1013, 'lightly': 1014, 'lime': 1015, 'lip': 1016, 'lips': 1017, 'lives': 1018, 'living': 1019, 'locking': 1020, 'lookin': 1021, 'lots': 1022, 'loud': 1023, 'louder': 1024, 'lovely': 1025, 'low': 1026, 'lower': 1027, 'lurches': 1028, 'luscious': 1029, 'lying': 1030, 'mactalde': 1031, 'madness': 1032, 'magical': 1033, 'make': 1034, 'managed': 1035, 'manner': 1036, 'matters': 1037, 'may': 1038, 'meal': 1039, 'mean': 1040, 'meat': 1041, 'medicine': 1042, 'medieval': 1043, 'melancholy': 1044, 'melted': 1045, 'melting': 1046, 'men': 1047, 'merchants': 1048, 'mesmerized': 1049, 'mess': 1050, 'michael': 1051, 'middle': 1052, 'mine': 1053, 'minute': 1054, 'misbehaving': 1055, 'missed': 1056, 'missing': 1057, 'mist': 1058, 'mold': 1059, 'mom': 1060, 'moment': 1061, 'monotonously': 1062, 'montag': 1063, 'moon': 1064, 'moonlit': 1065, 'moths': 1066, 'mottled': 1067, 'movement': 1068, 'movements': 1069, 'moving': 1070, 'mowing': 1071, 'mozzarella': 1072, 'mrs': 1073, 'much': 1074, 'muscles': 1075, 'mushrooms': 1076, 'n': 1077, 'nale': 1078, 'named': 1079, 'narrowing': 1080, 'navigated': 1081, 'nearer': 1082, 'network': 1083, 'new': 1084, 'nice': 1085, 'nineties': 1086, 'ninja': 1087, 'nostrils': 1088, 'note': 1089, 'notion': 1090, 'notions': 1091, 'occured': 1092, 'offer': 1093, 'older': 1094, 'ones': 1095, 'oooh': 1096, 'opaque': 1097, 'opera': 1098, 'ophelia': 1099, 'opponent': 1100, 'opulent': 1101, 'orange': 1102, 'ordered': 1103, 'ordinary': 1104, 'others': 1105, 'outboard': 1106, 'outline': 1107, 'outward': 1108, 'outwards': 1109, 'overnight': 1110, 'overran': 1111, 'oyster': 1112, 'packed': 1113, 'pain': 1114, 'painful': 1115, 'paint': 1116, 'palatial': 1117, 'palm': 1118, 'pancake': 1119, 'pancakes': 1120, 'pans': 1121, 'pardon': 1122, 'parked': 1123, 'part': 1124, 'parties': 1125, 'pass': 1126, 'passageways': 1127, 'passed': 1128, 'passionate': 1129, 'past': 1130, 'patch': 1131, 'patches': 1132, 'path': 1133, 'pavements': 1134, 'pay': 1135, 'pedestrian': 1136, 'pedestrians': 1137, 'peeled': 1138, 'pepperup': 1139, 'percy': 1140, 'permeate': 1141, 'perspire': 1142, 'petals': 1143, 'philosophies': 1144, 'piccadilly': 1145, 'picking': 1146, 'picks': 1147, 'piece': 1148, 'pies': 1149, 'pig': 1150, 'piled': 1151, 'piles': 1152, 'pillow': 1153, 'pines': 1154, 'pink': 1155, 'piss': 1156, 'piston': 1157, 'pitcher': 1158, 'pitches': 1159, 'planned': 1160, 'plants': 1161, 'players': 1162, 'playing': 1163, 'pleasant': 1164, 'plumber': 1165, 'plump': 1166, 'plunger': 1167, 'plush': 1168, 'point': 1169, 'pointed': 1170, 'poppies': 1171, 'potion': 1172, 'pots': 1173, 'poured': 1174, 'pouring': 1175, 'powder': 1176, 'preferred': 1177, 'pressed': 1178, 'pretty': 1179, 'products': 1180, 'progress': 1181, 'promises': 1182, 'protagonist': 1183, 'protection': 1184, 'protein': 1185, 'provolone': 1186, 'puck': 1187, 'pull': 1188, 'pulling': 1189, 'pulsing': 1190, 'purplish': 1191, 'pushed': 1192, 'puzzle': 1193, 'race': 1194, 'rampant': 1195, 'rapid': 1196, 'rather': 1197, 'rattled': 1198, 'rays': 1199, 'razor': 1200, 'reach': 1201, 'read': 1202, 'readers': 1203, 'ready': 1204, 'reason': 1205, 'reef': 1206, 'reflected': 1207, 'reflecting': 1208, 'reflexes': 1209, 'refuge': 1210, 'regret': 1211, 'release': 1212, 'relief': 1213, 'remaining': 1214, 'remove': 1215, 'replied': 1216, 'restaurant': 1217, 'return': 1218, 'revolted': 1219, 'riding': 1220, 'rising': 1221, 'rivers': 1222, 'riveted': 1223, 'roared': 1224, 'rolled': 1225, 'romantic': 1226, 'roof': 1227, 'roofs': 1228, 'rooms': 1229, 'rose': 1230, 'rosettes': 1231, 'rosy': 1232, 'rotten': 1233, 'rough': 1234, 'round': 1235, 'rounds': 1236, 'rubble': 1237, 'rumbles': 1238, 'rump': 1239, 'runt': 1240, 'rustle': 1241, 'ruzz': 1242, 'sad': 1243, 'saddle': 1244, 'safety': 1245, 'salina': 1246, 'salinas': 1247, 'sand': 1248, 'sapphire': 1249, 'sat': 1250, 'sauce': 1251, 'sausage': 1252, 'scarier': 1253, 'scent': 1254, 'scheduled': 1255, 'scrabbling': 1256, 'scramble': 1257, 'scrambled': 1258, 'screamed': 1259, 'screen': 1260, 'scribbled': 1261, 'seat': 1262, 'seconds': 1263, 'seeds': 1264, 'seeing': 1265, 'seem': 1266, 'selling': 1267, 'send': 1268, 'senior': 1269, 'sentence': 1270, 'served': 1271, 'serving': 1272, 'setting': 1273, 'shade': 1274, 'shadows': 1275, 'shake': 1276, 'shapes': 1277, 'sharp': 1278, 'sharpening': 1279, 'shattered': 1280, 'shavings': 1281, 'sheathed': 1282, 'sheer': 1283, 'shelves': 1284, 'shifted': 1285, 'shine': 1286, 'shit': 1287, 'shivering': 1288, 'shocked': 1289, 'shore': 1290, 'shout': 1291, 'shouted': 1292, 'showered': 1293, 'shrieked': 1294, 'shroud': 1295, 'shuf': 1296, 'shut': 1297, 'shuzz': 1298, 'sick': 1299, 'sides': 1300, 'sidewalks': 1301, 'sifted': 1302, 'sigh': 1303, 'sighed': 1304, 'sighet': 1305, 'sighing': 1306, 'silenced': 1307, 'silent': 1308, 'silly': 1309, 'simple': 1310, 'single': 1311, 'sings': 1312, 'sir': 1313, 'sisters': 1314, 'sits': 1315, 'situation': 1316, 'six': 1317, 'sizes': 1318, 'skies': 1319, 'slack': 1320, 'slam': 1321, 'slapping': 1322, 'slash': 1323, 'sleepy': 1324, 'sleigh': 1325, 'slept': 1326, 'slice': 1327, 'slick': 1328, 'slip': 1329, 'slopes': 1330, 'slow': 1331, 'slowed': 1332, 'slushies': 1333, 'smallest': 1334, 'smelling': 1335, 'smiled': 1336, 'smiles': 1337, 'smooth': 1338, 'snarl': 1339, 'snuck': 1340, 'snuffed': 1341, 'sold': 1342, 'solid': 1343, 'something': 1344, 'somewhere': 1345, 'soon': 1346, 'sorority': 1347, 'sorting': 1348, 'soul': 1349, 'spaces': 1350, 'spans': 1351, 'spate': 1352, 'speaks': 1353, 'speed': 1354, 'spilling': 1355, 'spit': 1356, 'splinter': 1357, 'sport': 1358, 'spreading': 1359, 'spring': 1360, 'spun': 1361, 'spurred': 1362, 'square': 1363, 'squinted': 1364, 'squinting': 1365, 'stacks': 1366, 'staff': 1367, 'stains': 1368, 'staleness': 1369, 'stands': 1370, 'stars': 1371, 'starts': 1372, 'state': 1373, 'stay': 1374, 'steadily': 1375, 'steady': 1376, 'stealth': 1377, 'steeds': 1378, 'stepping': 1379, 'stiff': 1380, 'stirred': 1381, 'stop': 1382, 'story': 1383, 'straightened': 1384, 'strawberry': 1385, 'street': 1386, 'streetlamps': 1387, 'strokes': 1388, 'struggled': 1389, 'studded': 1390, 'students': 1391, 'stumbled': 1392, 'subject': 1393, 'sucked': 1394, 'sudden': 1395, 'suddenly': 1396, 'suffer': 1397, 'sunday': 1398, 'sunny': 1399, 'sunshine': 1400, 'suppose': 1401, 'surpassed': 1402, 'surprised': 1403, 'surrender': 1404, 'suzie': 1405, 'swamped': 1406, 'sweaty': 1407, 'sweeping': 1408, 'sweet': 1409, 'swiftly': 1410, 'swimmers': 1411, 'swipes': 1412, 'swirled': 1413, 'switched': 1414, 'sycamores': 1415, 'tackle': 1416, 'take': 1417, 'talented': 1418, 'taller': 1419, 'tapped': 1420, 'temporary': 1421, 'ten': 1422, 'tensed': 1423, 'terms': 1424, 'text': 1425, 'thatched': 1426, 'thermometers': 1427, 'thin': 1428, 'thing': 1429, 'third': 1430, 'throat': 1431, 'throttle': 1432, 'thumbnail': 1433, 'thump': 1434, 'thunder': 1435, 'thundered': 1436, 'tiffany': 1437, 'tiger': 1438, 'tighten': 1439, 'tim': 1440, 'tin': 1441, 'tissue': 1442, 'tobacco': 1443, 'toilet': 1444, 'tom': 1445, 'tomato': 1446, 'tonight': 1447, 'toolbox': 1448, 'tools': 1449, 'tossed': 1450, 'tough': 1451, 'towards': 1452, 'trade': 1453, 'trees': 1454, 'trembled': 1455, 'tried': 1456, 'tripped': 1457, 'troubled': 1458, 'tuning': 1459, 'turbulent': 1460, 'turning': 1461, 'tv': 1462, 'tweed': 1463, 'twinkling': 1464, 'umbrella': 1465, 'unattached': 1466, 'uneven': 1467, 'unjust': 1468, 'unnatural': 1469, 'unsuccessful': 1470, 'unusual': 1471, 'upcoming': 1472, 'upon': 1473, 'upper': 1474, 'upstream': 1475, 'usurers': 1476, 'valley': 1477, 'vance': 1478, 'various': 1479, 'vast': 1480, 'vegetables': 1481, 'vehicle': 1482, 'veiled': 1483, 'vellum': 1484, 'vest': 1485, 'vigorously': 1486, 'vitamins': 1487, 'vivid': 1488, 'vocals': 1489, 'voice': 1490, 'waft': 1491, 'waist': 1492, 'wait': 1493, 'waited': 1494, 'waiting': 1495, 'waitress': 1496, 'walk': 1497, 'wanted': 1498, 'watch': 1499, 'watched': 1500, 'watermelon': 1501, 'wearin': 1502, 'weasley': 1503, 'wedding': 1504, 'weightlifting': 1505, 'welsh': 1506, 'wet': 1507, 'whenever': 1508, 'whispering': 1509, 'whisperings': 1510, 'wide': 1511, 'wildly': 1512, 'willed': 1513, 'wilting': 1514, 'windless': 1515, 'windows': 1516, 'wings': 1517, 'winters': 1518, 'wipe': 1519, 'wire': 1520, 'wished': 1521, 'woke': 1522, 'wonderful': 1523, 'words': 1524, 'wore': 1525, 'working': 1526, 'world': 1527, 'worn': 1528, 'wrenches': 1529, 'wrist': 1530, 'writing': 1531, 'wrong': 1532, 'yard': 1533, 'yards': 1534, 'yawned': 1535, 'years': 1536, 'yelled': 1537, 'yogurt': 1538, 'york': 1539, 'younger': 1540, 'yowl': 1541})\n"
     ]
    }
   ],
   "source": [
    " #단어장 생성\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "\n",
    "#단어장 생성 확인\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)   \n",
    "\n",
    "\n",
    "#ref :::::: https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('label', <torchtext.data.field.Field object at 0x1a4ae03490>), ('text', <torchtext.data.field.Field object at 0x1a4ae034d0>)])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.fields.items()) # tex, label 로 구분되어 있는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = 1\n",
    "num_layers = 2\n",
    "bidirection = True\n",
    "dropout = 0.2\n",
    "\n",
    "#instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
    "                   bidirectional = True, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(1542, 100)\n",
      "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 213,657 trainable parameters\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "copy_(): argument 'other' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-a0e1e7d28dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Initialize the pretrained embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpretrained_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: copy_(): argument 'other' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('label', <torchtext.data.field.Field object at 0x1a4ae03490>), ('text', <torchtext.data.field.Field object at 0x1a4ae034d0>)])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.fields.items()) # label, text가 각각 잘 구분되어 플드에 저작외었다. 이것을 이제 모델이 처 넣으면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=1, max_size=10000) #보캐브러리를 빌드한다. 그런데 왜하는겨?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 1542\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab))) #여기에 사용한 다어는 이많큼이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1a4ae032d0>>, {'<unk>': 0, '<pad>': 1, 'ft': 2, 'h': 3, 'fs': 4, 'could': 5, 'like': 6, 'behind': 7, 'one': 8, 'cold': 9, 'door': 10, 'face': 11, 'long': 12, 'looked': 13, 'see': 14, 'felt': 15, 'garden': 16, 'never': 17, 'said': 18, 'black': 19, 'c': 20, 'first': 21, 'hands': 22, 'night': 23, 'sun': 24, 'time': 25, 'day': 26, 'eyes': 27, 'front': 28, 'got': 29, 'hand': 30, 'late': 31, 'little': 32, 'stairs': 33, 'walked': 34, 'would': 35, 'back': 36, 'blood': 37, 'breath': 38, 'came': 39, 'every': 40, 'f': 41, 'far': 42, 'father': 43, 'house': 44, 'knew': 45, 'light': 46, 'made': 47, 'man': 48, 'nervous': 49, 'old': 50, 'reached': 51, 'red': 52, 'saw': 53, 'sweat': 54, 'tree': 55, 'two': 56, 'us': 57, 'village': 58, 'wind': 59, 'window': 60, 'already': 61, 'another': 62, 'away': 63, 'beautiful': 64, 'clouds': 65, 'dark': 66, 'darkness': 67, 'engine': 68, 'feet': 69, 'give': 70, 'glass': 71, 'go': 72, 'hair': 73, 'head': 74, 'held': 75, 'hot': 76, 'james': 77, 'last': 78, 'left': 79, 'lights': 80, 'lost': 81, 'mother': 82, 'page': 83, 'rain': 84, 'room': 85, 'seemed': 86, 'smell': 87, 'someone': 88, 'still': 89, 'stood': 90, 'streets': 91, 'took': 92, 'town': 93, 'wall': 94, 'walls': 95, 'weather': 96, 'went': 97, 'white': 98, 'alvin': 99, 'angry': 100, 'arms': 101, 'around': 102, 'boat': 103, 'bright': 104, 'cheek': 105, 'city': 106, 'dirty': 107, 'dress': 108, 'even': 109, 'fallen': 110, 'find': 111, 'five': 112, 'floor': 113, 'get': 114, 'gi': 115, 'good': 116, 'jim': 117, 'joey': 118, 'leaves': 119, 'life': 120, 'making': 121, 'minutes': 122, 'mr': 123, 'newspaper': 124, 'open': 125, 'pool': 126, 'river': 127, 'second': 128, 'show': 129, 'side': 130, 'slammed': 131, 'slowly': 132, 'small': 133, 'smoke': 134, 'steps': 135, 'thought': 136, 'thoughts': 137, 'toward': 138, 'turned': 139, 'way': 140, 'across': 141, 'afraid': 142, 'always': 143, 'among': 144, 'anyone': 145, 'anything': 146, 'asked': 147, 'bad': 148, 'bar': 149, 'bite': 150, 'blair': 151, 'blue': 152, 'books': 153, 'bottom': 154, 'box': 155, 'brother': 156, 'busy': 157, 'carl': 158, 'castle': 159, 'catch': 160, 'cheerful': 161, 'clara': 162, 'clear': 163, 'close': 164, 'closer': 165, 'crunched': 166, 'damp': 167, 'deep': 168, 'drew': 169, 'dry': 170, 'ears': 171, 'elroy': 172, 'enough': 173, 'favorite': 174, 'fear': 175, 'fingers': 176, 'found': 177, 'full': 178, 'girl': 179, 'grass': 180, 'green': 181, 'gripped': 182, 'ground': 183, 'gyou': 184, 'hated': 185, 'hear': 186, 'heard': 187, 'heart': 188, 'high': 189, 'hit': 190, 'home': 191, 'hoofbeats': 192, 'horse': 193, 'hours': 194, 'ice': 195, 'jay': 196, 'katie': 197, 'keep': 198, 'kept': 199, 'know': 200, 'lonely': 201, 'look': 202, 'looking': 203, 'looks': 204, 'love': 205, 'luke': 206, 'many': 207, 'meet': 208, 'mike': 209, 'mountains': 210, 'mouth': 211, 'must': 212, 'orias': 213, 'outside': 214, 'pale': 215, 'party': 216, 'people': 217, 'pictures': 218, 'pizza': 219, 'place': 220, 'pulled': 221, 'ran': 222, 'reading': 223, 'remember': 224, 'right': 225, 'running': 226, 'sally': 227, 'says': 228, 'school': 229, 'seen': 230, 'set': 231, 'shadow': 232, 'shaking': 233, 'sheet': 234, 'sky': 235, 'smile': 236, 'sometimes': 237, 'spilled': 238, 'storm': 239, 'summer': 240, 'sword': 241, 'table': 242, 'tell': 243, 'thick': 244, 'things': 245, 'though': 246, 'three': 247, 'tired': 248, 'today': 249, 'trembling': 250, 'veins': 251, 'want': 252, 'war': 253, 'warm': 254, 'well': 255, 'whole': 256, 'wooden': 257, 'work': 258, 'worked': 259, 'worry': 260, 'year': 261, 'yellow': 262, 'afternoon': 263, 'air': 264, 'alone': 265, 'amy': 266, 'anna': 267, 'anxiously': 268, 'archie': 269, 'arrive': 270, 'author': 271, 'barely': 272, 'beach': 273, 'became': 274, 'belt': 275, 'beneath': 276, 'bit': 277, 'book': 278, 'born': 279, 'bowen': 280, 'branch': 281, 'breakfast': 282, 'brick': 283, 'burning': 284, 'bus': 285, 'canadian': 286, 'canopy': 287, 'carefully': 288, 'carried': 289, 'cat': 290, 'center': 291, 'chan': 292, 'chapter': 293, 'cheese': 294, 'chilled': 295, 'church': 296, 'circus': 297, 'class': 298, 'climbed': 299, 'climbing': 300, 'clock': 301, 'commander': 302, 'complete': 303, 'cut': 304, 'cynthia': 305, 'dazzling': 306, 'decorated': 307, 'delicious': 308, 'described': 309, 'dog': 310, 'downstairs': 311, 'dresser': 312, 'earth': 313, 'eating': 314, 'elected': 315, 'emily': 316, 'fall': 317, 'family': 318, 'fast': 319, 'fd': 320, 'fence': 321, 'fern': 322, 'fifteen': 323, 'filled': 324, 'fire': 325, 'fish': 326, 'flowers': 327, 'fm': 328, 'footsteps': 329, 'forehead': 330, 'forest': 331, 'frost': 332, 'gabilan': 333, 'gate': 334, 'gibson': 335, 'going': 336, 'grandfather': 337, 'handle': 338, 'hard': 339, 'healthy': 340, 'heave': 341, 'heavy': 342, 'hoghouse': 343, 'hug': 344, 'hung': 345, 'imagine': 346, 'impossible': 347, 'ink': 348, 'insurance': 349, 'iron': 350, 'isolated': 351, 'jack': 352, 'jacket': 353, 'kicked': 354, 'kill': 355, 'knowing': 356, 'knuckles': 357, 'languages': 358, 'leather': 359, 'leaving': 360, 'let': 361, 'letting': 362, 'lightning': 363, 'liked': 364, 'london': 365, 'loved': 366, 'lucy': 367, 'madam': 368, 'malcolm': 369, 'mary': 370, 'massive': 371, 'mayor': 372, 'met': 373, 'metal': 374, 'metres': 375, 'might': 376, 'milk': 377, 'mind': 378, 'miss': 379, 'molly': 380, 'morning': 381, 'moved': 382, 'music': 383, 'name': 384, 'needs': 385, 'next': 386, 'noise': 387, 'north': 388, 'nose': 389, 'nothing': 390, 'nurse': 391, 'ocean': 392, 'october': 393, 'oliver': 394, 'onto': 395, 'opened': 396, 'orchestra': 397, 'palms': 398, 'paper': 399, 'patio': 400, 'peace': 401, 'peaceful': 402, 'pepperoni': 403, 'perfect': 404, 'person': 405, 'pigs': 406, 'pine': 407, 'ping': 408, 'pomfrey': 409, 'pong': 410, 'popped': 411, 'pounding': 412, 'public': 413, 'puppy': 414, 'purple': 415, 'put': 416, 'quickly': 417, 'raced': 418, 'rattling': 419, 'really': 420, 'rifles': 421, 'ring': 422, 'rock': 423, 'roger': 424, 'rolling': 425, 'run': 426, 'say': 427, 'sea': 428, 'sent': 429, 'several': 430, 'sewers': 431, 'sheets': 432, 'shirt': 433, 'signals': 434, 'silver': 435, 'since': 436, 'sister': 437, 'skin': 438, 'smelled': 439, 'smoking': 440, 'soldiers': 441, 'somehow': 442, 'sound': 443, 'speak': 444, 'speech': 445, 'sports': 446, 'spray': 447, 'spread': 448, 'squirrel': 449, 'staircase': 450, 'stale': 451, 'standing': 452, 'steam': 453, 'steep': 454, 'step': 455, 'stepped': 456, 'stomach': 457, 'stone': 458, 'straight': 459, 'stroke': 460, 'strong': 461, 'sure': 462, 'susie': 463, 'taking': 464, 'taste': 465, 'teeth': 466, 'temperature': 467, 'threw': 468, 'times': 469, 'tiny': 470, 'top': 471, 'touched': 472, 'train': 473, 'trunk': 474, 'trying': 475, 'twenty': 476, 'twisted': 477, 'used': 478, 'usual': 479, 'voices': 480, 'warmed': 481, 'watching': 482, 'water': 483, 'waters': 484, 'waves': 485, 'weak': 486, 'wearing': 487, 'weight': 488, 'whipped': 489, 'wife': 490, 'without': 491, 'woman': 492, 'wood': 493, 'wrapped': 494, 'young': 495, 'aaron': 496, 'abandoned': 497, 'accelerating': 498, 'ached': 499, 'active': 500, 'address': 501, 'adze': 502, 'afterward': 503, 'ago': 504, 'aim': 505, 'aimed': 506, 'allowed': 507, 'almost': 508, 'also': 509, 'amount': 510, 'animal': 511, 'anymore': 512, 'anytime': 513, 'appear': 514, 'applying': 515, 'appointment': 516, 'arable': 517, 'arm': 518, 'arrived': 519, 'ashes': 520, 'attention': 521, 'attractive': 522, 'autumn': 523, 'avoided': 524, 'aware': 525, 'ax': 526, 'bachelor': 527, 'backpack': 528, 'backward': 529, 'bag': 530, 'baking': 531, 'band': 532, 'bang': 533, 'banging': 534, 'barcel': 535, 'bathroom': 536, 'beads': 537, 'bearings': 538, 'beatty': 539, 'become': 540, 'becomes': 541, 'bedecked': 542, 'beg': 543, 'began': 544, 'bending': 545, 'beside': 546, 'best': 547, 'bill': 548, 'biting': 549, 'bitter': 550, 'blackened': 551, 'blackout': 552, 'blades': 553, 'blank': 554, 'bleached': 555, 'blessing': 556, 'blind': 557, 'blinding': 558, 'blinked': 559, 'blond': 560, 'bloodied': 561, 'blotting': 562, 'blushing': 563, 'boarded': 564, 'bobber': 565, 'bodies': 566, 'body': 567, 'bolts': 568, 'boots': 569, 'boring': 570, 'bouncing': 571, 'bow': 572, 'bowed': 573, 'boxes': 574, 'branches': 575, 'break': 576, 'breathe': 577, 'breeze': 578, 'brenda': 579, 'bricks': 580, 'brighter': 581, 'brightly': 582, 'bring': 583, 'bringing': 584, 'broadsword': 585, 'brought': 586, 'brushed': 587, 'brushwood': 588, 'bubbled': 589, 'buckets': 590, 'bud': 591, 'buds': 592, 'building': 593, 'bulbs': 594, 'bulging': 595, 'bullied': 596, 'bunches': 597, 'burned': 598, 'burrowed': 599, 'busied': 600, 'butterfly': 601, 'cab': 602, 'calcium': 603, 'calle': 604, 'calm': 605, 'canal': 606, 'candles': 607, 'canuda': 608, 'caps': 609, 'car': 610, 'carpenter': 611, 'carriage': 612, 'carry': 613, 'carrying': 614, 'cars': 615, 'casserole': 616, 'cast': 617, 'caught': 618, 'celebrated': 619, 'chain': 620, 'chair': 621, 'champagne': 622, 'championships': 623, 'changed': 624, 'chapel': 625, 'chased': 626, 'cheeks': 627, 'chest': 628, 'child': 629, 'children': 630, 'chill': 631, 'chocolate': 632, 'choked': 633, 'choking': 634, 'choppy': 635, 'christmas': 636, 'cigarette': 637, 'cjoey': 638, 'clammy': 639, 'clap': 640, 'classroom': 641, 'clatter': 642, 'clattering': 643, 'clean': 644, 'clearly': 645, 'click': 646, 'cliff': 647, 'cloud': 648, 'clung': 649, 'clutched': 650, 'cneither': 651, 'coat': 652, 'cobblestone': 653, 'cobblestones': 654, 'cocktail': 655, 'cocktails': 656, 'coffee': 657, 'colds': 658, 'collar': 659, 'collect': 660, 'collection': 661, 'college': 662, 'colorful': 663, 'colour': 664, 'come': 665, 'comes': 666, 'competes': 667, 'complaining': 668, 'confused': 669, 'congealed': 670, 'connect': 671, 'consumed': 672, 'containers': 673, 'content': 674, 'continued': 675, 'conveyance': 676, 'cookies': 677, 'cooking': 678, 'correct': 679, 'cottages': 680, 'county': 681, 'course': 682, 'courtyard': 683, 'coveralls': 684, 'covered': 685, 'covering': 686, 'covers': 687, 'crack': 688, 'crashed': 689, 'crawled': 690, 'creaky': 691, 'creditors': 692, 'creek': 693, 'creeping': 694, 'creepy': 695, 'crepe': 696, 'crept': 697, 'crisscrossed': 698, 'crop': 699, 'crossed': 700, 'crossword': 701, 'crow': 702, 'crowd': 703, 'crowded': 704, 'crumpling': 705, 'crunching': 706, 'crystal': 707, 'crystals': 708, 'cubes': 709, 'culinary': 710, 'cupboard': 711, 'cupboards': 712, 'curly': 713, 'cursing': 714, 'curtain': 715, 'customers': 716, 'dairy': 717, 'daisy': 718, 'dangled': 719, 'dashed': 720, 'dave': 721, 'dawn': 722, 'dead': 723, 'dearly': 724, 'deathly': 725, 'debated': 726, 'decent': 727, 'decide': 728, 'decided': 729, 'decisively': 730, 'delicately': 731, 'descended': 732, 'desert': 733, 'desperately': 734, 'destroyed': 735, 'diagilo': 736, 'different': 737, 'diligent': 738, 'diligently': 739, 'ding': 740, 'disappeared': 741, 'discerned': 742, 'discover': 743, 'distance': 744, 'distorted': 745, 'dividing': 746, 'doctor': 747, 'dodging': 748, 'donuts': 749, 'downwards': 750, 'drawer': 751, 'drawn': 752, 'drenched': 753, 'dressing': 754, 'drink': 755, 'drinker': 756, 'drinks': 757, 'drive': 758, 'driver': 759, 'droppings': 760, 'drove': 761, 'dug': 762, 'dull': 763, 'dumb': 764, 'dye': 765, 'early': 766, 'easily': 767, 'eevery': 768, 'effort': 769, 'eh': 770, 'ei': 771, 'eight': 772, 'ekaterina': 773, 'elephant': 774, 'eligible': 775, 'embrace': 776, 'emitted': 777, 'empty': 778, 'encouragement': 779, 'end': 780, 'energy': 781, 'eno': 782, 'entirely': 783, 'enveloped': 784, 'especially': 785, 'evening': 786, 'evinrude': 787, 'ewhat': 788, 'exhaustion': 789, 'expect': 790, 'expensive': 791, 'explosion': 792, 'eyed': 793, 'eyelashes': 794, 'fabric': 795, 'faces': 796, 'faded': 797, 'faint': 798, 'false': 799, 'fam': 800, 'familiar': 801, 'fan': 802, 'fancy': 803, 'feather': 804, 'feature': 805, 'feel': 806, 'feeling': 807, 'fell': 808, 'fetid': 809, 'fight': 810, 'figuring': 811, 'fingernail': 812, 'fiona': 813, 'fireplace': 814, 'fishing': 815, 'fishtail': 816, 'flaking': 817, 'flame': 818, 'flames': 819, 'flapped': 820, 'flares': 821, 'flat': 822, 'flattened': 823, 'flesh': 824, 'flew': 825, 'flickered': 826, 'fll': 827, 'floating': 828, 'flooding': 829, 'floorboard': 830, 'florentine': 831, 'flower': 832, 'flowing': 833, 'flying': 834, 'fog': 835, 'fogged': 836, 'foggy': 837, 'folded': 838, 'food': 839, 'football': 840, 'foothold': 841, 'forbidden': 842, 'forced': 843, 'foreign': 844, 'form': 845, 'formed': 846, 'forward': 847, 'fought': 848, 'frames': 849, 'freeze': 850, 'friend': 851, 'frightened': 852, 'frigid': 853, 'frozen': 854, 'fullness': 855, 'fully': 856, 'fur': 857, 'furs': 858, 'fve': 859, 'ga': 860, 'game': 861, 'gardener': 862, 'gardens': 863, 'gave': 864, 'gdarlene': 865, 'gdo': 866, 'gents': 867, 'georgie': 868, 'getting': 869, 'gget': 870, 'ggood': 871, 'gholy': 872, 'ghostly': 873, 'ginny': 874, 'girls': 875, 'given': 876, 'giving': 877, 'glet': 878, 'glided': 879, 'glistened': 880, 'glowing': 881, 'glumly': 882, 'glutinous': 883, 'gnice': 884, 'gnot': 885, 'god': 886, 'goh': 887, 'gold': 888, 'gotten': 889, 'gpiccadilly': 890, 'gpoint': 891, 'grabbed': 892, 'grabbing': 893, 'graceful': 894, 'grand': 895, 'grasping': 896, 'gravity': 897, 'gray': 898, 'grazing': 899, 'great': 900, 'grew': 901, 'grimace': 902, 'gritted': 903, 'gritty': 904, 'groaned': 905, 'grounds': 906, 'grow': 907, 'gsit': 908, 'gslice': 909, 'gstop': 910, 'guards': 911, 'guessing': 912, 'gun': 913, 'gushed': 914, 'gutters': 915, 'hail': 916, 'half': 917, 'halfway': 918, 'halls': 919, 'hallway': 920, 'halted': 921, 'hammer': 922, 'hammering': 923, 'hanging': 924, 'hansom': 925, 'happily': 926, 'harsh': 927, 'haze': 928, 'heaps': 929, 'heaven': 930, 'help': 931, 'hem': 932, 'hidden': 933, 'higher': 934, 'hill': 935, 'hills': 936, 'hilltops': 937, 'hinges': 938, 'hockey': 939, 'holt': 940, 'homework': 941, 'hooked': 942, 'horizon': 943, 'horsepower': 944, 'horses': 945, 'houses': 946, 'huddled': 947, 'human': 948, 'humming': 949, 'hungry': 950, 'hunk': 951, 'hurled': 952, 'hurry': 953, 'husband': 954, 'ideal': 955, 'ignited': 956, 'ill': 957, 'impenetrable': 958, 'impression': 959, 'incorrect': 960, 'increased': 961, 'increasing': 962, 'ing': 963, 'ingredient': 964, 'inhale': 965, 'inside': 966, 'instantly': 967, 'instead': 968, 'intensity': 969, 'interrupted': 970, 'invisible': 971, 'iona': 972, 'ireland': 973, 'itched': 974, 'jerked': 975, 'jews': 976, 'job': 977, 'joy': 978, 'juli': 979, 'jump': 980, 'jumped': 981, 'junkyard': 982, 'key': 983, 'kind': 984, 'kindergarten': 985, 'kinds': 986, 'kiosk': 987, 'kitchen': 988, 'kitchenware': 989, 'knee': 990, 'knight': 991, 'knowledge': 992, 'known': 993, 'lady': 994, 'latin': 995, 'lawns': 996, 'lay': 997, 'layers': 998, 'lead': 999, 'leaden': 1000, 'leader': 1001, 'leaned': 1002, 'leapt': 1003, 'leave': 1004, 'led': 1005, 'leg': 1006, 'lemonade': 1007, 'library': 1008, 'lifetime': 1009, 'lift': 1010, 'lifting': 1011, 'lifts': 1012, 'lighting': 1013, 'lightly': 1014, 'lime': 1015, 'lip': 1016, 'lips': 1017, 'lives': 1018, 'living': 1019, 'locking': 1020, 'lookin': 1021, 'lots': 1022, 'loud': 1023, 'louder': 1024, 'lovely': 1025, 'low': 1026, 'lower': 1027, 'lurches': 1028, 'luscious': 1029, 'lying': 1030, 'mactalde': 1031, 'madness': 1032, 'magical': 1033, 'make': 1034, 'managed': 1035, 'manner': 1036, 'matters': 1037, 'may': 1038, 'meal': 1039, 'mean': 1040, 'meat': 1041, 'medicine': 1042, 'medieval': 1043, 'melancholy': 1044, 'melted': 1045, 'melting': 1046, 'men': 1047, 'merchants': 1048, 'mesmerized': 1049, 'mess': 1050, 'michael': 1051, 'middle': 1052, 'mine': 1053, 'minute': 1054, 'misbehaving': 1055, 'missed': 1056, 'missing': 1057, 'mist': 1058, 'mold': 1059, 'mom': 1060, 'moment': 1061, 'monotonously': 1062, 'montag': 1063, 'moon': 1064, 'moonlit': 1065, 'moths': 1066, 'mottled': 1067, 'movement': 1068, 'movements': 1069, 'moving': 1070, 'mowing': 1071, 'mozzarella': 1072, 'mrs': 1073, 'much': 1074, 'muscles': 1075, 'mushrooms': 1076, 'n': 1077, 'nale': 1078, 'named': 1079, 'narrowing': 1080, 'navigated': 1081, 'nearer': 1082, 'network': 1083, 'new': 1084, 'nice': 1085, 'nineties': 1086, 'ninja': 1087, 'nostrils': 1088, 'note': 1089, 'notion': 1090, 'notions': 1091, 'occured': 1092, 'offer': 1093, 'older': 1094, 'ones': 1095, 'oooh': 1096, 'opaque': 1097, 'opera': 1098, 'ophelia': 1099, 'opponent': 1100, 'opulent': 1101, 'orange': 1102, 'ordered': 1103, 'ordinary': 1104, 'others': 1105, 'outboard': 1106, 'outline': 1107, 'outward': 1108, 'outwards': 1109, 'overnight': 1110, 'overran': 1111, 'oyster': 1112, 'packed': 1113, 'pain': 1114, 'painful': 1115, 'paint': 1116, 'palatial': 1117, 'palm': 1118, 'pancake': 1119, 'pancakes': 1120, 'pans': 1121, 'pardon': 1122, 'parked': 1123, 'part': 1124, 'parties': 1125, 'pass': 1126, 'passageways': 1127, 'passed': 1128, 'passionate': 1129, 'past': 1130, 'patch': 1131, 'patches': 1132, 'path': 1133, 'pavements': 1134, 'pay': 1135, 'pedestrian': 1136, 'pedestrians': 1137, 'peeled': 1138, 'pepperup': 1139, 'percy': 1140, 'permeate': 1141, 'perspire': 1142, 'petals': 1143, 'philosophies': 1144, 'piccadilly': 1145, 'picking': 1146, 'picks': 1147, 'piece': 1148, 'pies': 1149, 'pig': 1150, 'piled': 1151, 'piles': 1152, 'pillow': 1153, 'pines': 1154, 'pink': 1155, 'piss': 1156, 'piston': 1157, 'pitcher': 1158, 'pitches': 1159, 'planned': 1160, 'plants': 1161, 'players': 1162, 'playing': 1163, 'pleasant': 1164, 'plumber': 1165, 'plump': 1166, 'plunger': 1167, 'plush': 1168, 'point': 1169, 'pointed': 1170, 'poppies': 1171, 'potion': 1172, 'pots': 1173, 'poured': 1174, 'pouring': 1175, 'powder': 1176, 'preferred': 1177, 'pressed': 1178, 'pretty': 1179, 'products': 1180, 'progress': 1181, 'promises': 1182, 'protagonist': 1183, 'protection': 1184, 'protein': 1185, 'provolone': 1186, 'puck': 1187, 'pull': 1188, 'pulling': 1189, 'pulsing': 1190, 'purplish': 1191, 'pushed': 1192, 'puzzle': 1193, 'race': 1194, 'rampant': 1195, 'rapid': 1196, 'rather': 1197, 'rattled': 1198, 'rays': 1199, 'razor': 1200, 'reach': 1201, 'read': 1202, 'readers': 1203, 'ready': 1204, 'reason': 1205, 'reef': 1206, 'reflected': 1207, 'reflecting': 1208, 'reflexes': 1209, 'refuge': 1210, 'regret': 1211, 'release': 1212, 'relief': 1213, 'remaining': 1214, 'remove': 1215, 'replied': 1216, 'restaurant': 1217, 'return': 1218, 'revolted': 1219, 'riding': 1220, 'rising': 1221, 'rivers': 1222, 'riveted': 1223, 'roared': 1224, 'rolled': 1225, 'romantic': 1226, 'roof': 1227, 'roofs': 1228, 'rooms': 1229, 'rose': 1230, 'rosettes': 1231, 'rosy': 1232, 'rotten': 1233, 'rough': 1234, 'round': 1235, 'rounds': 1236, 'rubble': 1237, 'rumbles': 1238, 'rump': 1239, 'runt': 1240, 'rustle': 1241, 'ruzz': 1242, 'sad': 1243, 'saddle': 1244, 'safety': 1245, 'salina': 1246, 'salinas': 1247, 'sand': 1248, 'sapphire': 1249, 'sat': 1250, 'sauce': 1251, 'sausage': 1252, 'scarier': 1253, 'scent': 1254, 'scheduled': 1255, 'scrabbling': 1256, 'scramble': 1257, 'scrambled': 1258, 'screamed': 1259, 'screen': 1260, 'scribbled': 1261, 'seat': 1262, 'seconds': 1263, 'seeds': 1264, 'seeing': 1265, 'seem': 1266, 'selling': 1267, 'send': 1268, 'senior': 1269, 'sentence': 1270, 'served': 1271, 'serving': 1272, 'setting': 1273, 'shade': 1274, 'shadows': 1275, 'shake': 1276, 'shapes': 1277, 'sharp': 1278, 'sharpening': 1279, 'shattered': 1280, 'shavings': 1281, 'sheathed': 1282, 'sheer': 1283, 'shelves': 1284, 'shifted': 1285, 'shine': 1286, 'shit': 1287, 'shivering': 1288, 'shocked': 1289, 'shore': 1290, 'shout': 1291, 'shouted': 1292, 'showered': 1293, 'shrieked': 1294, 'shroud': 1295, 'shuf': 1296, 'shut': 1297, 'shuzz': 1298, 'sick': 1299, 'sides': 1300, 'sidewalks': 1301, 'sifted': 1302, 'sigh': 1303, 'sighed': 1304, 'sighet': 1305, 'sighing': 1306, 'silenced': 1307, 'silent': 1308, 'silly': 1309, 'simple': 1310, 'single': 1311, 'sings': 1312, 'sir': 1313, 'sisters': 1314, 'sits': 1315, 'situation': 1316, 'six': 1317, 'sizes': 1318, 'skies': 1319, 'slack': 1320, 'slam': 1321, 'slapping': 1322, 'slash': 1323, 'sleepy': 1324, 'sleigh': 1325, 'slept': 1326, 'slice': 1327, 'slick': 1328, 'slip': 1329, 'slopes': 1330, 'slow': 1331, 'slowed': 1332, 'slushies': 1333, 'smallest': 1334, 'smelling': 1335, 'smiled': 1336, 'smiles': 1337, 'smooth': 1338, 'snarl': 1339, 'snuck': 1340, 'snuffed': 1341, 'sold': 1342, 'solid': 1343, 'something': 1344, 'somewhere': 1345, 'soon': 1346, 'sorority': 1347, 'sorting': 1348, 'soul': 1349, 'spaces': 1350, 'spans': 1351, 'spate': 1352, 'speaks': 1353, 'speed': 1354, 'spilling': 1355, 'spit': 1356, 'splinter': 1357, 'sport': 1358, 'spreading': 1359, 'spring': 1360, 'spun': 1361, 'spurred': 1362, 'square': 1363, 'squinted': 1364, 'squinting': 1365, 'stacks': 1366, 'staff': 1367, 'stains': 1368, 'staleness': 1369, 'stands': 1370, 'stars': 1371, 'starts': 1372, 'state': 1373, 'stay': 1374, 'steadily': 1375, 'steady': 1376, 'stealth': 1377, 'steeds': 1378, 'stepping': 1379, 'stiff': 1380, 'stirred': 1381, 'stop': 1382, 'story': 1383, 'straightened': 1384, 'strawberry': 1385, 'street': 1386, 'streetlamps': 1387, 'strokes': 1388, 'struggled': 1389, 'studded': 1390, 'students': 1391, 'stumbled': 1392, 'subject': 1393, 'sucked': 1394, 'sudden': 1395, 'suddenly': 1396, 'suffer': 1397, 'sunday': 1398, 'sunny': 1399, 'sunshine': 1400, 'suppose': 1401, 'surpassed': 1402, 'surprised': 1403, 'surrender': 1404, 'suzie': 1405, 'swamped': 1406, 'sweaty': 1407, 'sweeping': 1408, 'sweet': 1409, 'swiftly': 1410, 'swimmers': 1411, 'swipes': 1412, 'swirled': 1413, 'switched': 1414, 'sycamores': 1415, 'tackle': 1416, 'take': 1417, 'talented': 1418, 'taller': 1419, 'tapped': 1420, 'temporary': 1421, 'ten': 1422, 'tensed': 1423, 'terms': 1424, 'text': 1425, 'thatched': 1426, 'thermometers': 1427, 'thin': 1428, 'thing': 1429, 'third': 1430, 'throat': 1431, 'throttle': 1432, 'thumbnail': 1433, 'thump': 1434, 'thunder': 1435, 'thundered': 1436, 'tiffany': 1437, 'tiger': 1438, 'tighten': 1439, 'tim': 1440, 'tin': 1441, 'tissue': 1442, 'tobacco': 1443, 'toilet': 1444, 'tom': 1445, 'tomato': 1446, 'tonight': 1447, 'toolbox': 1448, 'tools': 1449, 'tossed': 1450, 'tough': 1451, 'towards': 1452, 'trade': 1453, 'trees': 1454, 'trembled': 1455, 'tried': 1456, 'tripped': 1457, 'troubled': 1458, 'tuning': 1459, 'turbulent': 1460, 'turning': 1461, 'tv': 1462, 'tweed': 1463, 'twinkling': 1464, 'umbrella': 1465, 'unattached': 1466, 'uneven': 1467, 'unjust': 1468, 'unnatural': 1469, 'unsuccessful': 1470, 'unusual': 1471, 'upcoming': 1472, 'upon': 1473, 'upper': 1474, 'upstream': 1475, 'usurers': 1476, 'valley': 1477, 'vance': 1478, 'various': 1479, 'vast': 1480, 'vegetables': 1481, 'vehicle': 1482, 'veiled': 1483, 'vellum': 1484, 'vest': 1485, 'vigorously': 1486, 'vitamins': 1487, 'vivid': 1488, 'vocals': 1489, 'voice': 1490, 'waft': 1491, 'waist': 1492, 'wait': 1493, 'waited': 1494, 'waiting': 1495, 'waitress': 1496, 'walk': 1497, 'wanted': 1498, 'watch': 1499, 'watched': 1500, 'watermelon': 1501, 'wearin': 1502, 'weasley': 1503, 'wedding': 1504, 'weightlifting': 1505, 'welsh': 1506, 'wet': 1507, 'whenever': 1508, 'whispering': 1509, 'whisperings': 1510, 'wide': 1511, 'wildly': 1512, 'willed': 1513, 'wilting': 1514, 'windless': 1515, 'windows': 1516, 'wings': 1517, 'winters': 1518, 'wipe': 1519, 'wire': 1520, 'wished': 1521, 'woke': 1522, 'wonderful': 1523, 'words': 1524, 'wore': 1525, 'working': 1526, 'world': 1527, 'worn': 1528, 'wrenches': 1529, 'wrist': 1530, 'writing': 1531, 'wrong': 1532, 'yard': 1533, 'yards': 1534, 'yawned': 1535, 'years': 1536, 'yelled': 1537, 'yogurt': 1538, 'york': 1539, 'younger': 1540, 'yowl': 1541})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi) # 생성된 집합 내 단어들을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기까지 잘됨, 이것을 이제 레이블, torch tensor로 변환 해야함. train_dataset, test_dataset 각각 처리할것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토치텍스트의 테이터로더 생성\n",
    "\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 13\n",
      "테스트 데이터의 미니 배치 수 : 4\n"
     ]
    }
   ],
   "source": [
    "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
    "test_loader = Iterator(dataset=test_data, batch_size = batch_size)\n",
    "\n",
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.iterator.Iterator at 0x1a4b00bad0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.iterator.Iterator"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 771, 1401,   72,   41,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  86,  232,  110,  232,  188,  876,  900,  980, 1431,  634,   37,  132,\n",
      "          295,   15,   54,  433,    9,  824,    1,    1],\n",
      "        [ 426,   33,  361,  310,  965,  282, 1257,  153,  353, 1194,   28,   10,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  23,    9, 1065, 1325,  382,  319,  331,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 579,  131,  312,  751, 1297, 1361,  102,   22,  933,    7,   36, 1017,\n",
      "          975, 1380,  236,  721,  136,  191, 1317,  301],\n",
      "        [  34,   33,   51,  183,  113,  979, 1077,   47,  140, 1008, 1284,  778,\n",
      "          814,  633, 1237,   95,  725,  215,  826,   38],\n",
      "        [1457,  808,  529,   90,  563,  627,  233,   22,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 203,  318,  218,    5,  243,  158,  116,   48,  954,  738,  109,  315,\n",
      "          372,   93,    1,    1,    1,    1,    1,    1],\n",
      "        [ 387,  628,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 703,   13,  100,    2, 1403, 1219,  911,    5,  198,  401,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  93,   52,  283,  283,   35,   52,  134,  520,  507, 1037,   90,   93,\n",
      "         1469,   52,   19,   20,   19,  606,  127,  222],\n",
      "        [ 305, 1294,  221, 1512,   73,  131,   10,  360,   32,  156,  265,  669,\n",
      "          920,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 234,  399,  554, 1474,  130, 1531,  163, 1191,   19,  348, 1027,  995,\n",
      "         1425,  339, 1202, 1043,   30,    1,    1,    1],\n",
      "        [ 883,   67,   39,   57,  130,   32,   36,  845,  450,    5,  742,   19,\n",
      "          458,  135,  732,   81, 1275,    1,    1,    1],\n",
      "        [1437,  182,  432,  597,    9,  176,  330, 1328,   54,   10, 1198,  486,\n",
      "          938,    2,  346,   35,   12,   29,    1,    1],\n",
      "        [ 365,    9,  167,  837,  106,  698,  653,   91, 1137,  288,  748,  760,\n",
      "         1378,  221, 1036,  413,  676,    8, 1136,  367]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 16개씩 묶어줬음. 첫번째 미니배치에 저장\n",
    "\n",
    "print(batch.text) #첫번째 미니 배치의 text 필드를 호출해서 확인해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 133,  819, 1381,  474,   55,  690,   63,  119,  588,  746,  962,    8,\n",
      "        1131,  472,   55,  474, 1258,    6,  104,  449])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 첫번째 미니배치\n",
    "print(batch.text[0]) # 첫번째 미니배치 중 첫번째 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch)) #미니배치 자료형 확인. 토치텍스늬 데이터로더는  'torchtext.data.batch.Batch'라는 객체를 가져온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 133,  819, 1381,  474,   55,  690,   63,  119,  588,  746,  962,\n",
       "          8, 1131,  472,   55,  474, 1258,    6,  104,  449])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tr = batch.text.numpy() #tensor를 array로 전환해봄(테스트) , 여기에 라벨값이 포함되어 있는데, 이것을 구분해서 추가해줘보자...\n",
    "batch_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기가지 진행완료!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif = []\n",
    "data_verif = test_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif = []\n",
    "data_verif = train_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(data_verif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f67e83100594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEMBED_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNUN_CLASS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUN_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_vocab'"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000lines [00:08, 14582.67lines/s]\n",
      "120000lines [00:15, 7822.49lines/s]\n",
      "7600lines [00:00, 8340.65lines/s]\n"
     ]
    }
   ],
   "source": [
    "#원본코드인데.. 이미 가공된 데이터셋을 ngrams 처리해서 불러오기 때문에 입력데이터를 dataset에 맞게 수정해야 한다.\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "\n",
    "NGRAMS = 2\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.isdir('./data2'):\n",
    "    os.mkdir('./data2')\n",
    "    \n",
    "    \n",
    "#text_classification.DATASETS의 구조를 보고 결과데이터를 어떻게 생성하는지 분석하거나 이하 학습코드를 분석    \n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "    root='./data2', ngrams=NGRAMS, vocab=None) \n",
    "#ref : https://pytorch.org/text/datasets.html#ag-news\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  tensor([    131,       5,   23258,      27,    2922,     357,    2688,     769,\n",
       "              814,      14,      32,      15,      16,       6,     131,       7,\n",
       "              230,     293,     452,     836,    6438,      85,       2,      51,\n",
       "            43647,       2,   24372,       4,   60885,      51,  281059,       2,\n",
       "                0,       9,   21969,     115,       2,      51,  108539,       2,\n",
       "            36279,       4,      11,      81,      31,      90,      39,   23258,\n",
       "                6,      27,     357,    4090,    1698,      53,       5,     273,\n",
       "              821,       3,    1507,       7,       3,    1473,    3049,       2,\n",
       "             9821,   53919,  115850,   75043,   30252,  478273,  244818,     822,\n",
       "             4291,      43,      44,      46,     296,    2486,    2022,    8893,\n",
       "            23909,   49141,  381768,    9169,   19041,      89,     122,       0,\n",
       "            43648,   24031,   69185,   94356, 1174101,       0,  450795,       0,\n",
       "                0,  223922,  108592,     126,     122,       0,  178323,   35545,\n",
       "           409428,     735,     174,    3486,    2986,    3563,  119987,  102135,\n",
       "              151,   21657,   24613,  196267,  449408,     568,    9261,   16383,\n",
       "            10610,   12791,   10597,      29,    3937,  125919,   29219])),\n",
       " (3,\n",
       "  tensor([    398,    1371,    4357,     140,       4,     529,   17887,     769,\n",
       "              814,      14,      32,      15,      16,     398,     239,      85,\n",
       "                2,      51,   12202,       2,   36279,      11,      77,    1017,\n",
       "             3918,       6,      27,     621,    1304,       5,    1413,     450,\n",
       "             1535,   20318,    3524,    4357,       9,    1475,       6,    5662,\n",
       "           139374,     140,   17887,   10030,      25,    5818,     295,     374,\n",
       "             3237,     140,       2,   58236,  912220,  247465,    3730,   20914,\n",
       "                0,       0,     822,    4291,      43,      44,      46,   10183,\n",
       "             2133,    4850,      89,     122,       0,   27392,   35545,  132604,\n",
       "              161,  288511,  177353,   56884,     151,   37744,  115817,    1756,\n",
       "             5972,   49904, 1262338,  702497, 1079944,  965345,  128458,  175247,\n",
       "             5939,   33049,       0,  472516,       0,       0,       0,   11287,\n",
       "                0,  127381,  125934,       0,    3595])),\n",
       " (3,\n",
       "  tensor([  1743,   1191,   2678,    398,      5,   1044,   2419,    172,   5807,\n",
       "              14,     32,     15,     16,    506,    198,   7286,      4,      6,\n",
       "            1743,    288,   1118,   1847,      4,    500,    398,    239,     85,\n",
       "               2,      5,    172,     11,     77,     20,      3,    559,      7,\n",
       "               6,     27,   2419,    214,      8,    482,     17,     10,    415,\n",
       "           13976,     12,    592,   5611,    343,      2, 183509,      0, 326295,\n",
       "           29013,  36745,      0,  87826,      0,  15874,     43,     44,     46,\n",
       "           40085,      0, 430407, 103141,     87,  19259,      0, 404669,  43244,\n",
       "           10017,  29826,      0,   2133,   4850,     89,   2071,  10175,  39267,\n",
       "             161,  10293,    154,   5172,   3559,    107,    151, 262534,  14209,\n",
       "            6874,   2580,   6611,     23,   5736, 256315, 145528,  17037, 350126,\n",
       "               0,   4028])),\n",
       " (3,\n",
       "  tensor([  3270, 144492,  18571,    840,    368,      6,    334, 141753,  18571,\n",
       "               7,  62303,    136,     33,    109,   2508,      8,   6705,      4,\n",
       "             368,      4,    125,   5741,   1044,  68572,   2480,      2,      0,\n",
       "               0,      0,      0,  58315,  10751,      0,      0, 109318,      0,\n",
       "               0,   3087,    282,  21461,  18230,  49708,  49983,   5149,   9282,\n",
       "            7808,  38803,      0,      0,      0,  36581])),\n",
       " (3,\n",
       "  tensor([1155350,   17813,   46664,    1367,   46664,    1367,       4,     156,\n",
       "           422148,       4,   16838,      11, 1155350,       5,     633,     333,\n",
       "               34,   38763,       4,     601,    1395,       2,       0,       0,\n",
       "                0,       0,       0,   14019,    1323,       0,       0,       0,\n",
       "            20324,       0,       0,    1215,   34865,   15806,  801893,       0,\n",
       "             4382,   91929,   62739])),\n",
       " (3,\n",
       "  tensor([   9647,     111,       2,   19481,      17,      10,   13103,     339,\n",
       "            57385,   19481,   14857,      25,    2291,    3920,     740,       5,\n",
       "               35,   27554,     339,   45525,     301,      25,  221858,     130,\n",
       "                2,       0,    7864,   51327, 1098538,      23,  275296,       0,\n",
       "                0,   77111,       0,  221568,   63824,       0,       0,     958,\n",
       "             1149,   78427,       0,  152353,       0,   16709,       0,       0,\n",
       "             1272]))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
       "             1143,      14,      32,      15,      32,      16,  443749,       4,\n",
       "              572,     499,      17,      10,  741769,       7,  468770,       4,\n",
       "               52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
       "           326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
       "              144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
       "          1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
       "             4052])),\n",
       " (2,\n",
       "  tensor([  55003,    1474,    1150,    1832,    7559,      14,      32,      15,\n",
       "               32,      16,    1262,    1072,     436,   55003,     131,       4,\n",
       "           142576,      33,       6,    8062,      12,     756,  475640,       9,\n",
       "           991346,    3186,       8,       3,     698,     329,       4,      33,\n",
       "             6764, 1040465,   13979,      11,     278,     483,       7,       3,\n",
       "              172,       2,  659973,  193730, 1237754,  684719,  556644,      43,\n",
       "               44,     144,     145,   77775,   56578,   32382,  782124,   79225,\n",
       "             2908,  140697,  540900,    2031,   31960,   45339,   21562,  936430,\n",
       "          1282186,  578442,  991347,   69671,      26,    9260,  717285,    5378,\n",
       "              597,   27622, 1070413, 1040466,   38669,   27790,  175394,     711,\n",
       "               29,    1404,    1818])),\n",
       " (2,\n",
       "  tensor([    78,      9,    469,   8385,    206,     17,    996,     14,     32,\n",
       "              15,     32,     16,   3654,    600,    124,   3080, 140201,      3,\n",
       "             469,      9,      3,    996,     12,    369,     52,    328, 464765,\n",
       "              48,      3,    397,    172,    149,    113,    301,      3,  18223,\n",
       "               7, 285456,  52106,      2,   5606,  95553, 183737, 180431, 164136,\n",
       "          120431,  30446,     43,     44,    144,    145,  85276,  92253,  10654,\n",
       "          200704, 422054, 213900,   1877,   8549,    152,  12306,   6126,  55468,\n",
       "           63058,   4461, 358165, 464766,    204,   5641,   4893,  59857,   1515,\n",
       "           93728,    995,  83994,  79735, 411437, 460552, 110113])),\n",
       " (2,\n",
       "  tensor([     93,   16478,      78,    2680,      34,    1230,     717,    4562,\n",
       "               14,      32,      15,      32,      16,    1129,      49,    9392,\n",
       "               78,  766148,      34,       3,    1230,    4562,       8,     717,\n",
       "               93,  559272,     947,       6,    1239,    3934,     125, 1178056,\n",
       "                4,      35,      78,     396,      31,      11,     153,       2,\n",
       "           881320,  373252,   12125,   23059,  802619,  258328,  447615,  199864,\n",
       "               43,      44,     144,     145,   40078,   13205,  152671,  373240,\n",
       "          1002054,  766149,     171,    4412,  934044,   47573,    2586,   17490,\n",
       "           881151,  559273,   16579,   17268,   64855,  954751,  699138, 1178057,\n",
       "              733,   26650,   36317,    1670,     177,     435,     949])),\n",
       " (2,\n",
       "  tensor([     78,     124,    7860,       5,    6044,     198,       4,   17139,\n",
       "               27,   36218,       5,      45,     469,      14,     138,      15,\n",
       "              138,      16, 1197667,      61,      78,     124,       4,   31767,\n",
       "             2540,       9,   43425,   25199,       4,    6060,       6,      27,\n",
       "              489,   36218,    5810,     127,     403,     226,       3,      45,\n",
       "              532,     726,       2,     240,   60413,   65219,  104402,  107151,\n",
       "            10156,   48457, 1048623,  262618,  400118,    5800,    4956,   28355,\n",
       "              279,     280,     388,     386,  501493, 1197668,    7397,     240,\n",
       "             3497,   66207, 1235874,   50427,  317844, 1176539,  473765,  216053,\n",
       "            45249,     151,   64260,  745331,  949223,  325090,    4774,   26987,\n",
       "             1139,     243,    8436,    7063,    6238])),\n",
       " (2,\n",
       "  tensor([    206,     208,      53,       4,      55,     479,      94,    3464,\n",
       "               14,      32,      15,      32,      16,     206,    1060,    1902,\n",
       "              379,      11,  800978,    7992,     479,    3464,      12,       3,\n",
       "               94,      21,      78,     124,    3501,     476,     619,  528552,\n",
       "              965,       4,   39403,       6,    2350,     996,      34,     239,\n",
       "           935798,      85,       2,      14,    1141,       2,     495,      15,\n",
       "            11722,   15152,    3178,     118,  231225,  975243,  480985,  131178,\n",
       "               43,      44,     144,     145,    6425,   18789,   63098,   12156,\n",
       "             4606, 1004868,  800979, 1171655,   60005,  396069,      60,    1011,\n",
       "             6986,    2339,     240,   15238,   70524, 1028775,  482706,  528553,\n",
       "             6084,   51256,  101340,   15096,  269456,   27804,   73786,  688832,\n",
       "           935799,      89,     384,   57662,   24791,     932,   17728])),\n",
       " (2,\n",
       "  tensor([  1018,   1675,    582,      8,    415,    113,     14,     36,     15,\n",
       "              36,     16,   2612,      7,      3,    542,     17,     10,   1118,\n",
       "            1018,    172,   3234,   1675,    582,     28,    619,    142,      2,\n",
       "            1049,    189,      8,      3,    415,    113,      5,    619, 534560,\n",
       "               2,  21905,  14818,      4,      3,   1072,     72,   4880,     31,\n",
       "              81,      2, 100737,  98628,   9912,  18657,  15704,  19999,     62,\n",
       "              63,     71,     70,  85239,  16664,     29,    841,   2275,     23,\n",
       "           41434,  91602,  81876,  89964,   8199,  98628,  18613,  37184,   7399,\n",
       "             765,   5717,  77916,   1917,     26,    744,  15704,   4456,   9650,\n",
       "          482769, 534561,  77817, 535975, 288294,     42,  18426,  32381,  72988,\n",
       "           47073,   1132,    549])),\n",
       " (2,\n",
       "  tensor([   1900,    1714,     684,   44443,      48,    2013,      14,    3315,\n",
       "                2,     232,      15,    3315,       2,     232,      16,    1118,\n",
       "              169,   12060,     150,       6,    3972,       8,    1709,       4,\n",
       "                9,      27,     763,      12,    3794,    2462,     582,      92,\n",
       "              113,       4,       3,     133,      31,      81,       4,   15691,\n",
       "                3,     469,      24,    4021,      34,       6,  131682,    6254,\n",
       "                2,  360219,  957280, 1143380,  350974,  266796,  190595,    6596,\n",
       "             3316,     277,     928,    6636,    3316,     277,    1182,  141294,\n",
       "             3592,  438165,   22995,   17293,    5686,  146000,    3246,    7586,\n",
       "              108,    4936,   39342,   17008,   22055,   29322,  108286,   40674,\n",
       "              605,     976,      42,     742,    3807,    1132,     820,   31877,\n",
       "            99516,    1877,    9292,   68651,  380346,     613,  309262,  401039,\n",
       "            45492])),\n",
       " (2,\n",
       "  tensor([   1456,     602,      14,    4054,       2,     232,      15,    4054,\n",
       "                2,     232,      16,      40,   22024,       6,  420149,       2,\n",
       "             1224,       2,       8, 1155430,       4,    8786,  614302,   23842,\n",
       "             1797,       5,     503,      21,       3,     451,     701,      22,\n",
       "                6,    1832,     796,    5847,     436,      22,      35,    1308,\n",
       "             2127,    9247,       7,     619,    3643,       4,     219,       2,\n",
       "             1002,      40,       4,       6,     550,   69660,    4668,      28,\n",
       "               38,   18226,       5,     902,     147,  642157,      91,    1037,\n",
       "             2462,    1370,     341,      38,   22528,       2,      55,       4,\n",
       "               22,    4905,       4,    1879,    1037,      41,       3,  245967,\n",
       "             2827,      34,    1807,    4949,       4,     112,   23842,       2,\n",
       "            83196,  406394,   10956,    5498,     277,     928,   10957,    5498,\n",
       "              277,    1182,    5524,  173711,   87887,  544978,  420150,   11482,\n",
       "             3100,    1107,  864884, 1155431,   85118,  710639,  614303, 1100087,\n",
       "            20363,    2527,   28884,     194,   12465,    6090,   49951,     446,\n",
       "            21914,  684789,    6672,  356699,  127453,    3228,   13757,  583197,\n",
       "           176942,  102821,   20271,  120361,   13387,     223,   10964,   71661,\n",
       "            38040,  143313,      87,   17265,  127414, 1041355,  136947,    5022,\n",
       "           153035,  722611,    6727,  149512,  998456,  642158,  310432,  252583,\n",
       "           622234,   78794,   25784,  153040,  110408,     694,   20536,    1792,\n",
       "           322176,   94783,   85105,  649707,  874340,    1326,  284635,  367875,\n",
       "           285881,  111292,  132111,   59921,    1391, 1121846,  434103])),\n",
       " (2,\n",
       "  tensor([   572,    564,      2,   2326,  49106,    150,     88,      3,   1143,\n",
       "              27,     96,     14,     32,     15,     16, 443749,      4,    572,\n",
       "             499,     17,     10,  29160,   5488,      7, 468770,      4,     52,\n",
       "            7019,   1050,    442,      2,  14341,    673, 141447, 326092,  55044,\n",
       "            7887,    411,   9870, 628732,     97,    276,     43,     44,     46,\n",
       "          299709, 443750,  51274,    703,  14312,     23, 275050, 741752,  29990,\n",
       "          411508, 468771,   3779,  86384, 135944, 371666,   4052]))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_verif = []\n",
    "data_verif = test_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_verif_train = []\n",
    "data_verif_train = train_dataset\n",
    "data_verif_tr_len = len(data_verif_train)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'showingTelling.xlsx', 'showingTelling_csv.csv']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./data')\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kimkwangil/Project/01EssayFitAI/showing_telling'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
       "            1143,      14,      32,      15,      32,      16,  443749,       4,\n",
       "             572,     499,      17,      10,  741769,       7,  468770,       4,\n",
       "              52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
       "          326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
       "             144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
       "         1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
       "            4052]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.datasets.text_classification.TextClassificationDataset"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308844"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUN_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 25 seconds\n",
      "\tLoss: 0.0260(train)\t|\tAcc: 84.8%(train)\n",
      "\tLoss: 0.0001(valid)\t|\tAcc: 90.5%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0118(train)\t|\tAcc: 93.7%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 89.3%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0068(train)\t|\tAcc: 96.4%(train)\n",
      "\tLoss: 0.0001(valid)\t|\tAcc: 90.6%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 25 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 98.2%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 90.8%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0022(train)\t|\tAcc: 99.1%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 91.3%(valid)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0002(test)\t|\tAcc: 89.3%(test)\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "ag_news_label = {1 : \"World\",\n",
    "                 2 : \"Sports\",\n",
    "                 3 : \"Business\",\n",
    "                 4 : \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, model, vocab, ngrams):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
