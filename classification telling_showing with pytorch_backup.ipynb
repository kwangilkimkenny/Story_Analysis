{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification showing and telling with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John was sad to see his girlfriend leave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The house was creepy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I heard footsteps creeping behind me and it ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>She was my best friend. I could tell her almos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>She hated it there because it smelled bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "      <td>Her hand reached for the massive, iron door ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2</td>\n",
       "      <td>The way the door decisively slammed behind her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>Dust coated every last surface. He ran his fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2</td>\n",
       "      <td>The lime green patio umbrella flapped happily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2</td>\n",
       "      <td>\"And after all the weather was ideal. They cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "index                                                          \n",
       "0          1          John was sad to see his girlfriend leave.\n",
       "1          1                              The house was creepy.\n",
       "2          1  I heard footsteps creeping behind me and it ma...\n",
       "3          1  She was my best friend. I could tell her almos...\n",
       "4          1         She hated it there because it smelled bad.\n",
       "...      ...                                                ...\n",
       "254        2  Her hand reached for the massive, iron door ha...\n",
       "255        2  The way the door decisively slammed behind her...\n",
       "256        2  Dust coated every last surface. He ran his fin...\n",
       "257        2  The lime green patio umbrella flapped happily ...\n",
       "258        2  \"And after all the weather was ideal. They cou...\n",
       "\n",
       "[259 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/showingTelling_csv.csv', delimiter = ',', encoding=\"ISO-8859-1\")\n",
    "\n",
    "data.index.name = \"index\"\n",
    "data.columns = [\"label\", \"text\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "def shuffle(df, n=1, axis=0): #데이터가 1111 0000이라 잘 섞어주자. \n",
    "    df = data.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "    return df\n",
    "\n",
    "shuffle(data)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>Molly is a wonderful person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>\"I don't see why he needs an ax,\" continued Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>The crowd boiled like a simmering cauldron. Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2</td>\n",
       "      <td>From behind came the pounding of hoofbeats. Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>I was really mad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "index                                                          \n",
       "59         1                       Molly is a wonderful person.\n",
       "162        2  \"I don't see why he needs an ax,\" continued Fe...\n",
       "219        2  The crowd boiled like a simmering cauldron. Wh...\n",
       "211        2  From behind came the pounding of hoofbeats. Tr...\n",
       "64         1                                  I was really mad."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # 잘 섞였군! 하지만 데이터 클린징이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>It was an unusual cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>She felt embarrassed when she fell.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>She wore coveralls carried a plunger and metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>The little girl pressed so close to the window...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2</td>\n",
       "      <td>Jay waited the whole day to go to reading clas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "index                                                          \n",
       "54         1                             It was an unusual cat.\n",
       "30         1                She felt embarrassed when she fell.\n",
       "119        2  She wore coveralls carried a plunger and metal...\n",
       "137        2  The little girl pressed so close to the window...\n",
       "204        2  Jay waited the whole day to go to reading clas..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, remove_stopwords=False):\n",
    "        \n",
    "    # 영어가 아닌 특수문자들을 공백(\" \")으로 바꾸기\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "\n",
    "    # 대문자들을 소문자로 바꾸고 공백단위로 텍스트들 나눠서 리스트로 만든다.\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    if remove_stopwords: \n",
    "        # 불용어들을 제거\n",
    "    \n",
    "        #영어에 관련된 불용어 불러오기\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        # 불용어가 아닌 단어들로 이루어진 새로운 리스트 생성\n",
    "        words = [w for w in words if not w in stops]\n",
    "        # 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\n",
    "        clean_review = ' '.join(words)\n",
    "\n",
    "    else: # 불용어 제거하지 않을 때\n",
    "        clean_review = ' '.join(words)\n",
    "\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'molly wonderful person'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_ = []\n",
    "for review in train['text']:\n",
    "    clean_train_.append(preprocessing(review, remove_stopwords=True))\n",
    "\n",
    "# 전처리된 데이터 확인. 잘됨 !! ㅎ\n",
    "clean_train_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['molly wonderful person',\n",
       " 'see needs ax continued fern eight',\n",
       " 'crowd boiled like simmering cauldron guards ft looking people threw apple cores aimed well polished helmets yells curses cut air captain stepped forward hands spread',\n",
       " 'behind came pounding hoofbeats tree branches whipped across orias fs face showered saddle leaves gritted teeth face set snarl become protection unjust world would catch must catch',\n",
       " 'really mad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unusual cat'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_ = []\n",
    "for review in test['text']:\n",
    "    clean_test_.append(preprocessing(review, remove_stopwords=True))\n",
    "    \n",
    "# 전처리된 데이터 확인. 잘됨 !! ㅎ\n",
    "clean_test_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unusual cat',\n",
       " 'felt embarrassed fell',\n",
       " 'wore coveralls carried plunger metal toolbox wrenches various sizes hung leather belt around waist gpoint head h said',\n",
       " 'little girl pressed close window breath fogged glass',\n",
       " 'jay waited whole day go reading class always smiled got']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "59     1\n",
      "162    2\n",
      "219    2\n",
      "211    2\n",
      "64     1\n",
      "      ..\n",
      "139    2\n",
      "182    2\n",
      "167    2\n",
      "164    2\n",
      "143    2\n",
      "Name: label, Length: 206, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"label\"]) #showing telling 컬럼값을 확인해보고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>Molly is a wonderful person.</td>\n",
       "      <td>molly wonderful person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>\"I don't see why he needs an ax,\" continued Fe...</td>\n",
       "      <td>see needs ax continued fern eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>The crowd boiled like a simmering cauldron. Wh...</td>\n",
       "      <td>crowd boiled like simmering cauldron guards ft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2</td>\n",
       "      <td>From behind came the pounding of hoofbeats. Tr...</td>\n",
       "      <td>behind came pounding hoofbeats tree branches w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>I was really mad.</td>\n",
       "      <td>really mad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "index                                                             \n",
       "59         1                       Molly is a wonderful person.   \n",
       "162        2  \"I don't see why he needs an ax,\" continued Fe...   \n",
       "219        2  The crowd boiled like a simmering cauldron. Wh...   \n",
       "211        2  From behind came the pounding of hoofbeats. Tr...   \n",
       "64         1                                  I was really mad.   \n",
       "\n",
       "                                            cleaned_text  \n",
       "index                                                     \n",
       "59                                molly wonderful person  \n",
       "162                    see needs ax continued fern eight  \n",
       "219    crowd boiled like simmering cauldron guards ft...  \n",
       "211    behind came pounding hoofbeats tree branches w...  \n",
       "64                                            really mad  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleaned_text'] = clean_train_ # 이제 전처리된 내용을 한눈에 비교해 볼 수 있다.\n",
    "train[:5] #데이터 앞부분 5개반 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>It was an unusual cat.</td>\n",
       "      <td>unusual cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>She felt embarrassed when she fell.</td>\n",
       "      <td>felt embarrassed fell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>She wore coveralls carried a plunger and metal...</td>\n",
       "      <td>wore coveralls carried plunger metal toolbox w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>The little girl pressed so close to the window...</td>\n",
       "      <td>little girl pressed close window breath fogged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2</td>\n",
       "      <td>Jay waited the whole day to go to reading clas...</td>\n",
       "      <td>jay waited whole day go reading class always s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "index                                                             \n",
       "54         1                             It was an unusual cat.   \n",
       "30         1                She felt embarrassed when she fell.   \n",
       "119        2  She wore coveralls carried a plunger and metal...   \n",
       "137        2  The little girl pressed so close to the window...   \n",
       "204        2  Jay waited the whole day to go to reading clas...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "index                                                     \n",
       "54                                           unusual cat  \n",
       "30                                 felt embarrassed fell  \n",
       "119    wore coveralls carried plunger metal toolbox w...  \n",
       "137    little girl pressed close window breath fogged...  \n",
       "204    jay waited whole day go reading class always s...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['cleaned_text'] = clean_test_\n",
    "test[:5] #test 데이터셋도 전처리된 결과를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>molly wonderful person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>see needs ax continued fern eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>crowd boiled like simmering cauldron guards ft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2</td>\n",
       "      <td>behind came pounding hoofbeats tree branches w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>really mad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text\n",
       "index                                                          \n",
       "59         1                             molly wonderful person\n",
       "162        2                  see needs ax continued fern eight\n",
       "219        2  crowd boiled like simmering cauldron guards ft...\n",
       "211        2  behind came pounding hoofbeats tree branches w...\n",
       "64         1                                         really mad"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train[['label', 'cleaned_text']] #전처리 1차 끝!\n",
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>unusual cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>felt embarrassed fell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>wore coveralls carried plunger metal toolbox w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>little girl pressed close window breath fogged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2</td>\n",
       "      <td>jay waited whole day go reading class always s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text\n",
       "index                                                          \n",
       "54         1                                        unusual cat\n",
       "30         1                              felt embarrassed fell\n",
       "119        2  wore coveralls carried plunger metal toolbox w...\n",
       "137        2  little girl pressed close window breath fogged...\n",
       "204        2  jay waited whole day go reading class always s..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test[['label', 'cleaned_text']]  #전처리 1차 끝!\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_test = test_dataset.astype(str)\n",
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train = train_dataset.astype(str)\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset.values #train_dataset의 df를 numpy array로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_dataset.values #역시 이것도 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_dataset.dropna(inplace=True)\n",
    "test_dataset.dropna(inplace=True)\n",
    "\n",
    "train_dataset = train_dataset.sample(frac=1, random_state=999)\n",
    "test_dataset = test_dataset.sample(frac=1, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>lights sent signals village village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>looks glumly mess behind cupboard knowing fll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>night cold moonlit sleigh moved fast forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>crunching hit ears behind accelerating already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>suzie felt bench white cane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>awaken annoying buzz alarm clock anything read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2</td>\n",
       "      <td>town red brick brick would red smoke ashes all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>cynthia shrieked pulled wildly hair slammed do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2</td>\n",
       "      <td>sun set evening sky malcolm slowly turned walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>leg kept shaking turned head look clock every ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text\n",
       "index                                                          \n",
       "29         1                lights sent signals village village\n",
       "174        2  looks glumly mess behind cupboard knowing fll ...\n",
       "47         1        night cold moonlit sleigh moved fast forest\n",
       "112        2  crunching hit ears behind accelerating already...\n",
       "117        2                        suzie felt bench white cane\n",
       "...      ...                                                ...\n",
       "150        2  awaken annoying buzz alarm clock anything read...\n",
       "248        2  town red brick brick would red smoke ashes all...\n",
       "198        2  cynthia shrieked pulled wildly hair slammed do...\n",
       "228        2  sun set evening sky malcolm slowly turned walk...\n",
       "122        2  leg kept shaking turned head look clock every ...\n",
       "\n",
       "[206 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lights sent signals village village'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STdataset(Dataset):\n",
    "    '''showing telling dataset'''\n",
    "    def __init__(self, df): #데이터 전처리\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self): #데이터의 길이\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx): #데이터 1개를 가져오기\n",
    "        label = self.df.iloc[idx, 0]\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        return label, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_train_dataset = STdataset(train_dataset)\n",
    "train_loader = DataLoader(ST_train_dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.STdataset at 0x1a82e09d90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1a4ea49c90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch\n",
    "\n",
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split_with_sizes(): argument 'split_sizes' (position 1) must be tuple of ints, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ee5421ec641c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# encoding and zero padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mencoded_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpadded_list\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-ee5421ec641c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# encoding and zero padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mencoded_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpadded_list\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_tokens_single_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0madded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    628\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                             \u001b[0;32mand\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msub_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_token\u001b[0;34m(tok, text)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0msplit_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0msub_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: split_with_sizes(): argument 'split_sizes' (position 1) must be tuple of ints, not str"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 2\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model.eval()\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in eval_loader:\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    _, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이하 코드는 pytorch로 이진분류하려고 했으나 위 코드로 대체할거임, 위 코드가 BERT로 성능이 더 좋다는 뇌피셜! ㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('datasets/train_datasets.csv', index=False, header=False, sep=',')\n",
    "test_dataset.to_csv('datasets/test_datasets.csv', index=False, header=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 205\n",
      "테스트 샘플의 개수 : 51\n"
     ]
    }
   ],
   "source": [
    "from torchtext import data # torchtext.data 임포트\n",
    "\n",
    "# 필드 정의\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   is_target=True)\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=20)\n",
    "\n",
    "\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='datasets/', train='train_datasets.csv', test='test_datasets.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('text', TEXT)], skip_header=True)\n",
    "\n",
    "\n",
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))\n",
    "\n",
    "#ref: https://wikidocs.net/60314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '2', 'text': ['ekaterina', 'shocked', 'cold', 'fd', 'known', 'winters', 'never', 'far', 'north', 'never', 'deep', 'burrowed', 'furs', 'still', 'felt', 'eyelashes', 'freeze', 'crystals', 'ice', 'face', 'breath', 'frozen', 'solid', 'clear', 'night', 'raced', 'whispering', 'pines', 'like', 'feather', 'drawn', 'sheet', 'silver', 'seemed', 'magical', 'impossible', 'temporary', 'forbidden']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[2])) # text, label이 구분됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 1576\n",
      "Size of LABEL vocabulary: 3\n",
      "[('ft', 24), ('h', 17), ('fs', 16), ('like', 15), ('face', 13), ('never', 12), ('one', 12), ('felt', 11), ('could', 11), ('cold', 10)]\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1a3ece3790>>, {'<unk>': 0, '<pad>': 1, 'ft': 2, 'h': 3, 'fs': 4, 'like': 5, 'face': 6, 'never': 7, 'one': 8, 'could': 9, 'felt': 10, 'cold': 11, 'red': 12, 'would': 13, 'another': 14, 'behind': 15, 'day': 16, 'house': 17, 'long': 18, 'looked': 19, 'said': 20, 'stairs': 21, 'c': 22, 'came': 23, 'door': 24, 'every': 25, 'night': 26, 'old': 27, 'see': 28, 'sun': 29, 'time': 30, 'black': 31, 'blood': 32, 'glass': 33, 'got': 34, 'late': 35, 'made': 36, 'nervous': 37, 'people': 38, 'reached': 39, 'tree': 40, 'two': 41, 'walked': 42, 'went': 43, 'away': 44, 'bright': 45, 'dark': 46, 'darkness': 47, 'eyes': 48, 'far': 49, 'father': 50, 'first': 51, 'hand': 52, 'knew': 53, 'last': 54, 'little': 55, 'man': 56, 'mother': 57, 'room': 58, 'town': 59, 'us': 60, 'white': 61, 'wind': 62, 'arms': 63, 'back': 64, 'breath': 65, 'dress': 66, 'engine': 67, 'f': 68, 'filled': 69, 'front': 70, 'garden': 71, 'gi': 72, 'going': 73, 'green': 74, 'hair': 75, 'hands': 76, 'hot': 77, 'know': 78, 'left': 79, 'lights': 80, 'place': 81, 'river': 82, 'seemed': 83, 'small': 84, 'someone': 85, 'streets': 86, 'sweat': 87, 'though': 88, 'wall': 89, 'window': 90, 'yellow': 91, 'across': 92, 'afraid': 93, 'air': 94, 'already': 95, 'alvin': 96, 'anything': 97, 'around': 98, 'blue': 99, 'boat': 100, 'books': 101, 'cheek': 102, 'city': 103, 'clouds': 104, 'decorated': 105, 'dirty': 106, 'even': 107, 'fallen': 108, 'feet': 109, 'fern': 110, 'find': 111, 'give': 112, 'go': 113, 'head': 114, 'held': 115, 'horse': 116, 'kept': 117, 'lost': 118, 'making': 119, 'many': 120, 'mary': 121, 'meet': 122, 'metres': 123, 'milk': 124, 'must': 125, 'newspaper': 126, 'open': 127, 'pool': 128, 'public': 129, 'rain': 130, 'ran': 131, 'really': 132, 'sally': 133, 'saw': 134, 'seen': 135, 'show': 136, 'side': 137, 'slowly': 138, 'smoke': 139, 'stepped': 140, 'still': 141, 'stood': 142, 'table': 143, 'thought': 144, 'thoughts': 145, 'three': 146, 'tired': 147, 'took': 148, 'top': 149, 'toward': 150, 'weather': 151, 'well': 152, 'whole': 153, 'work': 154, 'always': 155, 'among': 156, 'angry': 157, 'anyone': 158, 'bar': 159, 'beautiful': 160, 'bit': 161, 'bite': 162, 'blair': 163, 'bottom': 164, 'branch': 165, 'brick': 166, 'broken': 167, 'burning': 168, 'busy': 169, 'castle': 170, 'catch': 171, 'cheerful': 172, 'cheese': 173, 'clara': 174, 'clear': 175, 'climbing': 176, 'close': 177, 'cut': 178, 'deep': 179, 'drew': 180, 'elroy': 181, 'enough': 182, 'fast': 183, 'favorite': 184, 'fish': 185, 'floor': 186, 'full': 187, 'get': 188, 'girl': 189, 'good': 190, 'gripped': 191, 'ground': 192, 'gyou': 193, 'hated': 194, 'heard': 195, 'heart': 196, 'hill': 197, 'hoofbeats': 198, 'hours': 199, 'houses': 200, 'ice': 201, 'inside': 202, 'james': 203, 'jim': 204, 'joey': 205, 'keep': 206, 'kill': 207, 'leaves': 208, 'let': 209, 'light': 210, 'london': 211, 'look': 212, 'looking': 213, 'looks': 214, 'love': 215, 'loved': 216, 'lucy': 217, 'luke': 218, 'met': 219, 'minutes': 220, 'mountains': 221, 'mouth': 222, 'mr': 223, 'name': 224, 'next': 225, 'noise': 226, 'oliver': 227, 'orias': 228, 'outside': 229, 'pale': 230, 'pepperoni': 231, 'reading': 232, 'right': 233, 'run': 234, 'running': 235, 'says': 236, 'sheet': 237, 'smell': 238, 'smelled': 239, 'sound': 240, 'spray': 241, 'spread': 242, 'standing': 243, 'steps': 244, 'sword': 245, 'take': 246, 'teeth': 247, 'tell': 248, 'thick': 249, 'threw': 250, 'thump': 251, 'today': 252, 'twenty': 253, 'veins': 254, 'village': 255, 'walls': 256, 'want': 257, 'war': 258, 'warm': 259, 'way': 260, 'women': 261, 'wooden': 262, 'worked': 263, 'worry': 264, 'abandoned': 265, 'ached': 266, 'aimed': 267, 'amy': 268, 'anna': 269, 'anxiously': 270, 'archie': 271, 'arrive': 272, 'asked': 273, 'attractive': 274, 'ax': 275, 'bad': 276, 'barely': 277, 'bathroom': 278, 'became': 279, 'began': 280, 'beneath': 281, 'bitter': 282, 'blond': 283, 'born': 284, 'bowen': 285, 'box': 286, 'breakfast': 287, 'bubbled': 288, 'bus': 289, 'canadian': 290, 'candles': 291, 'canopy': 292, 'carefully': 293, 'carl': 294, 'cars': 295, 'carts': 296, 'center': 297, 'chan': 298, 'chapel': 299, 'children': 300, 'chilled': 301, 'christmas': 302, 'church': 303, 'circus': 304, 'class': 305, 'cliff': 306, 'climbed': 307, 'clock': 308, 'closer': 309, 'clutched': 310, 'coffee': 311, 'complete': 312, 'creditors': 313, 'crow': 314, 'crowd': 315, 'crunched': 316, 'customers': 317, 'damp': 318, 'diagilo': 319, 'dog': 320, 'dominique': 321, 'downstairs': 322, 'dry': 323, 'dust': 324, 'ears': 325, 'eating': 326, 'empty': 327, 'end': 328, 'eyed': 329, 'fabric': 330, 'factories': 331, 'fall': 332, 'fd': 333, 'fear': 334, 'fell': 335, 'fence': 336, 'fifteen': 337, 'fingers': 338, 'fire': 339, 'five': 340, 'florentine': 341, 'fm': 342, 'foothold': 343, 'footsteps': 344, 'forced': 345, 'foreign': 346, 'found': 347, 'frost': 348, 'frozen': 349, 'gabilan': 350, 'gate': 351, 'gold': 352, 'grandfather': 353, 'grass': 354, 'great': 355, 'guards': 356, 'halls': 357, 'handle': 358, 'hard': 359, 'healthy': 360, 'heaps': 361, 'hear': 362, 'heave': 363, 'hem': 364, 'hockey': 365, 'hoghouse': 366, 'hug': 367, 'imagine': 368, 'impossible': 369, 'increased': 370, 'ink': 371, 'insurance': 372, 'iron': 373, 'jack': 374, 'jacket': 375, 'jay': 376, 'jews': 377, 'john': 378, 'katie': 379, 'kicked': 380, 'knight': 381, 'knowing': 382, 'knuckles': 383, 'letting': 384, 'library': 385, 'life': 386, 'lightning': 387, 'liked': 388, 'lit': 389, 'madam': 390, 'massive': 391, 'meat': 392, 'men': 393, 'michael': 394, 'might': 395, 'mind': 396, 'miss': 397, 'molly': 398, 'morning': 399, 'moving': 400, 'mozzarella': 401, 'mushrooms': 402, 'music': 403, 'needs': 404, 'north': 405, 'nothing': 406, 'nurse': 407, 'october': 408, 'ophelia': 409, 'orchestra': 410, 'others': 411, 'page': 412, 'palms': 413, 'pancake': 414, 'paper': 415, 'party': 416, 'passed': 417, 'past': 418, 'patio': 419, 'peaceful': 420, 'perfect': 421, 'person': 422, 'pictures': 423, 'pigs': 424, 'pine': 425, 'ping': 426, 'pizza': 427, 'playing': 428, 'pomfrey': 429, 'pong': 430, 'popped': 431, 'pretty': 432, 'purple': 433, 'put': 434, 'quickly': 435, 'raced': 436, 'rattling': 437, 'reach': 438, 'ready': 439, 'reflected': 440, 'release': 441, 'remember': 442, 'rifles': 443, 'ring': 444, 'roger': 445, 'rolling': 446, 'safety': 447, 'sauce': 448, 'sausage': 449, 'say': 450, 'school': 451, 'sea': 452, 'served': 453, 'sewers': 454, 'shadow': 455, 'shaking': 456, 'sharp': 457, 'sheer': 458, 'sheets': 459, 'shirt': 460, 'shops': 461, 'sighet': 462, 'silver': 463, 'since': 464, 'single': 465, 'sister': 466, 'sisters': 467, 'skin': 468, 'slammed': 469, 'smile': 470, 'smoking': 471, 'soldiers': 472, 'somehow': 473, 'sometimes': 474, 'sorority': 475, 'speak': 476, 'sports': 477, 'spreading': 478, 'spring': 479, 'squirrel': 480, 'stale': 481, 'steadily': 482, 'steam': 483, 'steep': 484, 'stomach': 485, 'storm': 486, 'straight': 487, 'straightened': 488, 'street': 489, 'stroke': 490, 'strokes': 491, 'strong': 492, 'stumbled': 493, 'summer': 494, 'sure': 495, 'susie': 496, 'suzie': 497, 'sweet': 498, 'taking': 499, 'taste': 500, 'temperature': 501, 'things': 502, 'think': 503, 'tiffany': 504, 'tim': 505, 'times': 506, 'tiny': 507, 'tomato': 508, 'touched': 509, 'trade': 510, 'train': 511, 'trembling': 512, 'trunk': 513, 'trying': 514, 'turned': 515, 'twisted': 516, 'used': 517, 'usual': 518, 'usurers': 519, 'vegetables': 520, 'voices': 521, 'waitress': 522, 'warmed': 523, 'watched': 524, 'water': 525, 'waters': 526, 'weak': 527, 'weight': 528, 'whipped': 529, 'wide': 530, 'windows': 531, 'without': 532, 'woman': 533, 'wood': 534, 'wrapped': 535, 'years': 536, 'young': 537, 'aaron': 538, 'acting': 539, 'active': 540, 'address': 541, 'afternoon': 542, 'afterward': 543, 'ago': 544, 'ahead': 545, 'aim': 546, 'alarm': 547, 'allowed': 548, 'almost': 549, 'alone': 550, 'also': 551, 'amid': 552, 'amount': 553, 'animal': 554, 'animals': 555, 'annoying': 556, 'anymore': 557, 'anytime': 558, 'appear': 559, 'appeared': 560, 'apple': 561, 'applying': 562, 'approached': 563, 'arable': 564, 'arrived': 565, 'ashes': 566, 'atop': 567, 'attention': 568, 'author': 569, 'autumn': 570, 'avoided': 571, 'awaken': 572, 'aware': 573, 'bachelor': 574, 'backpack': 575, 'bag': 576, 'baking': 577, 'bang': 578, 'banging': 579, 'barcel': 580, 'baskets': 581, 'beach': 582, 'beadle': 583, 'bearings': 584, 'beating': 585, 'become': 586, 'bedecked': 587, 'bench': 588, 'beside': 589, 'best': 590, 'better': 591, 'biting': 592, 'blackened': 593, 'blackout': 594, 'blank': 595, 'bleached': 596, 'blight': 597, 'blind': 598, 'blinding': 599, 'blinked': 600, 'bloodied': 601, 'blotting': 602, 'board': 603, 'boarded': 604, 'bodies': 605, 'body': 606, 'boiled': 607, 'bolts': 608, 'book': 609, 'boots': 610, 'boring': 611, 'bouncing': 612, 'bow': 613, 'boxes': 614, 'branches': 615, 'break': 616, 'breathe': 617, 'breathing': 618, 'breeze': 619, 'brenda': 620, 'bricks': 621, 'brighter': 622, 'brightly': 623, 'bring': 624, 'bringing': 625, 'broadsword': 626, 'brown': 627, 'brush': 628, 'brushed': 629, 'brushwood': 630, 'buck': 631, 'buckets': 632, 'bud': 633, 'buds': 634, 'building': 635, 'bulging': 636, 'bullied': 637, 'bunches': 638, 'burned': 639, 'burrowed': 640, 'bustle': 641, 'butterflies': 642, 'buzz': 643, 'cab': 644, 'calcium': 645, 'calle': 646, 'calm': 647, 'canal': 648, 'candle': 649, 'candy': 650, 'cane': 651, 'canuda': 652, 'cappuccino': 653, 'captain': 654, 'car': 655, 'carcasses': 656, 'cared': 657, 'carpenter': 658, 'carpet': 659, 'carriage': 660, 'carried': 661, 'carry': 662, 'carrying': 663, 'casserole': 664, 'cast': 665, 'cat': 666, 'cattle': 667, 'cauldron': 668, 'celebrated': 669, 'chaise': 670, 'champagne': 671, 'changed': 672, 'changing': 673, 'charming': 674, 'chased': 675, 'cheerfully': 676, 'chest': 677, 'child': 678, 'chill': 679, 'chocolate': 680, 'choked': 681, 'choking': 682, 'choppy': 683, 'cigarette': 684, 'clap': 685, 'classroom': 686, 'clatter': 687, 'clattering': 688, 'clean': 689, 'clearly': 690, 'click': 691, 'climb': 692, 'clipped': 693, 'cloth': 694, 'cloud': 695, 'clumps': 696, 'clung': 697, 'coated': 698, 'cobblestone': 699, 'cobblestones': 700, 'cocktail': 701, 'cocktails': 702, 'colds': 703, 'collect': 704, 'collection': 705, 'colorful': 706, 'colour': 707, 'come': 708, 'commander': 709, 'competes': 710, 'complaining': 711, 'concourse': 712, 'congealed': 713, 'connect': 714, 'considering': 715, 'consumed': 716, 'containers': 717, 'content': 718, 'continued': 719, 'conversation': 720, 'conveyance': 721, 'cookies': 722, 'cooking': 723, 'cores': 724, 'correct': 725, 'cottages': 726, 'county': 727, 'course': 728, 'covered': 729, 'covering': 730, 'covers': 731, 'crack': 732, 'crammed': 733, 'crashed': 734, 'crawled': 735, 'crawling': 736, 'crazy': 737, 'creaking': 738, 'creamy': 739, 'creature': 740, 'creek': 741, 'creeping': 742, 'creepy': 743, 'crepe': 744, 'cried': 745, 'crisscrossed': 746, 'crop': 747, 'crossed': 748, 'crossword': 749, 'crowded': 750, 'crumpling': 751, 'crying': 752, 'crystal': 753, 'crystals': 754, 'culinary': 755, 'cupboard': 756, 'cupboards': 757, 'curse': 758, 'curses': 759, 'cursing': 760, 'curtain': 761, 'dairy': 762, 'daisy': 763, 'dashed': 764, 'dave': 765, 'dawn': 766, 'dazzling': 767, 'dead': 768, 'dearly': 769, 'deathly': 770, 'debated': 771, 'decaying': 772, 'decent': 773, 'decide': 774, 'decided': 775, 'decisively': 776, 'degrees': 777, 'delicious': 778, 'demanding': 779, 'descended': 780, 'described': 781, 'desperately': 782, 'destroyed': 783, 'different': 784, 'diligently': 785, 'dim': 786, 'dimly': 787, 'ding': 788, 'dinner': 789, 'dirtier': 790, 'disappeared': 791, 'discerned': 792, 'discover': 793, 'distorted': 794, 'dividing': 795, 'doctor': 796, 'dodging': 797, 'donkey': 798, 'donuts': 799, 'doors': 800, 'downwards': 801, 'drag': 802, 'drawn': 803, 'drenched': 804, 'dressed': 805, 'dresser': 806, 'dressing': 807, 'drink': 808, 'drinker': 809, 'drive': 810, 'driver': 811, 'droppings': 812, 'drove': 813, 'ducked': 814, 'due': 815, 'dull': 816, 'dumb': 817, 'dung': 818, 'dusted': 819, 'dye': 820, 'ear': 821, 'early': 822, 'earth': 823, 'easily': 824, 'eastern': 825, 'eerily': 826, 'eevery': 827, 'effort': 828, 'eight': 829, 'ekaterina': 830, 'elected': 831, 'elephant': 832, 'eligible': 833, 'embrace': 834, 'embraced': 835, 'emily': 836, 'emitted': 837, 'encouragement': 838, 'energy': 839, 'eno': 840, 'entered': 841, 'entirely': 842, 'enveloped': 843, 'especially': 844, 'ethump': 845, 'everyone': 846, 'everything': 847, 'evinrude': 848, 'ewhat': 849, 'exhausted': 850, 'exhaustion': 851, 'expect': 852, 'expelled': 853, 'expensive': 854, 'explosion': 855, 'eyelashes': 856, 'faces': 857, 'faded': 858, 'faint': 859, 'faintly': 860, 'faithlessness': 861, 'familiar': 862, 'family': 863, 'fan': 864, 'feather': 865, 'feature': 866, 'feel': 867, 'feeling': 868, 'fetid': 869, 'fight': 870, 'figuring': 871, 'filmed': 872, 'filthy': 873, 'finger': 874, 'fingernail': 875, 'fiona': 876, 'fireplace': 877, 'fishing': 878, 'fishtail': 879, 'flame': 880, 'flames': 881, 'flapped': 882, 'flares': 883, 'flat': 884, 'flattened': 885, 'flesh': 886, 'flew': 887, 'flickered': 888, 'fll': 889, 'floating': 890, 'flooding': 891, 'flowers': 892, 'flowing': 893, 'flying': 894, 'fog': 895, 'fogged': 896, 'foggy': 897, 'folded': 898, 'food': 899, 'forbidden': 900, 'forehead': 901, 'foreigner': 902, 'forest': 903, 'form': 904, 'formed': 905, 'forward': 906, 'fought': 907, 'four': 908, 'frames': 909, 'freeze': 910, 'friend': 911, 'frightened': 912, 'frothy': 913, 'fully': 914, 'fur': 915, 'furs': 916, 'fury': 917, 'fve': 918, 'gardener': 919, 'gardens': 920, 'garlands': 921, 'gas': 922, 'gave': 923, 'gdarlene': 924, 'general': 925, 'gents': 926, 'georgie': 927, 'getting': 928, 'gget': 929, 'ggood': 930, 'gholy': 931, 'gibson': 932, 'ginny': 933, 'girlfriend': 934, 'girls': 935, 'given': 936, 'gives': 937, 'giving': 938, 'glances': 939, 'glet': 940, 'glistened': 941, 'glow': 942, 'glowing': 943, 'glumly': 944, 'glutinous': 945, 'gnice': 946, 'gnot': 947, 'gotten': 948, 'grabbed': 949, 'grabbing': 950, 'graceful': 951, 'graciously': 952, 'gradually': 953, 'gravity': 954, 'gray': 955, 'grimace': 956, 'gritted': 957, 'gritty': 958, 'grizzly': 959, 'grounds': 960, 'groups': 961, 'grow': 962, 'gslice': 963, 'gstop': 964, 'guessed': 965, 'guessing': 966, 'gun': 967, 'gushed': 968, 'gutters': 969, 'hail': 970, 'half': 971, 'halted': 972, 'hammering': 973, 'hanging': 974, 'hansom': 975, 'happily': 976, 'harsh': 977, 'haunted': 978, 'haze': 979, 'heads': 980, 'hearing': 981, 'heaven': 982, 'heavy': 983, 'helmets': 984, 'help': 985, 'high': 986, 'higher': 987, 'hills': 988, 'hilltops': 989, 'hinges': 990, 'hit': 991, 'holt': 992, 'home': 993, 'homework': 994, 'horizon': 995, 'horsepower': 996, 'horses': 997, 'huddled': 998, 'humid': 999, 'hung': 1000, 'hungarian': 1001, 'hungry': 1002, 'hunk': 1003, 'hurled': 1004, 'hurried': 1005, 'hurry': 1006, 'ideal': 1007, 'ignited': 1008, 'ill': 1009, 'immediately': 1010, 'impenetrable': 1011, 'impregnated': 1012, 'impression': 1013, 'incorrect': 1014, 'increasing': 1015, 'ing': 1016, 'ingredient': 1017, 'inhale': 1018, 'instantly': 1019, 'instead': 1020, 'intensity': 1021, 'interrupted': 1022, 'invisible': 1023, 'iona': 1024, 'ireland': 1025, 'isolated': 1026, 'itched': 1027, 'job': 1028, 'joy': 1029, 'julain': 1030, 'juli': 1031, 'jump': 1032, 'jumped': 1033, 'junkyard': 1034, 'key': 1035, 'kind': 1036, 'kindergarten': 1037, 'kinds': 1038, 'kiosk': 1039, 'kitchen': 1040, 'kitchenware': 1041, 'knowledge': 1042, 'known': 1043, 'labourers': 1044, 'laden': 1045, 'lady': 1046, 'languages': 1047, 'latin': 1048, 'lawns': 1049, 'lay': 1050, 'layered': 1051, 'layers': 1052, 'leaden': 1053, 'leaned': 1054, 'leapt': 1055, 'leather': 1056, 'leave': 1057, 'leaving': 1058, 'leg': 1059, 'lemonade': 1060, 'lifetime': 1061, 'lift': 1062, 'lifting': 1063, 'lifts': 1064, 'lighting': 1065, 'lightly': 1066, 'lime': 1067, 'lip': 1068, 'lives': 1069, 'livestock': 1070, 'living': 1071, 'locking': 1072, 'lonely': 1073, 'lookin': 1074, 'lots': 1075, 'loud': 1076, 'low': 1077, 'lower': 1078, 'lurches': 1079, 'luscious': 1080, 'lying': 1081, 'machines': 1082, 'mactalde': 1083, 'madness': 1084, 'magical': 1085, 'make': 1086, 'managed': 1087, 'manner': 1088, 'matters': 1089, 'may': 1090, 'mayor': 1091, 'meal': 1092, 'mean': 1093, 'medicine': 1094, 'medieval': 1095, 'melancholy': 1096, 'melted': 1097, 'merchants': 1098, 'mess': 1099, 'metal': 1100, 'metallic': 1101, 'middle': 1102, 'mike': 1103, 'mince': 1104, 'mine': 1105, 'minute': 1106, 'misbehaving': 1107, 'missed': 1108, 'missing': 1109, 'moishe': 1110, 'moment': 1111, 'monotonously': 1112, 'moon': 1113, 'mornings': 1114, 'moths': 1115, 'mottled': 1116, 'mounted': 1117, 'moved': 1118, 'movement': 1119, 'movements': 1120, 'mowing': 1121, 'mrs': 1122, 'much': 1123, 'muddy': 1124, 'muscles': 1125, 'n': 1126, 'nale': 1127, 'named': 1128, 'narrow': 1129, 'narrowing': 1130, 'navigated': 1131, 'nearer': 1132, 'needed': 1133, 'neighborhood': 1134, 'new': 1135, 'noises': 1136, 'nose': 1137, 'nostrils': 1138, 'note': 1139, 'notion': 1140, 'oath': 1141, 'occured': 1142, 'ocean': 1143, 'odours': 1144, 'offer': 1145, 'ones': 1146, 'onto': 1147, 'oooh': 1148, 'opaque': 1149, 'opera': 1150, 'opponent': 1151, 'ordered': 1152, 'ordinary': 1153, 'outboard': 1154, 'outfits': 1155, 'outline': 1156, 'outward': 1157, 'outwards': 1158, 'overnight': 1159, 'overran': 1160, 'owl': 1161, 'oyster': 1162, 'packed': 1163, 'pails': 1164, 'pain': 1165, 'palm': 1166, 'pancakes': 1167, 'pans': 1168, 'papa': 1169, 'parked': 1170, 'part': 1171, 'passionate': 1172, 'patch': 1173, 'path': 1174, 'pavements': 1175, 'pay': 1176, 'peace': 1177, 'pedestrian': 1178, 'pedestrians': 1179, 'peeled': 1180, 'pepperup': 1181, 'perched': 1182, 'percy': 1183, 'permeate': 1184, 'piccadilly': 1185, 'picking': 1186, 'pies': 1187, 'pig': 1188, 'piled': 1189, 'piles': 1190, 'pillow': 1191, 'pines': 1192, 'pink': 1193, 'piss': 1194, 'piston': 1195, 'pitcher': 1196, 'pitches': 1197, 'places': 1198, 'plane': 1199, 'planned': 1200, 'plants': 1201, 'platform': 1202, 'players': 1203, 'pleasant': 1204, 'plumber': 1205, 'plush': 1206, 'point': 1207, 'pointed': 1208, 'police': 1209, 'polished': 1210, 'polluted': 1211, 'poppies': 1212, 'potion': 1213, 'pots': 1214, 'pounded': 1215, 'pounding': 1216, 'poured': 1217, 'pouring': 1218, 'powder': 1219, 'preferred': 1220, 'presents': 1221, 'pressed': 1222, 'products': 1223, 'progress': 1224, 'promise': 1225, 'prosper': 1226, 'protection': 1227, 'protein': 1228, 'provolone': 1229, 'puck': 1230, 'pull': 1231, 'pulled': 1232, 'pulling': 1233, 'pulsing': 1234, 'puppy': 1235, 'purplish': 1236, 'puzzle': 1237, 'quick': 1238, 'race': 1239, 'rapid': 1240, 'rattled': 1241, 'rays': 1242, 'razor': 1243, 'read': 1244, 'readers': 1245, 'realized': 1246, 'reason': 1247, 'reef': 1248, 'reflexes': 1249, 'refuge': 1250, 'regent': 1251, 'regret': 1252, 'relief': 1253, 'remaining': 1254, 'remove': 1255, 'replied': 1256, 'restaurant': 1257, 'return': 1258, 'revolted': 1259, 'ribbons': 1260, 'riding': 1261, 'rising': 1262, 'rivers': 1263, 'riveted': 1264, 'roar': 1265, 'roared': 1266, 'rock': 1267, 'rolled': 1268, 'romantic': 1269, 'roof': 1270, 'roofs': 1271, 'rooms': 1272, 'rose': 1273, 'rosettes': 1274, 'rosy': 1275, 'rotting': 1276, 'rough': 1277, 'round': 1278, 'rounds': 1279, 'rows': 1280, 'rubble': 1281, 'rump': 1282, 'runt': 1283, 'rushing': 1284, 'ruzz': 1285, 'sad': 1286, 'saddle': 1287, 'salina': 1288, 'salinas': 1289, 'sapphire': 1290, 'scared': 1291, 'scarier': 1292, 'scaring': 1293, 'scattered': 1294, 'scent': 1295, 'scrabbling': 1296, 'scramble': 1297, 'scrambled': 1298, 'screamed': 1299, 'screaming': 1300, 'screech': 1301, 'screen': 1302, 'scribbled': 1303, 'seat': 1304, 'second': 1305, 'seconds': 1306, 'secretive': 1307, 'seeing': 1308, 'seem': 1309, 'selling': 1310, 'send': 1311, 'sent': 1312, 'sentence': 1313, 'set': 1314, 'setting': 1315, 'several': 1316, 'sex': 1317, 'shade': 1318, 'shadows': 1319, 'shake': 1320, 'sharpening': 1321, 'sharply': 1322, 'shattered': 1323, 'sheathed': 1324, 'shelves': 1325, 'shifted': 1326, 'shine': 1327, 'shit': 1328, 'shivering': 1329, 'shocked': 1330, 'shook': 1331, 'shore': 1332, 'shoreditch': 1333, 'shout': 1334, 'shouted': 1335, 'shower': 1336, 'showered': 1337, 'shrieked': 1338, 'shroud': 1339, 'shuf': 1340, 'shuzz': 1341, 'sick': 1342, 'sides': 1343, 'sidewalks': 1344, 'sifted': 1345, 'sigh': 1346, 'sighed': 1347, 'sighing': 1348, 'signals': 1349, 'silenced': 1350, 'silently': 1351, 'simmering': 1352, 'simple': 1353, 'sir': 1354, 'situation': 1355, 'skies': 1356, 'sky': 1357, 'slack': 1358, 'slam': 1359, 'slapping': 1360, 'slash': 1361, 'sleepy': 1362, 'slept': 1363, 'slice': 1364, 'slick': 1365, 'slip': 1366, 'slopes': 1367, 'slow': 1368, 'slowed': 1369, 'slushies': 1370, 'smaller': 1371, 'smallest': 1372, 'smelling': 1373, 'smiled': 1374, 'smiles': 1375, 'smithfield': 1376, 'smooth': 1377, 'snarl': 1378, 'snuffed': 1379, 'sold': 1380, 'sole': 1381, 'solid': 1382, 'something': 1383, 'somewhere': 1384, 'soon': 1385, 'sorting': 1386, 'soul': 1387, 'spaces': 1388, 'span': 1389, 'spans': 1390, 'spat': 1391, 'spate': 1392, 'speech': 1393, 'speed': 1394, 'spilled': 1395, 'spilling': 1396, 'spit': 1397, 'splinter': 1398, 'sport': 1399, 'spurred': 1400, 'squaked': 1401, 'square': 1402, 'squinting': 1403, 'stacks': 1404, 'staff': 1405, 'stained': 1406, 'stains': 1407, 'staircase': 1408, 'staleness': 1409, 'stand': 1410, 'stands': 1411, 'stars': 1412, 'starts': 1413, 'state': 1414, 'station': 1415, 'stay': 1416, 'steady': 1417, 'steeds': 1418, 'step': 1419, 'stirred': 1420, 'stock': 1421, 'stone': 1422, 'stop': 1423, 'stories': 1424, 'story': 1425, 'straggling': 1426, 'strawberry': 1427, 'streamers': 1428, 'streetlamps': 1429, 'struggled': 1430, 'studded': 1431, 'students': 1432, 'stuffed': 1433, 'subject': 1434, 'suburbs': 1435, 'sucked': 1436, 'sudden': 1437, 'suddenly': 1438, 'sugar': 1439, 'sunny': 1440, 'sunshine': 1441, 'supplies': 1442, 'surface': 1443, 'surpassed': 1444, 'surprised': 1445, 'surrender': 1446, 'sweaty': 1447, 'sweeping': 1448, 'swelled': 1449, 'swimmers': 1450, 'swipes': 1451, 'switched': 1452, 'sycamores': 1453, 'tables': 1454, 'taken': 1455, 'talented': 1456, 'tall': 1457, 'taller': 1458, 'talons': 1459, 'tapped': 1460, 'tasted': 1461, 'tears': 1462, 'temporary': 1463, 'ten': 1464, 'tensed': 1465, 'terms': 1466, 'terribly': 1467, 'text': 1468, 'thatched': 1469, 'thickly': 1470, 'thin': 1471, 'thing': 1472, 'threaded': 1473, 'throat': 1474, 'throttle': 1475, 'thunder': 1476, 'thundered': 1477, 'tiger': 1478, 'tighten': 1479, 'tin': 1480, 'tissue': 1481, 'tobacco': 1482, 'toilet': 1483, 'told': 1484, 'tom': 1485, 'tonight': 1486, 'tools': 1487, 'tossed': 1488, 'tough': 1489, 'traffic': 1490, 'treats': 1491, 'trees': 1492, 'trembled': 1493, 'tried': 1494, 'troubled': 1495, 'trudging': 1496, 'truly': 1497, 'tuning': 1498, 'turbulent': 1499, 'turning': 1500, 'tweed': 1501, 'twinkling': 1502, 'ugly': 1503, 'umbrella': 1504, 'unattached': 1505, 'unbroken': 1506, 'unclosed': 1507, 'unjust': 1508, 'unnatural': 1509, 'unsuccessful': 1510, 'upcoming': 1511, 'upon': 1512, 'upper': 1513, 'upstream': 1514, 'valley': 1515, 'various': 1516, 'vast': 1517, 'vehicle': 1518, 'veiled': 1519, 'vellum': 1520, 'vest': 1521, 'vigorously': 1522, 'vitamins': 1523, 'vivid': 1524, 'wafers': 1525, 'waft': 1526, 'waited': 1527, 'waiting': 1528, 'walk': 1529, 'walks': 1530, 'wanted': 1531, 'warmth': 1532, 'wash': 1533, 'watch': 1534, 'watching': 1535, 'watermelon': 1536, 'waves': 1537, 'wearin': 1538, 'wearing': 1539, 'weasley': 1540, 'wedding': 1541, 'weightlifting': 1542, 'welsh': 1543, 'west': 1544, 'whether': 1545, 'whispering': 1546, 'whisperings': 1547, 'wife': 1548, 'wild': 1549, 'willed': 1550, 'wilting': 1551, 'windless': 1552, 'winged': 1553, 'wings': 1554, 'winters': 1555, 'wipe': 1556, 'wiped': 1557, 'wished': 1558, 'woke': 1559, 'wondered': 1560, 'wonderful': 1561, 'working': 1562, 'world': 1563, 'wretched': 1564, 'wrist': 1565, 'writing': 1566, 'yard': 1567, 'yards': 1568, 'yawned': 1569, 'year': 1570, 'yelled': 1571, 'yells': 1572, 'yogurt': 1573, 'york': 1574, 'yowl': 1575})\n"
     ]
    }
   ],
   "source": [
    " #단어장 생성\n",
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "\n",
    "#단어장 생성 확인\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "print(TEXT.vocab.stoi)   \n",
    "\n",
    "\n",
    "#ref :::::: https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('label', <torchtext.data.field.Field object at 0x1a3ecc2250>), ('text', <torchtext.data.field.Field object at 0x1a3ecb5510>)])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.fields.items()) # tex, label 로 구분되어 있는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#check whether cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "#set batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#Load an iterator\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cd70eb4abc5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEMBED_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNUN_CLASS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUN_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(train_data.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_data.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-355035372515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparameters\n",
    "size_of_vocab = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "num_hidden_nodes = 32\n",
    "num_output_nodes = 1\n",
    "num_layers = 2\n",
    "bidirection = True\n",
    "dropout = 0.2\n",
    "\n",
    "#instantiate the model\n",
    "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
    "                   bidirectional = True, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(1581, 100)\n",
      "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#architecture\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 217,557 trainable parameters\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "copy_(): argument 'other' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a0e1e7d28dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Initialize the pretrained embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpretrained_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: copy_(): argument 'other' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "#No. of trianable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('label', <torchtext.data.field.Field object at 0x1a4ae03490>), ('text', <torchtext.data.field.Field object at 0x1a4ae034d0>)])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.fields.items()) # label, text가 각각 잘 구분되어 플드에 저작외었다. 이것을 이제 모델이 처 넣으면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=1, max_size=10000) #보캐브러리를 빌드한다. 그런데 왜하는겨?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 1542\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab))) #여기에 사용한 다어는 이많큼이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1a4ae032d0>>, {'<unk>': 0, '<pad>': 1, 'ft': 2, 'h': 3, 'fs': 4, 'could': 5, 'like': 6, 'behind': 7, 'one': 8, 'cold': 9, 'door': 10, 'face': 11, 'long': 12, 'looked': 13, 'see': 14, 'felt': 15, 'garden': 16, 'never': 17, 'said': 18, 'black': 19, 'c': 20, 'first': 21, 'hands': 22, 'night': 23, 'sun': 24, 'time': 25, 'day': 26, 'eyes': 27, 'front': 28, 'got': 29, 'hand': 30, 'late': 31, 'little': 32, 'stairs': 33, 'walked': 34, 'would': 35, 'back': 36, 'blood': 37, 'breath': 38, 'came': 39, 'every': 40, 'f': 41, 'far': 42, 'father': 43, 'house': 44, 'knew': 45, 'light': 46, 'made': 47, 'man': 48, 'nervous': 49, 'old': 50, 'reached': 51, 'red': 52, 'saw': 53, 'sweat': 54, 'tree': 55, 'two': 56, 'us': 57, 'village': 58, 'wind': 59, 'window': 60, 'already': 61, 'another': 62, 'away': 63, 'beautiful': 64, 'clouds': 65, 'dark': 66, 'darkness': 67, 'engine': 68, 'feet': 69, 'give': 70, 'glass': 71, 'go': 72, 'hair': 73, 'head': 74, 'held': 75, 'hot': 76, 'james': 77, 'last': 78, 'left': 79, 'lights': 80, 'lost': 81, 'mother': 82, 'page': 83, 'rain': 84, 'room': 85, 'seemed': 86, 'smell': 87, 'someone': 88, 'still': 89, 'stood': 90, 'streets': 91, 'took': 92, 'town': 93, 'wall': 94, 'walls': 95, 'weather': 96, 'went': 97, 'white': 98, 'alvin': 99, 'angry': 100, 'arms': 101, 'around': 102, 'boat': 103, 'bright': 104, 'cheek': 105, 'city': 106, 'dirty': 107, 'dress': 108, 'even': 109, 'fallen': 110, 'find': 111, 'five': 112, 'floor': 113, 'get': 114, 'gi': 115, 'good': 116, 'jim': 117, 'joey': 118, 'leaves': 119, 'life': 120, 'making': 121, 'minutes': 122, 'mr': 123, 'newspaper': 124, 'open': 125, 'pool': 126, 'river': 127, 'second': 128, 'show': 129, 'side': 130, 'slammed': 131, 'slowly': 132, 'small': 133, 'smoke': 134, 'steps': 135, 'thought': 136, 'thoughts': 137, 'toward': 138, 'turned': 139, 'way': 140, 'across': 141, 'afraid': 142, 'always': 143, 'among': 144, 'anyone': 145, 'anything': 146, 'asked': 147, 'bad': 148, 'bar': 149, 'bite': 150, 'blair': 151, 'blue': 152, 'books': 153, 'bottom': 154, 'box': 155, 'brother': 156, 'busy': 157, 'carl': 158, 'castle': 159, 'catch': 160, 'cheerful': 161, 'clara': 162, 'clear': 163, 'close': 164, 'closer': 165, 'crunched': 166, 'damp': 167, 'deep': 168, 'drew': 169, 'dry': 170, 'ears': 171, 'elroy': 172, 'enough': 173, 'favorite': 174, 'fear': 175, 'fingers': 176, 'found': 177, 'full': 178, 'girl': 179, 'grass': 180, 'green': 181, 'gripped': 182, 'ground': 183, 'gyou': 184, 'hated': 185, 'hear': 186, 'heard': 187, 'heart': 188, 'high': 189, 'hit': 190, 'home': 191, 'hoofbeats': 192, 'horse': 193, 'hours': 194, 'ice': 195, 'jay': 196, 'katie': 197, 'keep': 198, 'kept': 199, 'know': 200, 'lonely': 201, 'look': 202, 'looking': 203, 'looks': 204, 'love': 205, 'luke': 206, 'many': 207, 'meet': 208, 'mike': 209, 'mountains': 210, 'mouth': 211, 'must': 212, 'orias': 213, 'outside': 214, 'pale': 215, 'party': 216, 'people': 217, 'pictures': 218, 'pizza': 219, 'place': 220, 'pulled': 221, 'ran': 222, 'reading': 223, 'remember': 224, 'right': 225, 'running': 226, 'sally': 227, 'says': 228, 'school': 229, 'seen': 230, 'set': 231, 'shadow': 232, 'shaking': 233, 'sheet': 234, 'sky': 235, 'smile': 236, 'sometimes': 237, 'spilled': 238, 'storm': 239, 'summer': 240, 'sword': 241, 'table': 242, 'tell': 243, 'thick': 244, 'things': 245, 'though': 246, 'three': 247, 'tired': 248, 'today': 249, 'trembling': 250, 'veins': 251, 'want': 252, 'war': 253, 'warm': 254, 'well': 255, 'whole': 256, 'wooden': 257, 'work': 258, 'worked': 259, 'worry': 260, 'year': 261, 'yellow': 262, 'afternoon': 263, 'air': 264, 'alone': 265, 'amy': 266, 'anna': 267, 'anxiously': 268, 'archie': 269, 'arrive': 270, 'author': 271, 'barely': 272, 'beach': 273, 'became': 274, 'belt': 275, 'beneath': 276, 'bit': 277, 'book': 278, 'born': 279, 'bowen': 280, 'branch': 281, 'breakfast': 282, 'brick': 283, 'burning': 284, 'bus': 285, 'canadian': 286, 'canopy': 287, 'carefully': 288, 'carried': 289, 'cat': 290, 'center': 291, 'chan': 292, 'chapter': 293, 'cheese': 294, 'chilled': 295, 'church': 296, 'circus': 297, 'class': 298, 'climbed': 299, 'climbing': 300, 'clock': 301, 'commander': 302, 'complete': 303, 'cut': 304, 'cynthia': 305, 'dazzling': 306, 'decorated': 307, 'delicious': 308, 'described': 309, 'dog': 310, 'downstairs': 311, 'dresser': 312, 'earth': 313, 'eating': 314, 'elected': 315, 'emily': 316, 'fall': 317, 'family': 318, 'fast': 319, 'fd': 320, 'fence': 321, 'fern': 322, 'fifteen': 323, 'filled': 324, 'fire': 325, 'fish': 326, 'flowers': 327, 'fm': 328, 'footsteps': 329, 'forehead': 330, 'forest': 331, 'frost': 332, 'gabilan': 333, 'gate': 334, 'gibson': 335, 'going': 336, 'grandfather': 337, 'handle': 338, 'hard': 339, 'healthy': 340, 'heave': 341, 'heavy': 342, 'hoghouse': 343, 'hug': 344, 'hung': 345, 'imagine': 346, 'impossible': 347, 'ink': 348, 'insurance': 349, 'iron': 350, 'isolated': 351, 'jack': 352, 'jacket': 353, 'kicked': 354, 'kill': 355, 'knowing': 356, 'knuckles': 357, 'languages': 358, 'leather': 359, 'leaving': 360, 'let': 361, 'letting': 362, 'lightning': 363, 'liked': 364, 'london': 365, 'loved': 366, 'lucy': 367, 'madam': 368, 'malcolm': 369, 'mary': 370, 'massive': 371, 'mayor': 372, 'met': 373, 'metal': 374, 'metres': 375, 'might': 376, 'milk': 377, 'mind': 378, 'miss': 379, 'molly': 380, 'morning': 381, 'moved': 382, 'music': 383, 'name': 384, 'needs': 385, 'next': 386, 'noise': 387, 'north': 388, 'nose': 389, 'nothing': 390, 'nurse': 391, 'ocean': 392, 'october': 393, 'oliver': 394, 'onto': 395, 'opened': 396, 'orchestra': 397, 'palms': 398, 'paper': 399, 'patio': 400, 'peace': 401, 'peaceful': 402, 'pepperoni': 403, 'perfect': 404, 'person': 405, 'pigs': 406, 'pine': 407, 'ping': 408, 'pomfrey': 409, 'pong': 410, 'popped': 411, 'pounding': 412, 'public': 413, 'puppy': 414, 'purple': 415, 'put': 416, 'quickly': 417, 'raced': 418, 'rattling': 419, 'really': 420, 'rifles': 421, 'ring': 422, 'rock': 423, 'roger': 424, 'rolling': 425, 'run': 426, 'say': 427, 'sea': 428, 'sent': 429, 'several': 430, 'sewers': 431, 'sheets': 432, 'shirt': 433, 'signals': 434, 'silver': 435, 'since': 436, 'sister': 437, 'skin': 438, 'smelled': 439, 'smoking': 440, 'soldiers': 441, 'somehow': 442, 'sound': 443, 'speak': 444, 'speech': 445, 'sports': 446, 'spray': 447, 'spread': 448, 'squirrel': 449, 'staircase': 450, 'stale': 451, 'standing': 452, 'steam': 453, 'steep': 454, 'step': 455, 'stepped': 456, 'stomach': 457, 'stone': 458, 'straight': 459, 'stroke': 460, 'strong': 461, 'sure': 462, 'susie': 463, 'taking': 464, 'taste': 465, 'teeth': 466, 'temperature': 467, 'threw': 468, 'times': 469, 'tiny': 470, 'top': 471, 'touched': 472, 'train': 473, 'trunk': 474, 'trying': 475, 'twenty': 476, 'twisted': 477, 'used': 478, 'usual': 479, 'voices': 480, 'warmed': 481, 'watching': 482, 'water': 483, 'waters': 484, 'waves': 485, 'weak': 486, 'wearing': 487, 'weight': 488, 'whipped': 489, 'wife': 490, 'without': 491, 'woman': 492, 'wood': 493, 'wrapped': 494, 'young': 495, 'aaron': 496, 'abandoned': 497, 'accelerating': 498, 'ached': 499, 'active': 500, 'address': 501, 'adze': 502, 'afterward': 503, 'ago': 504, 'aim': 505, 'aimed': 506, 'allowed': 507, 'almost': 508, 'also': 509, 'amount': 510, 'animal': 511, 'anymore': 512, 'anytime': 513, 'appear': 514, 'applying': 515, 'appointment': 516, 'arable': 517, 'arm': 518, 'arrived': 519, 'ashes': 520, 'attention': 521, 'attractive': 522, 'autumn': 523, 'avoided': 524, 'aware': 525, 'ax': 526, 'bachelor': 527, 'backpack': 528, 'backward': 529, 'bag': 530, 'baking': 531, 'band': 532, 'bang': 533, 'banging': 534, 'barcel': 535, 'bathroom': 536, 'beads': 537, 'bearings': 538, 'beatty': 539, 'become': 540, 'becomes': 541, 'bedecked': 542, 'beg': 543, 'began': 544, 'bending': 545, 'beside': 546, 'best': 547, 'bill': 548, 'biting': 549, 'bitter': 550, 'blackened': 551, 'blackout': 552, 'blades': 553, 'blank': 554, 'bleached': 555, 'blessing': 556, 'blind': 557, 'blinding': 558, 'blinked': 559, 'blond': 560, 'bloodied': 561, 'blotting': 562, 'blushing': 563, 'boarded': 564, 'bobber': 565, 'bodies': 566, 'body': 567, 'bolts': 568, 'boots': 569, 'boring': 570, 'bouncing': 571, 'bow': 572, 'bowed': 573, 'boxes': 574, 'branches': 575, 'break': 576, 'breathe': 577, 'breeze': 578, 'brenda': 579, 'bricks': 580, 'brighter': 581, 'brightly': 582, 'bring': 583, 'bringing': 584, 'broadsword': 585, 'brought': 586, 'brushed': 587, 'brushwood': 588, 'bubbled': 589, 'buckets': 590, 'bud': 591, 'buds': 592, 'building': 593, 'bulbs': 594, 'bulging': 595, 'bullied': 596, 'bunches': 597, 'burned': 598, 'burrowed': 599, 'busied': 600, 'butterfly': 601, 'cab': 602, 'calcium': 603, 'calle': 604, 'calm': 605, 'canal': 606, 'candles': 607, 'canuda': 608, 'caps': 609, 'car': 610, 'carpenter': 611, 'carriage': 612, 'carry': 613, 'carrying': 614, 'cars': 615, 'casserole': 616, 'cast': 617, 'caught': 618, 'celebrated': 619, 'chain': 620, 'chair': 621, 'champagne': 622, 'championships': 623, 'changed': 624, 'chapel': 625, 'chased': 626, 'cheeks': 627, 'chest': 628, 'child': 629, 'children': 630, 'chill': 631, 'chocolate': 632, 'choked': 633, 'choking': 634, 'choppy': 635, 'christmas': 636, 'cigarette': 637, 'cjoey': 638, 'clammy': 639, 'clap': 640, 'classroom': 641, 'clatter': 642, 'clattering': 643, 'clean': 644, 'clearly': 645, 'click': 646, 'cliff': 647, 'cloud': 648, 'clung': 649, 'clutched': 650, 'cneither': 651, 'coat': 652, 'cobblestone': 653, 'cobblestones': 654, 'cocktail': 655, 'cocktails': 656, 'coffee': 657, 'colds': 658, 'collar': 659, 'collect': 660, 'collection': 661, 'college': 662, 'colorful': 663, 'colour': 664, 'come': 665, 'comes': 666, 'competes': 667, 'complaining': 668, 'confused': 669, 'congealed': 670, 'connect': 671, 'consumed': 672, 'containers': 673, 'content': 674, 'continued': 675, 'conveyance': 676, 'cookies': 677, 'cooking': 678, 'correct': 679, 'cottages': 680, 'county': 681, 'course': 682, 'courtyard': 683, 'coveralls': 684, 'covered': 685, 'covering': 686, 'covers': 687, 'crack': 688, 'crashed': 689, 'crawled': 690, 'creaky': 691, 'creditors': 692, 'creek': 693, 'creeping': 694, 'creepy': 695, 'crepe': 696, 'crept': 697, 'crisscrossed': 698, 'crop': 699, 'crossed': 700, 'crossword': 701, 'crow': 702, 'crowd': 703, 'crowded': 704, 'crumpling': 705, 'crunching': 706, 'crystal': 707, 'crystals': 708, 'cubes': 709, 'culinary': 710, 'cupboard': 711, 'cupboards': 712, 'curly': 713, 'cursing': 714, 'curtain': 715, 'customers': 716, 'dairy': 717, 'daisy': 718, 'dangled': 719, 'dashed': 720, 'dave': 721, 'dawn': 722, 'dead': 723, 'dearly': 724, 'deathly': 725, 'debated': 726, 'decent': 727, 'decide': 728, 'decided': 729, 'decisively': 730, 'delicately': 731, 'descended': 732, 'desert': 733, 'desperately': 734, 'destroyed': 735, 'diagilo': 736, 'different': 737, 'diligent': 738, 'diligently': 739, 'ding': 740, 'disappeared': 741, 'discerned': 742, 'discover': 743, 'distance': 744, 'distorted': 745, 'dividing': 746, 'doctor': 747, 'dodging': 748, 'donuts': 749, 'downwards': 750, 'drawer': 751, 'drawn': 752, 'drenched': 753, 'dressing': 754, 'drink': 755, 'drinker': 756, 'drinks': 757, 'drive': 758, 'driver': 759, 'droppings': 760, 'drove': 761, 'dug': 762, 'dull': 763, 'dumb': 764, 'dye': 765, 'early': 766, 'easily': 767, 'eevery': 768, 'effort': 769, 'eh': 770, 'ei': 771, 'eight': 772, 'ekaterina': 773, 'elephant': 774, 'eligible': 775, 'embrace': 776, 'emitted': 777, 'empty': 778, 'encouragement': 779, 'end': 780, 'energy': 781, 'eno': 782, 'entirely': 783, 'enveloped': 784, 'especially': 785, 'evening': 786, 'evinrude': 787, 'ewhat': 788, 'exhaustion': 789, 'expect': 790, 'expensive': 791, 'explosion': 792, 'eyed': 793, 'eyelashes': 794, 'fabric': 795, 'faces': 796, 'faded': 797, 'faint': 798, 'false': 799, 'fam': 800, 'familiar': 801, 'fan': 802, 'fancy': 803, 'feather': 804, 'feature': 805, 'feel': 806, 'feeling': 807, 'fell': 808, 'fetid': 809, 'fight': 810, 'figuring': 811, 'fingernail': 812, 'fiona': 813, 'fireplace': 814, 'fishing': 815, 'fishtail': 816, 'flaking': 817, 'flame': 818, 'flames': 819, 'flapped': 820, 'flares': 821, 'flat': 822, 'flattened': 823, 'flesh': 824, 'flew': 825, 'flickered': 826, 'fll': 827, 'floating': 828, 'flooding': 829, 'floorboard': 830, 'florentine': 831, 'flower': 832, 'flowing': 833, 'flying': 834, 'fog': 835, 'fogged': 836, 'foggy': 837, 'folded': 838, 'food': 839, 'football': 840, 'foothold': 841, 'forbidden': 842, 'forced': 843, 'foreign': 844, 'form': 845, 'formed': 846, 'forward': 847, 'fought': 848, 'frames': 849, 'freeze': 850, 'friend': 851, 'frightened': 852, 'frigid': 853, 'frozen': 854, 'fullness': 855, 'fully': 856, 'fur': 857, 'furs': 858, 'fve': 859, 'ga': 860, 'game': 861, 'gardener': 862, 'gardens': 863, 'gave': 864, 'gdarlene': 865, 'gdo': 866, 'gents': 867, 'georgie': 868, 'getting': 869, 'gget': 870, 'ggood': 871, 'gholy': 872, 'ghostly': 873, 'ginny': 874, 'girls': 875, 'given': 876, 'giving': 877, 'glet': 878, 'glided': 879, 'glistened': 880, 'glowing': 881, 'glumly': 882, 'glutinous': 883, 'gnice': 884, 'gnot': 885, 'god': 886, 'goh': 887, 'gold': 888, 'gotten': 889, 'gpiccadilly': 890, 'gpoint': 891, 'grabbed': 892, 'grabbing': 893, 'graceful': 894, 'grand': 895, 'grasping': 896, 'gravity': 897, 'gray': 898, 'grazing': 899, 'great': 900, 'grew': 901, 'grimace': 902, 'gritted': 903, 'gritty': 904, 'groaned': 905, 'grounds': 906, 'grow': 907, 'gsit': 908, 'gslice': 909, 'gstop': 910, 'guards': 911, 'guessing': 912, 'gun': 913, 'gushed': 914, 'gutters': 915, 'hail': 916, 'half': 917, 'halfway': 918, 'halls': 919, 'hallway': 920, 'halted': 921, 'hammer': 922, 'hammering': 923, 'hanging': 924, 'hansom': 925, 'happily': 926, 'harsh': 927, 'haze': 928, 'heaps': 929, 'heaven': 930, 'help': 931, 'hem': 932, 'hidden': 933, 'higher': 934, 'hill': 935, 'hills': 936, 'hilltops': 937, 'hinges': 938, 'hockey': 939, 'holt': 940, 'homework': 941, 'hooked': 942, 'horizon': 943, 'horsepower': 944, 'horses': 945, 'houses': 946, 'huddled': 947, 'human': 948, 'humming': 949, 'hungry': 950, 'hunk': 951, 'hurled': 952, 'hurry': 953, 'husband': 954, 'ideal': 955, 'ignited': 956, 'ill': 957, 'impenetrable': 958, 'impression': 959, 'incorrect': 960, 'increased': 961, 'increasing': 962, 'ing': 963, 'ingredient': 964, 'inhale': 965, 'inside': 966, 'instantly': 967, 'instead': 968, 'intensity': 969, 'interrupted': 970, 'invisible': 971, 'iona': 972, 'ireland': 973, 'itched': 974, 'jerked': 975, 'jews': 976, 'job': 977, 'joy': 978, 'juli': 979, 'jump': 980, 'jumped': 981, 'junkyard': 982, 'key': 983, 'kind': 984, 'kindergarten': 985, 'kinds': 986, 'kiosk': 987, 'kitchen': 988, 'kitchenware': 989, 'knee': 990, 'knight': 991, 'knowledge': 992, 'known': 993, 'lady': 994, 'latin': 995, 'lawns': 996, 'lay': 997, 'layers': 998, 'lead': 999, 'leaden': 1000, 'leader': 1001, 'leaned': 1002, 'leapt': 1003, 'leave': 1004, 'led': 1005, 'leg': 1006, 'lemonade': 1007, 'library': 1008, 'lifetime': 1009, 'lift': 1010, 'lifting': 1011, 'lifts': 1012, 'lighting': 1013, 'lightly': 1014, 'lime': 1015, 'lip': 1016, 'lips': 1017, 'lives': 1018, 'living': 1019, 'locking': 1020, 'lookin': 1021, 'lots': 1022, 'loud': 1023, 'louder': 1024, 'lovely': 1025, 'low': 1026, 'lower': 1027, 'lurches': 1028, 'luscious': 1029, 'lying': 1030, 'mactalde': 1031, 'madness': 1032, 'magical': 1033, 'make': 1034, 'managed': 1035, 'manner': 1036, 'matters': 1037, 'may': 1038, 'meal': 1039, 'mean': 1040, 'meat': 1041, 'medicine': 1042, 'medieval': 1043, 'melancholy': 1044, 'melted': 1045, 'melting': 1046, 'men': 1047, 'merchants': 1048, 'mesmerized': 1049, 'mess': 1050, 'michael': 1051, 'middle': 1052, 'mine': 1053, 'minute': 1054, 'misbehaving': 1055, 'missed': 1056, 'missing': 1057, 'mist': 1058, 'mold': 1059, 'mom': 1060, 'moment': 1061, 'monotonously': 1062, 'montag': 1063, 'moon': 1064, 'moonlit': 1065, 'moths': 1066, 'mottled': 1067, 'movement': 1068, 'movements': 1069, 'moving': 1070, 'mowing': 1071, 'mozzarella': 1072, 'mrs': 1073, 'much': 1074, 'muscles': 1075, 'mushrooms': 1076, 'n': 1077, 'nale': 1078, 'named': 1079, 'narrowing': 1080, 'navigated': 1081, 'nearer': 1082, 'network': 1083, 'new': 1084, 'nice': 1085, 'nineties': 1086, 'ninja': 1087, 'nostrils': 1088, 'note': 1089, 'notion': 1090, 'notions': 1091, 'occured': 1092, 'offer': 1093, 'older': 1094, 'ones': 1095, 'oooh': 1096, 'opaque': 1097, 'opera': 1098, 'ophelia': 1099, 'opponent': 1100, 'opulent': 1101, 'orange': 1102, 'ordered': 1103, 'ordinary': 1104, 'others': 1105, 'outboard': 1106, 'outline': 1107, 'outward': 1108, 'outwards': 1109, 'overnight': 1110, 'overran': 1111, 'oyster': 1112, 'packed': 1113, 'pain': 1114, 'painful': 1115, 'paint': 1116, 'palatial': 1117, 'palm': 1118, 'pancake': 1119, 'pancakes': 1120, 'pans': 1121, 'pardon': 1122, 'parked': 1123, 'part': 1124, 'parties': 1125, 'pass': 1126, 'passageways': 1127, 'passed': 1128, 'passionate': 1129, 'past': 1130, 'patch': 1131, 'patches': 1132, 'path': 1133, 'pavements': 1134, 'pay': 1135, 'pedestrian': 1136, 'pedestrians': 1137, 'peeled': 1138, 'pepperup': 1139, 'percy': 1140, 'permeate': 1141, 'perspire': 1142, 'petals': 1143, 'philosophies': 1144, 'piccadilly': 1145, 'picking': 1146, 'picks': 1147, 'piece': 1148, 'pies': 1149, 'pig': 1150, 'piled': 1151, 'piles': 1152, 'pillow': 1153, 'pines': 1154, 'pink': 1155, 'piss': 1156, 'piston': 1157, 'pitcher': 1158, 'pitches': 1159, 'planned': 1160, 'plants': 1161, 'players': 1162, 'playing': 1163, 'pleasant': 1164, 'plumber': 1165, 'plump': 1166, 'plunger': 1167, 'plush': 1168, 'point': 1169, 'pointed': 1170, 'poppies': 1171, 'potion': 1172, 'pots': 1173, 'poured': 1174, 'pouring': 1175, 'powder': 1176, 'preferred': 1177, 'pressed': 1178, 'pretty': 1179, 'products': 1180, 'progress': 1181, 'promises': 1182, 'protagonist': 1183, 'protection': 1184, 'protein': 1185, 'provolone': 1186, 'puck': 1187, 'pull': 1188, 'pulling': 1189, 'pulsing': 1190, 'purplish': 1191, 'pushed': 1192, 'puzzle': 1193, 'race': 1194, 'rampant': 1195, 'rapid': 1196, 'rather': 1197, 'rattled': 1198, 'rays': 1199, 'razor': 1200, 'reach': 1201, 'read': 1202, 'readers': 1203, 'ready': 1204, 'reason': 1205, 'reef': 1206, 'reflected': 1207, 'reflecting': 1208, 'reflexes': 1209, 'refuge': 1210, 'regret': 1211, 'release': 1212, 'relief': 1213, 'remaining': 1214, 'remove': 1215, 'replied': 1216, 'restaurant': 1217, 'return': 1218, 'revolted': 1219, 'riding': 1220, 'rising': 1221, 'rivers': 1222, 'riveted': 1223, 'roared': 1224, 'rolled': 1225, 'romantic': 1226, 'roof': 1227, 'roofs': 1228, 'rooms': 1229, 'rose': 1230, 'rosettes': 1231, 'rosy': 1232, 'rotten': 1233, 'rough': 1234, 'round': 1235, 'rounds': 1236, 'rubble': 1237, 'rumbles': 1238, 'rump': 1239, 'runt': 1240, 'rustle': 1241, 'ruzz': 1242, 'sad': 1243, 'saddle': 1244, 'safety': 1245, 'salina': 1246, 'salinas': 1247, 'sand': 1248, 'sapphire': 1249, 'sat': 1250, 'sauce': 1251, 'sausage': 1252, 'scarier': 1253, 'scent': 1254, 'scheduled': 1255, 'scrabbling': 1256, 'scramble': 1257, 'scrambled': 1258, 'screamed': 1259, 'screen': 1260, 'scribbled': 1261, 'seat': 1262, 'seconds': 1263, 'seeds': 1264, 'seeing': 1265, 'seem': 1266, 'selling': 1267, 'send': 1268, 'senior': 1269, 'sentence': 1270, 'served': 1271, 'serving': 1272, 'setting': 1273, 'shade': 1274, 'shadows': 1275, 'shake': 1276, 'shapes': 1277, 'sharp': 1278, 'sharpening': 1279, 'shattered': 1280, 'shavings': 1281, 'sheathed': 1282, 'sheer': 1283, 'shelves': 1284, 'shifted': 1285, 'shine': 1286, 'shit': 1287, 'shivering': 1288, 'shocked': 1289, 'shore': 1290, 'shout': 1291, 'shouted': 1292, 'showered': 1293, 'shrieked': 1294, 'shroud': 1295, 'shuf': 1296, 'shut': 1297, 'shuzz': 1298, 'sick': 1299, 'sides': 1300, 'sidewalks': 1301, 'sifted': 1302, 'sigh': 1303, 'sighed': 1304, 'sighet': 1305, 'sighing': 1306, 'silenced': 1307, 'silent': 1308, 'silly': 1309, 'simple': 1310, 'single': 1311, 'sings': 1312, 'sir': 1313, 'sisters': 1314, 'sits': 1315, 'situation': 1316, 'six': 1317, 'sizes': 1318, 'skies': 1319, 'slack': 1320, 'slam': 1321, 'slapping': 1322, 'slash': 1323, 'sleepy': 1324, 'sleigh': 1325, 'slept': 1326, 'slice': 1327, 'slick': 1328, 'slip': 1329, 'slopes': 1330, 'slow': 1331, 'slowed': 1332, 'slushies': 1333, 'smallest': 1334, 'smelling': 1335, 'smiled': 1336, 'smiles': 1337, 'smooth': 1338, 'snarl': 1339, 'snuck': 1340, 'snuffed': 1341, 'sold': 1342, 'solid': 1343, 'something': 1344, 'somewhere': 1345, 'soon': 1346, 'sorority': 1347, 'sorting': 1348, 'soul': 1349, 'spaces': 1350, 'spans': 1351, 'spate': 1352, 'speaks': 1353, 'speed': 1354, 'spilling': 1355, 'spit': 1356, 'splinter': 1357, 'sport': 1358, 'spreading': 1359, 'spring': 1360, 'spun': 1361, 'spurred': 1362, 'square': 1363, 'squinted': 1364, 'squinting': 1365, 'stacks': 1366, 'staff': 1367, 'stains': 1368, 'staleness': 1369, 'stands': 1370, 'stars': 1371, 'starts': 1372, 'state': 1373, 'stay': 1374, 'steadily': 1375, 'steady': 1376, 'stealth': 1377, 'steeds': 1378, 'stepping': 1379, 'stiff': 1380, 'stirred': 1381, 'stop': 1382, 'story': 1383, 'straightened': 1384, 'strawberry': 1385, 'street': 1386, 'streetlamps': 1387, 'strokes': 1388, 'struggled': 1389, 'studded': 1390, 'students': 1391, 'stumbled': 1392, 'subject': 1393, 'sucked': 1394, 'sudden': 1395, 'suddenly': 1396, 'suffer': 1397, 'sunday': 1398, 'sunny': 1399, 'sunshine': 1400, 'suppose': 1401, 'surpassed': 1402, 'surprised': 1403, 'surrender': 1404, 'suzie': 1405, 'swamped': 1406, 'sweaty': 1407, 'sweeping': 1408, 'sweet': 1409, 'swiftly': 1410, 'swimmers': 1411, 'swipes': 1412, 'swirled': 1413, 'switched': 1414, 'sycamores': 1415, 'tackle': 1416, 'take': 1417, 'talented': 1418, 'taller': 1419, 'tapped': 1420, 'temporary': 1421, 'ten': 1422, 'tensed': 1423, 'terms': 1424, 'text': 1425, 'thatched': 1426, 'thermometers': 1427, 'thin': 1428, 'thing': 1429, 'third': 1430, 'throat': 1431, 'throttle': 1432, 'thumbnail': 1433, 'thump': 1434, 'thunder': 1435, 'thundered': 1436, 'tiffany': 1437, 'tiger': 1438, 'tighten': 1439, 'tim': 1440, 'tin': 1441, 'tissue': 1442, 'tobacco': 1443, 'toilet': 1444, 'tom': 1445, 'tomato': 1446, 'tonight': 1447, 'toolbox': 1448, 'tools': 1449, 'tossed': 1450, 'tough': 1451, 'towards': 1452, 'trade': 1453, 'trees': 1454, 'trembled': 1455, 'tried': 1456, 'tripped': 1457, 'troubled': 1458, 'tuning': 1459, 'turbulent': 1460, 'turning': 1461, 'tv': 1462, 'tweed': 1463, 'twinkling': 1464, 'umbrella': 1465, 'unattached': 1466, 'uneven': 1467, 'unjust': 1468, 'unnatural': 1469, 'unsuccessful': 1470, 'unusual': 1471, 'upcoming': 1472, 'upon': 1473, 'upper': 1474, 'upstream': 1475, 'usurers': 1476, 'valley': 1477, 'vance': 1478, 'various': 1479, 'vast': 1480, 'vegetables': 1481, 'vehicle': 1482, 'veiled': 1483, 'vellum': 1484, 'vest': 1485, 'vigorously': 1486, 'vitamins': 1487, 'vivid': 1488, 'vocals': 1489, 'voice': 1490, 'waft': 1491, 'waist': 1492, 'wait': 1493, 'waited': 1494, 'waiting': 1495, 'waitress': 1496, 'walk': 1497, 'wanted': 1498, 'watch': 1499, 'watched': 1500, 'watermelon': 1501, 'wearin': 1502, 'weasley': 1503, 'wedding': 1504, 'weightlifting': 1505, 'welsh': 1506, 'wet': 1507, 'whenever': 1508, 'whispering': 1509, 'whisperings': 1510, 'wide': 1511, 'wildly': 1512, 'willed': 1513, 'wilting': 1514, 'windless': 1515, 'windows': 1516, 'wings': 1517, 'winters': 1518, 'wipe': 1519, 'wire': 1520, 'wished': 1521, 'woke': 1522, 'wonderful': 1523, 'words': 1524, 'wore': 1525, 'working': 1526, 'world': 1527, 'worn': 1528, 'wrenches': 1529, 'wrist': 1530, 'writing': 1531, 'wrong': 1532, 'yard': 1533, 'yards': 1534, 'yawned': 1535, 'years': 1536, 'yelled': 1537, 'yogurt': 1538, 'york': 1539, 'younger': 1540, 'yowl': 1541})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi) # 생성된 집합 내 단어들을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기까지 잘됨, 이것을 이제 레이블, torch tensor로 변환 해야함. train_dataset, test_dataset 각각 처리할것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토치텍스트의 테이터로더 생성\n",
    "\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 13\n",
      "테스트 데이터의 미니 배치 수 : 4\n"
     ]
    }
   ],
   "source": [
    "train_loader = Iterator(dataset=train_data, batch_size = batch_size)\n",
    "test_loader = Iterator(dataset=test_data, batch_size = batch_size)\n",
    "\n",
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.iterator.Iterator at 0x1a4b00bad0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.iterator.Iterator"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 771, 1401,   72,   41,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  86,  232,  110,  232,  188,  876,  900,  980, 1431,  634,   37,  132,\n",
      "          295,   15,   54,  433,    9,  824,    1,    1],\n",
      "        [ 426,   33,  361,  310,  965,  282, 1257,  153,  353, 1194,   28,   10,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  23,    9, 1065, 1325,  382,  319,  331,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 579,  131,  312,  751, 1297, 1361,  102,   22,  933,    7,   36, 1017,\n",
      "          975, 1380,  236,  721,  136,  191, 1317,  301],\n",
      "        [  34,   33,   51,  183,  113,  979, 1077,   47,  140, 1008, 1284,  778,\n",
      "          814,  633, 1237,   95,  725,  215,  826,   38],\n",
      "        [1457,  808,  529,   90,  563,  627,  233,   22,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 203,  318,  218,    5,  243,  158,  116,   48,  954,  738,  109,  315,\n",
      "          372,   93,    1,    1,    1,    1,    1,    1],\n",
      "        [ 387,  628,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 703,   13,  100,    2, 1403, 1219,  911,    5,  198,  401,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [  93,   52,  283,  283,   35,   52,  134,  520,  507, 1037,   90,   93,\n",
      "         1469,   52,   19,   20,   19,  606,  127,  222],\n",
      "        [ 305, 1294,  221, 1512,   73,  131,   10,  360,   32,  156,  265,  669,\n",
      "          920,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 234,  399,  554, 1474,  130, 1531,  163, 1191,   19,  348, 1027,  995,\n",
      "         1425,  339, 1202, 1043,   30,    1,    1,    1],\n",
      "        [ 883,   67,   39,   57,  130,   32,   36,  845,  450,    5,  742,   19,\n",
      "          458,  135,  732,   81, 1275,    1,    1,    1],\n",
      "        [1437,  182,  432,  597,    9,  176,  330, 1328,   54,   10, 1198,  486,\n",
      "          938,    2,  346,   35,   12,   29,    1,    1],\n",
      "        [ 365,    9,  167,  837,  106,  698,  653,   91, 1137,  288,  748,  760,\n",
      "         1378,  221, 1036,  413,  676,    8, 1136,  367]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 16개씩 묶어줬음. 첫번째 미니배치에 저장\n",
    "\n",
    "print(batch.text) #첫번째 미니 배치의 text 필드를 호출해서 확인해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 133,  819, 1381,  474,   55,  690,   63,  119,  588,  746,  962,    8,\n",
      "        1131,  472,   55,  474, 1258,    6,  104,  449])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # 첫번째 미니배치\n",
    "print(batch.text[0]) # 첫번째 미니배치 중 첫번째 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch)) #미니배치 자료형 확인. 토치텍스늬 데이터로더는  'torchtext.data.batch.Batch'라는 객체를 가져온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 133,  819, 1381,  474,   55,  690,   63,  119,  588,  746,  962,\n",
       "          8, 1131,  472,   55,  474, 1258,    6,  104,  449])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tr = batch.text.numpy() #tensor를 array로 전환해봄(테스트) , 여기에 라벨값이 포함되어 있는데, 이것을 구분해서 추가해줘보자...\n",
    "batch_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기가지 진행완료!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif = []\n",
    "data_verif = test_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif = []\n",
    "data_verif = train_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(data_verif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_verif[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f67e83100594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEMBED_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNUN_CLASS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUN_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_vocab'"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000lines [00:08, 14582.67lines/s]\n",
      "120000lines [00:15, 7822.49lines/s]\n",
      "7600lines [00:00, 8340.65lines/s]\n"
     ]
    }
   ],
   "source": [
    "#원본코드인데.. 이미 가공된 데이터셋을 ngrams 처리해서 불러오기 때문에 입력데이터를 dataset에 맞게 수정해야 한다.\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "\n",
    "NGRAMS = 2\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.isdir('./data2'):\n",
    "    os.mkdir('./data2')\n",
    "    \n",
    "    \n",
    "#text_classification.DATASETS의 구조를 보고 결과데이터를 어떻게 생성하는지 분석하거나 이하 학습코드를 분석    \n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "    root='./data2', ngrams=NGRAMS, vocab=None) \n",
    "#ref : https://pytorch.org/text/datasets.html#ag-news\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  tensor([    131,       5,   23258,      27,    2922,     357,    2688,     769,\n",
       "              814,      14,      32,      15,      16,       6,     131,       7,\n",
       "              230,     293,     452,     836,    6438,      85,       2,      51,\n",
       "            43647,       2,   24372,       4,   60885,      51,  281059,       2,\n",
       "                0,       9,   21969,     115,       2,      51,  108539,       2,\n",
       "            36279,       4,      11,      81,      31,      90,      39,   23258,\n",
       "                6,      27,     357,    4090,    1698,      53,       5,     273,\n",
       "              821,       3,    1507,       7,       3,    1473,    3049,       2,\n",
       "             9821,   53919,  115850,   75043,   30252,  478273,  244818,     822,\n",
       "             4291,      43,      44,      46,     296,    2486,    2022,    8893,\n",
       "            23909,   49141,  381768,    9169,   19041,      89,     122,       0,\n",
       "            43648,   24031,   69185,   94356, 1174101,       0,  450795,       0,\n",
       "                0,  223922,  108592,     126,     122,       0,  178323,   35545,\n",
       "           409428,     735,     174,    3486,    2986,    3563,  119987,  102135,\n",
       "              151,   21657,   24613,  196267,  449408,     568,    9261,   16383,\n",
       "            10610,   12791,   10597,      29,    3937,  125919,   29219])),\n",
       " (3,\n",
       "  tensor([    398,    1371,    4357,     140,       4,     529,   17887,     769,\n",
       "              814,      14,      32,      15,      16,     398,     239,      85,\n",
       "                2,      51,   12202,       2,   36279,      11,      77,    1017,\n",
       "             3918,       6,      27,     621,    1304,       5,    1413,     450,\n",
       "             1535,   20318,    3524,    4357,       9,    1475,       6,    5662,\n",
       "           139374,     140,   17887,   10030,      25,    5818,     295,     374,\n",
       "             3237,     140,       2,   58236,  912220,  247465,    3730,   20914,\n",
       "                0,       0,     822,    4291,      43,      44,      46,   10183,\n",
       "             2133,    4850,      89,     122,       0,   27392,   35545,  132604,\n",
       "              161,  288511,  177353,   56884,     151,   37744,  115817,    1756,\n",
       "             5972,   49904, 1262338,  702497, 1079944,  965345,  128458,  175247,\n",
       "             5939,   33049,       0,  472516,       0,       0,       0,   11287,\n",
       "                0,  127381,  125934,       0,    3595])),\n",
       " (3,\n",
       "  tensor([  1743,   1191,   2678,    398,      5,   1044,   2419,    172,   5807,\n",
       "              14,     32,     15,     16,    506,    198,   7286,      4,      6,\n",
       "            1743,    288,   1118,   1847,      4,    500,    398,    239,     85,\n",
       "               2,      5,    172,     11,     77,     20,      3,    559,      7,\n",
       "               6,     27,   2419,    214,      8,    482,     17,     10,    415,\n",
       "           13976,     12,    592,   5611,    343,      2, 183509,      0, 326295,\n",
       "           29013,  36745,      0,  87826,      0,  15874,     43,     44,     46,\n",
       "           40085,      0, 430407, 103141,     87,  19259,      0, 404669,  43244,\n",
       "           10017,  29826,      0,   2133,   4850,     89,   2071,  10175,  39267,\n",
       "             161,  10293,    154,   5172,   3559,    107,    151, 262534,  14209,\n",
       "            6874,   2580,   6611,     23,   5736, 256315, 145528,  17037, 350126,\n",
       "               0,   4028])),\n",
       " (3,\n",
       "  tensor([  3270, 144492,  18571,    840,    368,      6,    334, 141753,  18571,\n",
       "               7,  62303,    136,     33,    109,   2508,      8,   6705,      4,\n",
       "             368,      4,    125,   5741,   1044,  68572,   2480,      2,      0,\n",
       "               0,      0,      0,  58315,  10751,      0,      0, 109318,      0,\n",
       "               0,   3087,    282,  21461,  18230,  49708,  49983,   5149,   9282,\n",
       "            7808,  38803,      0,      0,      0,  36581])),\n",
       " (3,\n",
       "  tensor([1155350,   17813,   46664,    1367,   46664,    1367,       4,     156,\n",
       "           422148,       4,   16838,      11, 1155350,       5,     633,     333,\n",
       "               34,   38763,       4,     601,    1395,       2,       0,       0,\n",
       "                0,       0,       0,   14019,    1323,       0,       0,       0,\n",
       "            20324,       0,       0,    1215,   34865,   15806,  801893,       0,\n",
       "             4382,   91929,   62739])),\n",
       " (3,\n",
       "  tensor([   9647,     111,       2,   19481,      17,      10,   13103,     339,\n",
       "            57385,   19481,   14857,      25,    2291,    3920,     740,       5,\n",
       "               35,   27554,     339,   45525,     301,      25,  221858,     130,\n",
       "                2,       0,    7864,   51327, 1098538,      23,  275296,       0,\n",
       "                0,   77111,       0,  221568,   63824,       0,       0,     958,\n",
       "             1149,   78427,       0,  152353,       0,   16709,       0,       0,\n",
       "             1272]))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
       "             1143,      14,      32,      15,      32,      16,  443749,       4,\n",
       "              572,     499,      17,      10,  741769,       7,  468770,       4,\n",
       "               52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
       "           326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
       "              144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
       "          1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
       "             4052])),\n",
       " (2,\n",
       "  tensor([  55003,    1474,    1150,    1832,    7559,      14,      32,      15,\n",
       "               32,      16,    1262,    1072,     436,   55003,     131,       4,\n",
       "           142576,      33,       6,    8062,      12,     756,  475640,       9,\n",
       "           991346,    3186,       8,       3,     698,     329,       4,      33,\n",
       "             6764, 1040465,   13979,      11,     278,     483,       7,       3,\n",
       "              172,       2,  659973,  193730, 1237754,  684719,  556644,      43,\n",
       "               44,     144,     145,   77775,   56578,   32382,  782124,   79225,\n",
       "             2908,  140697,  540900,    2031,   31960,   45339,   21562,  936430,\n",
       "          1282186,  578442,  991347,   69671,      26,    9260,  717285,    5378,\n",
       "              597,   27622, 1070413, 1040466,   38669,   27790,  175394,     711,\n",
       "               29,    1404,    1818])),\n",
       " (2,\n",
       "  tensor([    78,      9,    469,   8385,    206,     17,    996,     14,     32,\n",
       "              15,     32,     16,   3654,    600,    124,   3080, 140201,      3,\n",
       "             469,      9,      3,    996,     12,    369,     52,    328, 464765,\n",
       "              48,      3,    397,    172,    149,    113,    301,      3,  18223,\n",
       "               7, 285456,  52106,      2,   5606,  95553, 183737, 180431, 164136,\n",
       "          120431,  30446,     43,     44,    144,    145,  85276,  92253,  10654,\n",
       "          200704, 422054, 213900,   1877,   8549,    152,  12306,   6126,  55468,\n",
       "           63058,   4461, 358165, 464766,    204,   5641,   4893,  59857,   1515,\n",
       "           93728,    995,  83994,  79735, 411437, 460552, 110113])),\n",
       " (2,\n",
       "  tensor([     93,   16478,      78,    2680,      34,    1230,     717,    4562,\n",
       "               14,      32,      15,      32,      16,    1129,      49,    9392,\n",
       "               78,  766148,      34,       3,    1230,    4562,       8,     717,\n",
       "               93,  559272,     947,       6,    1239,    3934,     125, 1178056,\n",
       "                4,      35,      78,     396,      31,      11,     153,       2,\n",
       "           881320,  373252,   12125,   23059,  802619,  258328,  447615,  199864,\n",
       "               43,      44,     144,     145,   40078,   13205,  152671,  373240,\n",
       "          1002054,  766149,     171,    4412,  934044,   47573,    2586,   17490,\n",
       "           881151,  559273,   16579,   17268,   64855,  954751,  699138, 1178057,\n",
       "              733,   26650,   36317,    1670,     177,     435,     949])),\n",
       " (2,\n",
       "  tensor([     78,     124,    7860,       5,    6044,     198,       4,   17139,\n",
       "               27,   36218,       5,      45,     469,      14,     138,      15,\n",
       "              138,      16, 1197667,      61,      78,     124,       4,   31767,\n",
       "             2540,       9,   43425,   25199,       4,    6060,       6,      27,\n",
       "              489,   36218,    5810,     127,     403,     226,       3,      45,\n",
       "              532,     726,       2,     240,   60413,   65219,  104402,  107151,\n",
       "            10156,   48457, 1048623,  262618,  400118,    5800,    4956,   28355,\n",
       "              279,     280,     388,     386,  501493, 1197668,    7397,     240,\n",
       "             3497,   66207, 1235874,   50427,  317844, 1176539,  473765,  216053,\n",
       "            45249,     151,   64260,  745331,  949223,  325090,    4774,   26987,\n",
       "             1139,     243,    8436,    7063,    6238])),\n",
       " (2,\n",
       "  tensor([    206,     208,      53,       4,      55,     479,      94,    3464,\n",
       "               14,      32,      15,      32,      16,     206,    1060,    1902,\n",
       "              379,      11,  800978,    7992,     479,    3464,      12,       3,\n",
       "               94,      21,      78,     124,    3501,     476,     619,  528552,\n",
       "              965,       4,   39403,       6,    2350,     996,      34,     239,\n",
       "           935798,      85,       2,      14,    1141,       2,     495,      15,\n",
       "            11722,   15152,    3178,     118,  231225,  975243,  480985,  131178,\n",
       "               43,      44,     144,     145,    6425,   18789,   63098,   12156,\n",
       "             4606, 1004868,  800979, 1171655,   60005,  396069,      60,    1011,\n",
       "             6986,    2339,     240,   15238,   70524, 1028775,  482706,  528553,\n",
       "             6084,   51256,  101340,   15096,  269456,   27804,   73786,  688832,\n",
       "           935799,      89,     384,   57662,   24791,     932,   17728])),\n",
       " (2,\n",
       "  tensor([  1018,   1675,    582,      8,    415,    113,     14,     36,     15,\n",
       "              36,     16,   2612,      7,      3,    542,     17,     10,   1118,\n",
       "            1018,    172,   3234,   1675,    582,     28,    619,    142,      2,\n",
       "            1049,    189,      8,      3,    415,    113,      5,    619, 534560,\n",
       "               2,  21905,  14818,      4,      3,   1072,     72,   4880,     31,\n",
       "              81,      2, 100737,  98628,   9912,  18657,  15704,  19999,     62,\n",
       "              63,     71,     70,  85239,  16664,     29,    841,   2275,     23,\n",
       "           41434,  91602,  81876,  89964,   8199,  98628,  18613,  37184,   7399,\n",
       "             765,   5717,  77916,   1917,     26,    744,  15704,   4456,   9650,\n",
       "          482769, 534561,  77817, 535975, 288294,     42,  18426,  32381,  72988,\n",
       "           47073,   1132,    549])),\n",
       " (2,\n",
       "  tensor([   1900,    1714,     684,   44443,      48,    2013,      14,    3315,\n",
       "                2,     232,      15,    3315,       2,     232,      16,    1118,\n",
       "              169,   12060,     150,       6,    3972,       8,    1709,       4,\n",
       "                9,      27,     763,      12,    3794,    2462,     582,      92,\n",
       "              113,       4,       3,     133,      31,      81,       4,   15691,\n",
       "                3,     469,      24,    4021,      34,       6,  131682,    6254,\n",
       "                2,  360219,  957280, 1143380,  350974,  266796,  190595,    6596,\n",
       "             3316,     277,     928,    6636,    3316,     277,    1182,  141294,\n",
       "             3592,  438165,   22995,   17293,    5686,  146000,    3246,    7586,\n",
       "              108,    4936,   39342,   17008,   22055,   29322,  108286,   40674,\n",
       "              605,     976,      42,     742,    3807,    1132,     820,   31877,\n",
       "            99516,    1877,    9292,   68651,  380346,     613,  309262,  401039,\n",
       "            45492])),\n",
       " (2,\n",
       "  tensor([   1456,     602,      14,    4054,       2,     232,      15,    4054,\n",
       "                2,     232,      16,      40,   22024,       6,  420149,       2,\n",
       "             1224,       2,       8, 1155430,       4,    8786,  614302,   23842,\n",
       "             1797,       5,     503,      21,       3,     451,     701,      22,\n",
       "                6,    1832,     796,    5847,     436,      22,      35,    1308,\n",
       "             2127,    9247,       7,     619,    3643,       4,     219,       2,\n",
       "             1002,      40,       4,       6,     550,   69660,    4668,      28,\n",
       "               38,   18226,       5,     902,     147,  642157,      91,    1037,\n",
       "             2462,    1370,     341,      38,   22528,       2,      55,       4,\n",
       "               22,    4905,       4,    1879,    1037,      41,       3,  245967,\n",
       "             2827,      34,    1807,    4949,       4,     112,   23842,       2,\n",
       "            83196,  406394,   10956,    5498,     277,     928,   10957,    5498,\n",
       "              277,    1182,    5524,  173711,   87887,  544978,  420150,   11482,\n",
       "             3100,    1107,  864884, 1155431,   85118,  710639,  614303, 1100087,\n",
       "            20363,    2527,   28884,     194,   12465,    6090,   49951,     446,\n",
       "            21914,  684789,    6672,  356699,  127453,    3228,   13757,  583197,\n",
       "           176942,  102821,   20271,  120361,   13387,     223,   10964,   71661,\n",
       "            38040,  143313,      87,   17265,  127414, 1041355,  136947,    5022,\n",
       "           153035,  722611,    6727,  149512,  998456,  642158,  310432,  252583,\n",
       "           622234,   78794,   25784,  153040,  110408,     694,   20536,    1792,\n",
       "           322176,   94783,   85105,  649707,  874340,    1326,  284635,  367875,\n",
       "           285881,  111292,  132111,   59921,    1391, 1121846,  434103])),\n",
       " (2,\n",
       "  tensor([   572,    564,      2,   2326,  49106,    150,     88,      3,   1143,\n",
       "              27,     96,     14,     32,     15,     16, 443749,      4,    572,\n",
       "             499,     17,     10,  29160,   5488,      7, 468770,      4,     52,\n",
       "            7019,   1050,    442,      2,  14341,    673, 141447, 326092,  55044,\n",
       "            7887,    411,   9870, 628732,     97,    276,     43,     44,     46,\n",
       "          299709, 443750,  51274,    703,  14312,     23, 275050, 741752,  29990,\n",
       "          411508, 468771,   3779,  86384, 135944, 371666,   4052]))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_verif = []\n",
    "data_verif = test_dataset\n",
    "data_verif_len = len(data_verif)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_verif_train = []\n",
    "data_verif_train = train_dataset\n",
    "data_verif_tr_len = len(data_verif_train)\n",
    "data_verif_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'showingTelling.xlsx', 'showingTelling_csv.csv']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./data')\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kimkwangil/Project/01EssayFitAI/showing_telling'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
       "            1143,      14,      32,      15,      32,      16,  443749,       4,\n",
       "             572,     499,      17,      10,  741769,       7,  468770,       4,\n",
       "              52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
       "          326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
       "             144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
       "         1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
       "            4052]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.datasets.text_classification.TextClassificationDataset"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308844"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUN_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 25 seconds\n",
      "\tLoss: 0.0260(train)\t|\tAcc: 84.8%(train)\n",
      "\tLoss: 0.0001(valid)\t|\tAcc: 90.5%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0118(train)\t|\tAcc: 93.7%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 89.3%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0068(train)\t|\tAcc: 96.4%(train)\n",
      "\tLoss: 0.0001(valid)\t|\tAcc: 90.6%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 25 seconds\n",
      "\tLoss: 0.0038(train)\t|\tAcc: 98.2%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 90.8%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0022(train)\t|\tAcc: 99.1%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 91.3%(valid)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0002(test)\t|\tAcc: 89.3%(test)\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "ag_news_label = {1 : \"World\",\n",
    "                 2 : \"Sports\",\n",
    "                 3 : \"Business\",\n",
    "                 4 : \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, model, vocab, ngrams):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
