{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data  \n",
    "\n",
    "# Yale 교수 전공 및 general 모든 정보 link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smoking-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "pd.options.display.max_rows = 999 # 데이터 프레임 표시 최대 열수를 999로 지정\n",
    "pd.set_option('display.max_columns',999) # 데이터 프레임 표시 최대 행수를 999로 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "becoming-course",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>major_title</th>\n",
       "      <th>info_type</th>\n",
       "      <th>Link</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>African American Studies</td>\n",
       "      <td>general_keywords</td>\n",
       "      <td>https://afamstudies.yale.edu/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>African American Studies</td>\n",
       "      <td>general_keywords</td>\n",
       "      <td>https://afamstudies.yale.edu/about-us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>African American Studies</td>\n",
       "      <td>facilities_resources</td>\n",
       "      <td>https://yalecollege.yale.edu/communities/cultu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>African American Studies</td>\n",
       "      <td>courses_concentrations</td>\n",
       "      <td>https://afamstudies.yale.edu/undergraduate-major</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>African American Studies</td>\n",
       "      <td>facilities_resources</td>\n",
       "      <td>http://catalog.yale.edu/ycps/subjects-of-instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2947</td>\n",
       "      <td>Women's, Gender and Sexuality Studies</td>\n",
       "      <td>professors</td>\n",
       "      <td>https://wgss.yale.edu/people/eda-pepi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2948</td>\n",
       "      <td>Women's, Gender and Sexuality Studies</td>\n",
       "      <td>professors</td>\n",
       "      <td>https://wgss.yale.edu/people/graeme-reid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2949</td>\n",
       "      <td>Women's, Gender and Sexuality Studies</td>\n",
       "      <td>professors</td>\n",
       "      <td>https://wgss.yale.edu/people/evren-savci</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>Women's, Gender and Sexuality Studies</td>\n",
       "      <td>professors</td>\n",
       "      <td>https://wgss.yale.edu/people/maria-trumpler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2951</td>\n",
       "      <td>Women's, Gender and Sexuality Studies</td>\n",
       "      <td>professors</td>\n",
       "      <td>https://wgss.yale.edu/people/laura-wexler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2952 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                major_title               info_type  \\\n",
       "0                  African American Studies        general_keywords   \n",
       "1                  African American Studies        general_keywords   \n",
       "2                  African American Studies    facilities_resources   \n",
       "3                  African American Studies  courses_concentrations   \n",
       "4                  African American Studies    facilities_resources   \n",
       "...                                     ...                     ...   \n",
       "2947  Women's, Gender and Sexuality Studies              professors   \n",
       "2948  Women's, Gender and Sexuality Studies              professors   \n",
       "2949  Women's, Gender and Sexuality Studies              professors   \n",
       "2950  Women's, Gender and Sexuality Studies              professors   \n",
       "2951  Women's, Gender and Sexuality Studies              professors   \n",
       "\n",
       "                                                   Link  Unnamed: 3  \n",
       "0                         https://afamstudies.yale.edu/         NaN  \n",
       "1                 https://afamstudies.yale.edu/about-us         NaN  \n",
       "2     https://yalecollege.yale.edu/communities/cultu...         NaN  \n",
       "3      https://afamstudies.yale.edu/undergraduate-major         NaN  \n",
       "4     http://catalog.yale.edu/ycps/subjects-of-instr...         NaN  \n",
       "...                                                 ...         ...  \n",
       "2947              https://wgss.yale.edu/people/eda-pepi         NaN  \n",
       "2948           https://wgss.yale.edu/people/graeme-reid         NaN  \n",
       "2949           https://wgss.yale.edu/people/evren-savci         NaN  \n",
       "2950        https://wgss.yale.edu/people/maria-trumpler         NaN  \n",
       "2951          https://wgss.yale.edu/people/laura-wexler         NaN  \n",
       "\n",
       "[2952 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get excel data to dataframe\n",
    "file_name = './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dedicated-pastor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2952"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amazing-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major_title + info_type 으로 파일명을 만들고 링크타고 데이터 추출후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "greater-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'African American Studies'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mjr_title = df.iloc[0]['major_title']\n",
    "mjr_title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reduced-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general_keywords'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_type = df.iloc[0]['info_type']\n",
    "info_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "handed-shore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://afamstudies.yale.edu/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = df.iloc[0]['Link']\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ongoing-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_file_full_name = \"Yale\" + \"_\" +  mjr_title + \"_\" + info_type + \"_info\" + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "anticipated-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe에서 데이터 추출하고 파일명으로 저장하기\n",
    "md_file = open(mk_file_full_name, 'w')\n",
    "# Yale_African American Studies_general_keywords_info.txt\n",
    "md_fine.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "italic-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 링크타고 들어가서 키워드 크롤링\n",
    "# 검색어로 크롬 실행, 실행결과의 링크 추출, 링크를 타고 각 페이지 접속, 페이지 내용 전체 크롤링, text 추출하고, 단어 리스트로 만드는 코드\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from urllib.parse import ParseResultBytes, quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "# 혹은 options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# UserAgent값을 바꿔줍시다! 서버가 인식하지 못하도록 가상으로 headless 값 추가함ㅠ\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "decreased-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linked_search_result(linked_page):\n",
    "#     baseUrl = 'https://www.google.com/search?q='\n",
    "\n",
    "#     #plusUrl = input('무엇을 검색할까요? :')\n",
    "#     plusUrl = input_word\n",
    "\n",
    "#     # url = baseUrl + quote_plus(plusUrl)\n",
    "#     url = baseUrl + plusUrl\n",
    "#     # 한글을 사용할 경우 :  quote_plus 적용 - URL에 막 %CE%GD%EC 이런 거 생성해줌\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path= r'./data/chromedriver_mac_ver_90', chrome_options=options)\n",
    "    driver.get(linked_page)\n",
    "\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "#     v = soup.select('.yuRUbf')\n",
    "\n",
    "#     search_title_result = []\n",
    "#     search_linked_contents_result = []\n",
    "#     for i in v:\n",
    "#         #print(i.select_one('.LC20lb.DKV0Md').text)\n",
    "#         search_title_result.append(i.select_one('.LC20lb.DKV0Md').text)\n",
    "#         #print(i.a.attrs['href'])\n",
    "#         search_linked_contents_result.append(i.a.attrs['href'])\n",
    "#         #print()\n",
    "\n",
    "\n",
    "    # search_linked_contents_result 의 각 링크로 접속하여 해당 내용을 모두 text로 크롤링한 후, 단어만 추리고, 다시 주요키워드를 추출한다.\n",
    "    \n",
    "    get_all_linked_web_data = []\n",
    "    \n",
    "    driver.get(linked_page)\n",
    "    html = driver.page_source\n",
    "    get_all_data = BeautifulSoup(html, features=\"html.parser\")\n",
    "    get_all_linked_web_data.append(get_all_data)\n",
    "        \n",
    "    body = re.search('<body.*/body>', html, re.I|re.S)\n",
    "    if (body is None):\n",
    "        print (\"No <body> in html\")\n",
    "        exit()\n",
    "            \n",
    "    body = body.group()\n",
    "    #print(body)\n",
    "    \n",
    "    # 추출된 정보 클린징\n",
    "    korean = re.compile('[\\u3131-\\u3163\\uac00-\\ud7a3]+')#한글제거\n",
    "\n",
    "    item_extract = str(body).replace('\\n', ' ')\n",
    "    item_extract = re.sub('<span.*?>.*?</span>', ' ', item_extract)\n",
    "    item_extract = re.sub('<b>.*?</b>', ' ', item_extract)    \n",
    "    item_extract = re.sub('<.*?>', ' ', item_extract)        \n",
    "    item_extract = item_extract.replace('\\t', ' ')\n",
    "    item_extract = re.sub(korean, '', item_extract)\n",
    "    item_extract = re.sub('[-=.#/?:$}]', ' ', item_extract)\n",
    "    item_extract = re.sub(\"[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』;{}()'\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]\", ' ', item_extract)\n",
    "    #print (item_extract)\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return item_extract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "interracial-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimkwangil/opt/anaconda3/envs/py37pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "get_result = linked_search_result('https://afamstudies.yale.edu/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "thorough-sword",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    omega media query dummy   position  relative  z index   1       omega media query dummy   z index  2       omega media query dummy   z index  0      omega media query dummy   z index  1      omega media query dummy   z index  2               Skip to main content                                                                                                                                                                                                                                                                                                                                                                                                                 Department of African American Studies nbsp                                                                                                                                                                         Graduate Program     Undergraduate Major     Research  amp  Collections     Media Gallery     People     Contact Us                                                                                                                        Welcome                                                                   Welcome to the Department of African American Studies at Yale  nbsp The African American Studies Department examines  from numerous disciplinary perspectives  the experiences of people of African descent in Black Atlantic societies  including the United States  the Caribbean  and Latin America     Learn More                                       From the nbsp Collection                                                                                                                                   Walter Evans Collection of Frederick Douglass and Douglass Family Papers                                                                       Half length group portrait  family group of six  father  mother  four children                                                                       The Rev  Dr  Martin Luther King  Jr   shown here with former Yale trustee the Rev  Gardiner M  Day  received an honorary LL D degree at Yale’s 263rd commencement in 1964                                                                        Ella Fitzgerald in 1940  photographed by Carl Van Vechten  who documented much of the Harlem Renaissance Credit   Carl Van Vechten © Van Vechten Trust                                      1    2    3    4      Previous    Next                                                                          News                                                                                                     America on Fire  The Untold History of Police Violence and Black Rebellion Since the 1960s                                                                                                                Carolyn Roberts  the Sidonie 2021 Yale College teaching prize  Miskimin Clauss Prize for teaching excellence in the humanities                                                                                                               Elizabeth Hinton  To understand policing today  look back to the federal policies and missed opportunities of the 1960s                                                                                                 More news                                                                                       African American Studies  amp  the Crises of Our Time    African American Studies  Support for the Scholars  Strike             Click here for the latest information on Yale s COVID 19 policies and procedures     African American Studies Response to COVID 19     nbsp  nbsp                                                    Join in Our Academic Work    The Combined Ph D  in African American Studies  nbsp  Important Update     Choose Our Undergraduate Program     Questions  nbsp    Contact the Registrar nbsp         nbsp                                    Events                                                                  More events                              Follow us for more news  amp  events         nbsp  nbsp                                                     New from African American Studies                                                                                                                      Daphne A  Brooks                                                                       Hazel Carby                                                                       Tavia Nyong o                                                                       Edward Rugemer                                                                       David Blight                                                                       Kobena Mercer                                                                      More publications                                                                                              Yale University Art Gallery Copyright Whitfield Lovell DC Moore Gallery                                                     Engage with Our Ideas                        “Style With Soul  How The World’s Most Iconic Black Women Singers Expressed Themselves Through Fashion ” Tavia Nyong’o  Vogue      “White Supermacy as Daily Pratice ” Micah Jones   Historians’ Watch      “José Muñoz  Then and There  nbsp On the afterlives of the pioneering queer theorist ” nbsp Tavia Nyong’o   thebaffler com                                                                    Kindren  quilt  Bisa Butler                                                                                                Accessibility at Yale  ·        Privacy policy          Copyright © 2021 Yale University · All rights reserved                                            About Us     Contact Us                                                                                                                                                                                            '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-scoop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-frontier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-winner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-custom",
   "metadata": {},
   "source": [
    "## test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "boring-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "pd.options.display.max_rows = 999 # 데이터 프레임 표시 최대 열수를 999로 지정\n",
    "pd.set_option('display.max_columns',999) # 데이터 프레임 표시 최대 행수를 999로 지정\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import openpyxl\n",
    "from urllib.parse import ParseResultBytes, quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "# 혹은 options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# UserAgent값을 바꿔줍시다! 서버가 인식하지 못하도록 가상으로 headless 값 추가함ㅠ\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "graduate-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(input_data):\n",
    "    remove = input_data.replace(\"  \",\" \") # 변환\n",
    "    remove_ = re.sub(r\"\\t\", \" \", remove) # 제거\n",
    "    remove__ = re.sub(r\"\\n\", \" \", remove_) # 제거\n",
    "    remove__ = remove__.replace(\"   \", \" \")\n",
    "    remove__ = remove__.replace(\"  \", \" \")\n",
    "    remove__ = remove__.replace(\" \", \",\")\n",
    "    remove__ = remove__.replace(\"…/\", \" \")\n",
    "    remove__ = remove__.replace(\"…\", \" \")\n",
    "    remove__ = remove__.replace(\"/\", \" \")\n",
    "    remove__ = remove__.replace(\" \", \",\")\n",
    "    remove__ = remove__.replace(\")\", \",\")\n",
    "    remove__ = remove__.replace(\"(\", \",\")\n",
    "    preprossed = remove__.split(\",\") # 단어를 리스트로 변환\n",
    "    #print(preprossed)\n",
    "    \n",
    "    # 표제어 추출, 동사는 현재형으로 변환\n",
    "    lemma_list =[]\n",
    "    for i in preprossed:\n",
    "        lema_re = lemmatizer.lemmatize(i, pos='v') #표제어 추출, 동사는 현재형으로 변환\n",
    "        lemma_list.append(lema_re)\n",
    "    \n",
    "    # 표제어 추출\n",
    "    ext_lema = [lemmatizer.lemmatize(w) for w in preprossed]\n",
    "    # 중복값을 제거하고\n",
    "    rm_dupli = set(ext_lema)\n",
    "    # 다시 리스트로 만들고\n",
    "    re_li = list(rm_dupli)\n",
    "    # 빈 값은 제거하고\n",
    "    get_wd =list(filter(None, re_li))\n",
    "    # 소문자로 모두 변환\n",
    "    lower_wd = [i.lower() for i in get_wd]\n",
    "    \n",
    "    result = []\n",
    "    for w in lower_wd: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "coordinated-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linked_search_result(linked_page):\n",
    "#     baseUrl = 'https://www.google.com/search?q='\n",
    "\n",
    "#     #plusUrl = input('무엇을 검색할까요? :')\n",
    "#     plusUrl = input_word\n",
    "\n",
    "#     # url = baseUrl + quote_plus(plusUrl)\n",
    "#     url = baseUrl + plusUrl\n",
    "#     # 한글을 사용할 경우 :  quote_plus 적용 - URL에 막 %CE%GD%EC 이런 거 생성해줌\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path= r'./data/chromedriver_mac_ver_90', chrome_options=options)\n",
    "    \n",
    "    try:\n",
    "        driver.get(linked_page)\n",
    "        \n",
    "    #     html = driver.page_source\n",
    "    #     soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    #     v = soup.select('.yuRUbf')\n",
    "\n",
    "    #     search_title_result = []\n",
    "    #     search_linked_contents_result = []\n",
    "    #     for i in v:\n",
    "    #         #print(i.select_one('.LC20lb.DKV0Md').text)\n",
    "    #         search_title_result.append(i.select_one('.LC20lb.DKV0Md').text)\n",
    "    #         #print(i.a.attrs['href'])\n",
    "    #         search_linked_contents_result.append(i.a.attrs['href'])\n",
    "    #         #print()\n",
    "\n",
    "\n",
    "        # search_linked_contents_result 의 각 링크로 접속하여 해당 내용을 모두 text로 크롤링한 후, 단어만 추리고, 다시 주요키워드를 추출한다.\n",
    "\n",
    "        get_all_linked_web_data = []\n",
    "\n",
    "        driver.get(linked_page)\n",
    "        html = driver.page_source\n",
    "        get_all_data = BeautifulSoup(html, features=\"html.parser\")\n",
    "        get_all_linked_web_data.append(get_all_data)\n",
    "\n",
    "        body = re.search('<body.*/body>', html, re.I|re.S)\n",
    "        if (body is None):\n",
    "            print (\"No <body> in html\")\n",
    "            exit()\n",
    "\n",
    "        body = body.group()\n",
    "        #print(body)\n",
    "\n",
    "        # 추출된 정보 클린징\n",
    "        korean = re.compile('[\\u3131-\\u3163\\uac00-\\ud7a3]+')#한글제거\n",
    "\n",
    "        item_extract = str(body).replace('\\n', ' ')\n",
    "        item_extract = re.sub('<span.*?>.*?</span>', ' ', item_extract)\n",
    "        item_extract = re.sub('<b>.*?</b>', ' ', item_extract)    \n",
    "        item_extract = re.sub('<.*?>', ' ', item_extract)        \n",
    "        item_extract = item_extract.replace('\\t', ' ')\n",
    "        item_extract = re.sub(korean, '', item_extract)\n",
    "        item_extract = re.sub('[-=.#/?:$}]', ' ', item_extract)\n",
    "        item_extract = re.sub(\"[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』;{}()'\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]\", ' ', item_extract)\n",
    "        #print (item_extract)\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "    except:\n",
    "        item_extract = [\"not enough infomation\"]\n",
    "\n",
    "    return item_extract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "floral-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동으로 데이터 추출코드, 1)파일명 생성 2)링크접속 3)데이터크롤링 4)키워드로 저장\n",
    "# file_name : 추출해야할 csv 파일 경로 및 파일명 지정\n",
    "#     file_name = './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "\n",
    "# college_name : 'Yale'\n",
    "# file_name =: './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "def input_name_of_college(college_name, file_name):\n",
    "    # import file to dataframe\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # get major title data\n",
    "    mjr_title = df.iloc[0]['major_title']\n",
    "    \n",
    "    # get info_type data\n",
    "    info_type = df.iloc[0]['info_type']\n",
    "    \n",
    "    #get link data\n",
    "    linked_page = df.iloc[0]['Link']\n",
    "    \n",
    "    # make file with full name\n",
    "    mk_file_full_name = college_name + \"_\" +  mjr_title + \"_\" + info_type + \"_info\" + \".txt\"\n",
    "    \n",
    "    # dataframe에서 데이터 추출하고 파일명으로 저장하기\n",
    "    md_file = open(mk_file_full_name, 'w')\n",
    "    # Yale_African American Studies_general_keywords_info.txt\n",
    "    \n",
    "    # 링크데이터로 크롤링하기\n",
    "    get_linked_data = linked_search_result(linked_page)\n",
    "    \n",
    "    # 데이터 클린징 후 리스트로 만들기\n",
    "    cleaned_data = cleaning_data(str(get_linked_data))\n",
    "    \n",
    "    # 리스트를 문자열로 변환\n",
    "    str_data = \" \".join(cleaned_data)\n",
    "    \n",
    "    # 생성된 파일에 결과데이터 저장하기\n",
    "    md_file.write(str_data)\n",
    "    \n",
    "    # 파일 닫기\n",
    "    md_file.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "indian-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimkwangil/opt/anaconda3/envs/py37pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "college_name = 'Yale'\n",
    "file_name = './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "result = input_name_of_college(college_name, file_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-staff",
   "metadata": {},
   "source": [
    "## auto-run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cellular-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동으로 데이터 추출코드, 1)파일명 생성 2)링크접속 3)데이터크롤링 4)키워드로 저장\n",
    "# file_name : 추출해야할 csv 파일 경로 및 파일명 지정\n",
    "#     file_name = './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "\n",
    "# college_name : 'Yale'\n",
    "# file_name =: './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "def input_name_of_college(college_name, file_name):\n",
    "    # import file to dataframe\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    i = 0\n",
    "    for i in range(len(df.index)):\n",
    "        # get major title data\n",
    "        mjr_title = df.iloc[i]['major_title']\n",
    "\n",
    "        # get info_type data\n",
    "        info_type = df.iloc[i]['info_type']\n",
    "\n",
    "        #get link data\n",
    "        linked_page = df.iloc[i]['Link']\n",
    "\n",
    "        # make file with full name\n",
    "        mk_file_full_name = college_name + \"_\" +  mjr_title + \"_\" + info_type + \"_info\" + \".txt\"\n",
    "\n",
    "        # dataframe에서 데이터 추출하고 파일명으로 저장하기\n",
    "        md_file = open(mk_file_full_name, 'w')\n",
    "        # Yale_African American Studies_general_keywords_info.txt\n",
    "\n",
    "        # 링크데이터로 크롤링하기\n",
    "        try:\n",
    "            get_linked_data = linked_search_result(linked_page)\n",
    "            \n",
    "            # 데이터 클린징 후 리스트로 만들기\n",
    "            cleaned_data = cleaning_data(str(get_linked_data))\n",
    "\n",
    "            # 리스트를 문자열로 변환\n",
    "            str_data = \" \".join(cleaned_data)\n",
    "\n",
    "            # 생성된 파일에 결과데이터 저장하기\n",
    "            md_file.write(str_data)\n",
    "\n",
    "            # 파일 닫기\n",
    "            md_file.close()\n",
    "\n",
    "            # add numb\n",
    "            i += 1\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            md_file.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "removed-crisis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimkwangil/opt/anaconda3/envs/py37pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "college_name = 'Yale'\n",
    "file_name = './college_datasets/Yale/Yale 교수 전공 및 general 모든 정보 link.csv'\n",
    "result = input_name_of_college(college_name, file_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-front",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
