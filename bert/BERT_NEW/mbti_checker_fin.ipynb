{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8c16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948e4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset into a DataFrame\n",
    "df = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbe966f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f603ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    8675 non-null   object\n",
      " 1   posts   8675 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#showing dataset infos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8945366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsaving the clean dataset into a csv file\\ndf.to_csv('mbti_clean_dataset.csv',index=False)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing URLs and punctuation from dataset\n",
    "for index in df.index.values:\n",
    "    df.posts.iloc[index] = ' '.join(df.posts.iloc[index].split('|||'))\n",
    "    df.posts.iloc[index] = re.sub(r\"http\\S+\",\"\",df.posts.iloc[index])\n",
    "    df.posts.iloc[index] = re.sub(r\"[-/@.?!_,:;()|0-9]\",\"\",df.posts.iloc[index])\n",
    "    df.posts.iloc[index] = ' '.join(df.posts.iloc[index].split('  '))\n",
    "\"\"\"\n",
    "saving the clean dataset into a csv file\n",
    "df.to_csv('mbti_clean_dataset.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2fa597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
       "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identifying the different classes of users in the dataset\n",
    "labels = df.type.unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434decce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INFJ',\n",
       " 'ENTP',\n",
       " 'INTP',\n",
       " 'INTJ',\n",
       " 'ENTJ',\n",
       " 'ENFJ',\n",
       " 'INFP',\n",
       " 'ENFP',\n",
       " 'ISFP',\n",
       " 'ISTP',\n",
       " 'ISFJ',\n",
       " 'ISTJ',\n",
       " 'ESTP',\n",
       " 'ESFP',\n",
       " 'ESTJ',\n",
       " 'ESFJ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping personality types with their numberical representation\n",
    "labels2 = []\n",
    "label_rep = {}\n",
    "for index,labels in enumerate(labels):\n",
    "    label_rep[labels] = index\n",
    "    labels2.append(labels)\n",
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741dd471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INFJ': 0,\n",
       " 'ENTP': 1,\n",
       " 'INTP': 2,\n",
       " 'INTJ': 3,\n",
       " 'ENTJ': 4,\n",
       " 'ENFJ': 5,\n",
       " 'INFP': 6,\n",
       " 'ENFP': 7,\n",
       " 'ISFP': 8,\n",
       " 'ISTP': 9,\n",
       " 'ISFJ': 10,\n",
       " 'ISTJ': 11,\n",
       " 'ESTP': 12,\n",
       " 'ESFP': 13,\n",
       " 'ESTJ': 14,\n",
       " 'ESFJ': 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726dd316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' enfp and intj moments  sportscenter not top ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one   Of course to which I say I know th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP  I enjoyed our conversation the oth...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired That's another silly misconcepti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>' Science is not perfect No scientist claims t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'No I can't draw on my own nails haha Those we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>I'm not sure that's a good question The distin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>' I'm in this position where I have to actuall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  label\n",
       "0  INFJ  ' enfp and intj moments  sportscenter not top ...      0\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...      1\n",
       "2  INTP  'Good one   Of course to which I say I know th...      2\n",
       "3  INTJ  'Dear INTP  I enjoyed our conversation the oth...      3\n",
       "4  ENTJ  'You're fired That's another silly misconcepti...      4\n",
       "5  INTJ  ' Science is not perfect No scientist claims t...      3\n",
       "6  INFJ  'No I can't draw on my own nails haha Those we...      0\n",
       "7  INTJ  'I tend to build up a collection of things on ...      3\n",
       "8  INFJ  I'm not sure that's a good question The distin...      0\n",
       "9  INTP  ' I'm in this position where I have to actuall...      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing each personality type with its numerical representation\n",
    "df['label'] = df.type.replace(label_rep)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57eae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "df.to_csv(\"mbti_cleaned_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9759ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from transformers.models.bert.modeling_bert import BertModel,BertForMaskedLM\n",
    "#from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0f4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25176fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mbti_cleaned_datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2958244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>' enfp and intj moments  sportscenter not top ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one   Of course to which I say I know th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP  I enjoyed our conversation the oth...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired That's another silly misconcepti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                              posts  label\n",
       "0           0  INFJ  ' enfp and intj moments  sportscenter not top ...      0\n",
       "1           1  ENTP  'I'm finding the lack of me in these posts ver...      1\n",
       "2           2  INTP  'Good one   Of course to which I say I know th...      2\n",
       "3           3  INTJ  'Dear INTP  I enjoyed our conversation the oth...      3\n",
       "4           4  ENTJ  'You're fired That's another silly misconcepti...      4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8dd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 8675 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948f93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select required columns\n",
    "data = data[['posts', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e99aa4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' enfp and intj moments  sportscenter not top ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one   Of course to which I say I know th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP  I enjoyed our conversation the oth...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired That's another silly misconcepti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  label\n",
       "0  ' enfp and intj moments  sportscenter not top ...      0\n",
       "1  'I'm finding the lack of me in these posts ver...      1\n",
       "2  'Good one   Of course to which I say I know th...      2\n",
       "3  'Dear INTP  I enjoyed our conversation the oth...      3\n",
       "4  'You're fired That's another silly misconcepti...      4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98e112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows, where the label is present only ones (can't be split)\n",
    "data = data.groupby('label').filter(lambda x : len(x) > 1)\n",
    "#data = data.groupby('Product').filter(lambda x : len(x) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c85d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' enfp and intj moments  sportscenter not top ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one   Of course to which I say I know th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP  I enjoyed our conversation the oth...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired That's another silly misconcepti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  label\n",
       "0  ' enfp and intj moments  sportscenter not top ...      0\n",
       "1  'I'm finding the lack of me in these posts ver...      1\n",
       "2  'Good one   Of course to which I say I know th...      2\n",
       "3  'Dear INTP  I enjoyed our conversation the oth...      3\n",
       "4  'You're fired That's another silly misconcepti...      4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39acef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Well I would recommend talkingi than practice...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Im a little bored and wanted to start a rando...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Ya girl if she is a prima donna like you've d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'How the passion is dying because of my financ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Women crushes Kristi Yamaguchi Rachel Weisz P...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>'  your favorite place in the whole town is th...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>'Hellish most certainly in fact i would most l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>'estj Yes I like travelling I've been to Ameri...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>'Wracking my brain and I don't think this is a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>'Really o it's the quiet ones you have to watc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts  label\n",
       "0     'Well I would recommend talkingi than practice...      5\n",
       "1     'Im a little bored and wanted to start a rando...      3\n",
       "2     'Ya girl if she is a prima donna like you've d...      1\n",
       "3     'How the passion is dying because of my financ...      3\n",
       "4     'Women crushes Kristi Yamaguchi Rachel Weisz P...      6\n",
       "...                                                 ...    ...\n",
       "8670  '  your favorite place in the whole town is th...      6\n",
       "8671  'Hellish most certainly in fact i would most l...      0\n",
       "8672  'estj Yes I like travelling I've been to Ameri...      8\n",
       "8673  'Wracking my brain and I don't think this is a...      5\n",
       "8674  'Really o it's the quiet ones you have to watc...      0\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shaffle datasets\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ce51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels:  [ 1  9  8 11 12  2  6  7  3  0  4  5 10 14 13 15]\n"
     ]
    }
   ],
   "source": [
    "data=data.dropna()                                                           # Drop NaN valuues, if any\n",
    "data=data.reset_index(drop=True)                                             # Reset index after dropping the columns/rows with NaN values\n",
    "data = shuffle(data)                                                         # Shuffle the dataset\n",
    "print('Available labels: ',data.label.unique())                              # Print all the unique labels in the dataset\n",
    "data['posts']=data['posts'].map(preprocess_sentence)                           # Clean the text column using preprocess_sentence function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85a018d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 8675 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>see thread entp forum reason first listen half...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>martian andy weir good istp got makeup today t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>actually girls happy dating year started going...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>even religion evil perpetuates narrow minded s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>isfp looking advice estjs estj friend performa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts  label\n",
       "7768  see thread entp forum reason first listen half...      1\n",
       "8128  martian andy weir good istp got makeup today t...      9\n",
       "7426  actually girls happy dating year started going...      8\n",
       "4474  even religion evil perpetuates narrow minded s...     11\n",
       "7195  isfp looking advice estjs estj friend performa...      8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea724645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=len(data.label.unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e876ec80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61a8c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'to', 'train', 'the', 'model', ',', 'lets', 'look', 'at', 'how', 'a', 'trained', 'model', 'calculate', '##s', 'its', 'prediction', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent= 'how to train the model, lets look at how a trained model calculates its prediction.'\n",
    "tokens=bert_tokenizer.tokenize(sent)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc83ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py36TorchTf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenized_sequence= bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =30,pad_to_max_length = True,\n",
    "return_attention_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3674fe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2129, 2000, 3345, 1996, 2944, 1010, 11082, 2298, 2012, 2129, 1037, 4738, 2944, 18422, 2015, 2049, 17547, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d26384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] how to train the model, lets look at how a trained model calculates its prediction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(tokenized_sequence['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6c5423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 8675)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences=data['posts']\n",
    "labels=data['label']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1c09b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=[] # 입력데디터 리스트 선언\n",
    "attention_masks=[] # 앞뒤 정보를 비교하여 마스크 예측하기 위한 리스트 선언\n",
    "\n",
    "for sent in sentences: # 문장하나씩 가져와서 인풋, 마스스크를 추가\n",
    "    # 문장을 숫자로 바꾼다. 짧은 문장은 패딩처리하고, 토큰화 한다.\n",
    "    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f22f7043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2156, 11689, ..., 22540,  2003,   102],\n",
       "       [  101, 20795,  5557, ...,  4699,  4994,   102],\n",
       "       [  101,  2941,  3057, ...,  9297,  2126,   102],\n",
       "       ...,\n",
       "       [  101, 10166,  4333, ...,  2147,  3849,   102],\n",
       "       [  101,  5702, 13869, ..., 28653,  3431,   102],\n",
       "       [  101,  2442,  6449, ...,  4312,  2036,   102]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e382f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ee653cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 9, 8, ..., 6, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b462e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 8675, 8675)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "960dcb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data_pc/bert_inp.pkl'\n",
    "pickle_mask_path='./data_pc/bert_mask.pkl'\n",
    "pickle_label_path='./data_pc/bert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5d51ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (8675, 64) Attention mask shape (8675, 64) Input label shape (8675,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2118f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2156, 11689, ..., 22540,  2003,   102],\n",
       "       [  101, 20795,  5557, ...,  4699,  4994,   102],\n",
       "       [  101,  2941,  3057, ...,  9297,  2126,   102],\n",
       "       ...,\n",
       "       [  101, 10166,  4333, ...,  2147,  3849,   102],\n",
       "       [  101,  5702, 13869, ..., 28653,  3431,   102],\n",
       "       [  101,  2442,  6449, ...,  4312,  2036,   102]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids # 입력문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68e36d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks # 마스크처리된 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc09819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 9, 8, ..., 6, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels # 문장당 레이블(5 가지 척도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8a0be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (6940, 64) Val input shape (1735, 64)\n",
      "Train label shape (6940,) Val label shape (1735,)\n",
      "Train attention mask shape (6940, 64) Val attention mask shape (1735, 64)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6af1da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 사용하는 데이터\n",
    "\n",
    "# input_ids : val_inp    --> 입력문장\n",
    "# val_mask --> 마스크처리된 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b170806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 26478,  8609, ...,  4465, 11895,   102],\n",
       "       [  101,  2817, 23347, ...,  2360,  2111,   102],\n",
       "       [  101,  3071,  3531, ...,  2094,  2190,   102],\n",
       "       ...,\n",
       "       [  101, 14145,  2080, ...,  2111,  4276,   102],\n",
       "       [  101,  5262,  5852, ...,  2627,  2086,   102],\n",
       "       [  101,  4169,  2088, ...,  3501,  3595,   102]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15ca12e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735, 64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b75b234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 0, ..., 1, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9855ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd8a0976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "caac8ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735, 64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c21836aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  12304     \n",
      "=================================================================\n",
      "Total params: 109,494,544\n",
      "Trainable params: 109,494,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Bert Model None\n"
     ]
    }
   ],
   "source": [
    "log_dir='tensorboard_data/tb_bert'\n",
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "print('\\nBert Model',bert_model.summary())\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "bert_model.compile(loss=loss,optimizer=optimizer,metrics=[metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "217/217 [==============================] - 47s 218ms/step - loss: 1.6533 - accuracy: 0.5027 - val_loss: 2.0530 - val_accuracy: 0.3873\n",
      "Epoch 2/100\n",
      "217/217 [==============================] - 47s 216ms/step - loss: 1.3396 - accuracy: 0.6157 - val_loss: 2.1699 - val_accuracy: 0.3787\n",
      "Epoch 3/100\n",
      "217/217 [==============================] - 47s 217ms/step - loss: 1.0268 - accuracy: 0.7122 - val_loss: 2.3469 - val_accuracy: 0.3683\n",
      "Epoch 4/100\n",
      "217/217 [==============================] - 48s 219ms/step - loss: 0.7508 - accuracy: 0.7938 - val_loss: 2.6685 - val_accuracy: 0.3487\n",
      "Epoch 5/100\n",
      "217/217 [==============================] - 47s 219ms/step - loss: 0.5256 - accuracy: 0.8646 - val_loss: 2.8910 - val_accuracy: 0.3343\n",
      "Epoch 6/100\n",
      "141/217 [==================>...........] - ETA: 15s - loss: 0.3870 - accuracy: 0.8980"
     ]
    }
   ],
   "source": [
    "\n",
    "history=bert_model.fit([train_inp,train_mask],train_label,batch_size=32,epochs=100,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a915d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "trained_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=16)\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "trained_model.load_weights(model_save_path)\n",
    "\n",
    "preds = trained_model.predict([val_inp,val_mask],batch_size=32)\n",
    "print('preds:', preds)\n",
    "print(type(preds))\n",
    "preds = preds['logits']\n",
    "print('preds_:', preds)\n",
    "# import numpy as np\n",
    "# pred_labels = np.argmax(preds)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "print('pred_labels', pred_labels)\n",
    "print('val_label', val_label)\n",
    "\n",
    "f1 = f1_score(val_label,pred_labels, average='micro')\n",
    "print('F1 score',f1)\n",
    "print('Classification Report')\n",
    "\n",
    "\n",
    "target_names = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP', 'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "print(classification_report(val_label,pred_labels,target_names=target_names))\n",
    "\n",
    "print('Training and saving built model.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sentnece label : lean_left\n",
    "\n",
    "sent_input = \"\"\"One Metropolitan Police officer who was beaten and tased during the riot, Michael Fanone, has advocated for the release of his body camera video and repeatedly criticized Republicans who've tried to downplay the violence during the insurrection.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 문장을 숫자로 바꾼다. 짧은 문장은 패딩처리하고, 토큰화 한다.\n",
    "bert_inp=bert_tokenizer.encode_plus(sent_input,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "input_ids=bert_inp['input_ids']\n",
    "attention_masks= bert_inp['attention_mask']\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2df64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae04f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21533851",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_inp : input_ids\n",
    "# val_mask : attention_masks\n",
    "\n",
    "preds = trained_model.predict([input_ids,attention_masks],batch_size=32)\n",
    "preds = preds['logits'] # 시그모이드함수 적용하여 데이터의 결과를 두 그룹으로 분류해본다. 0 or 1\n",
    "print(\"prieds'logit':\", preds)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "print('pred_labels', pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b203c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_labels)\n",
    "\n",
    "plt.title(\"MBTI AI\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.bincount(pred_labels)\n",
    "result = np.argmax(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a86784",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'INFJ': 0,\n",
    " 'ENTP': 1,\n",
    " 'INTP': 2,\n",
    " 'INTJ': 3,\n",
    " 'ENTJ': 4,\n",
    " 'ENFJ': 5,\n",
    " 'INFP': 6,\n",
    " 'ENFP': 7,\n",
    " 'ISFP': 8,\n",
    " 'ISTP': 9,\n",
    " 'ISFJ': 10,\n",
    " 'ISTJ': 11,\n",
    " 'ESTP': 12,\n",
    " 'ESFP': 13,\n",
    " 'ESTJ': 14,\n",
    " 'ESFJ': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbti(result):\n",
    "    if result == 0:\n",
    "        print('INFJ')\n",
    "        result = 'INFJ'\n",
    "    elif result == 1:\n",
    "        print('ENTP')\n",
    "        result = 'ENTP'\n",
    "    elif result == 2:\n",
    "        print('INTP')\n",
    "        result = 'INTP'\n",
    "    elif result == 3:\n",
    "        print('INTJ')\n",
    "        result = 'INTJ'\n",
    "    elif result == 4:\n",
    "        print('ENTJ')\n",
    "        result = 'ENTJ'\n",
    "    elif result == 5:\n",
    "        print('ENFJ')\n",
    "        result = 'ENFJ'\n",
    "    elif result == 6:\n",
    "        print('INFP')\n",
    "        result = 'INFP'\n",
    "    elif result == 7:\n",
    "        print('ENFP')\n",
    "        result = 'ENFP'\n",
    "    elif result == 8:\n",
    "        print('ISFP')\n",
    "        result = 'ISFP'\n",
    "    elif result == 9:\n",
    "        print('ISTP')\n",
    "        result = 'ISTP'\n",
    "    elif result == 10:\n",
    "        print('ISFJ')\n",
    "        result = 'ISFJ'\n",
    "    elif result == 11:\n",
    "        print('ISTJ')\n",
    "        result = 'ISTJ'\n",
    "    elif result == 12:\n",
    "        print('ESTP')\n",
    "        result = 'ESTP'\n",
    "    elif result == 13:\n",
    "        print('ESFP')\n",
    "        result = 'ESFP'\n",
    "    elif result == 14:\n",
    "        print('ESTJ')\n",
    "        result = 'ESTJ'\n",
    "    else:# reulst == 15:\n",
    "        print('ESFJ')\n",
    "        result = 'ESFJ'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d71f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Result = get_mbti(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fb851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b80453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29db03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b46f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b6f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
