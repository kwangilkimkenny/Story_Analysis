{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cacki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cacki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#conflict\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from mpld3 import plugins, fig_to_html, save_html, fig_to_dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "#character, setting\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import multiprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from gensim.models import Phrases\n",
    "from textblob import TextBlob\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ContainsBio(Enum):\n",
    "    YES = 1\n",
    "    NO = 0\n",
    "    MAYBE = 2\n",
    "\n",
    "\n",
    "def human_contains_pronouns(bio):\n",
    "    perfect_matches = ['he/him', 'she/her', 'they/them', 'ze', 'hir']\n",
    "    probably_matches = ['they', 'he', 'her', 'him', 'her', 'pronouns']\n",
    "\n",
    "    words = re.findall(r\"[\\w'/]+\", bio.lower())\n",
    "    for match in perfect_matches:\n",
    "        if match in words:\n",
    "            return ContainsBio.YES\n",
    "\n",
    "    for match in probably_matches:\n",
    "        if match in words:\n",
    "            return ContainsBio.MAYBE\n",
    "    return ContainsBio.NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text= \"\"\"A window into the soul.For most people, this would be the eyes. The eyes cannot lie; they often tell more about a person's emotions than their words. What distinguishes a fake smile from a genuine one? The eyes. What shows sadness? The eyes. What gives away a liar? The eyes.But are the eyes the only window into the soul?Recently, I began painting with watercolors. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again. Every stroke must be done purposefully, every color mixed to its exact value.I laid my materials before me, preparing myself for the worst. I checked my list of supplies, making sure my setup was perfect.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint. Too little water on my brush. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes. \\u2014It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. More alizarin crimson. More water. More yellow ochre. Less water. More phthalo blue. The cycle continued. Eventually, I was satisfied. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.Craving feedback, I posted my art to Snapchat. I got a few messages such as 'wow' and 'pretty,' but one message stood out. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.What I didn't know at the time was that my response would come a few months later while babysitting. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with. After I went to the bathroom and came back, the watercolors were doused with water. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.''Oh.'Now, I would be lying if I said I realized the connection between the two events immediately.Instead, I made the connection when I decided to sit down one day and objectively critique my art. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.When I peer around at people's projects during Code Club, I notice the clear differences between their code. Some people break it up by commenting in every possible section. Others breeze through the project, not caring to comment or organize their code. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. I shakily rose my hand. 'We should create workshops of our own,' I suggested.I got a few strange looks. 'It's a good idea, but it's too much work.' 'We just don't have enough free time to make it work.' 'Maybe we could, but I don't know how to make workshops.' My suggestion was shot down. I shuffled in my seat. 'I could make them.' A few people stared at me in disbelief. I glanced over at the club advisor, Mr. C, nervous to hear his response.'If you're willing to take on the work, we can try it.' Mr. C replied. And so I embarked on my quest. I researched different workshops on the internet, learning the information myself at first. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner. I was exhausted; my first workshop took 16 cumulative hours to create.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ContainsBio.MAYBE: 2>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humnan_pronoun = human_contains_pronouns(input_text)\n",
    "humnan_pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anaphoric reference\n",
    "\n",
    "def pronouns_Anaphoric(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    \n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #OVERLAP 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['all','another','any','anybody','anyone','anything','as','aught','both','each'\n",
    "                    ,'each other','either','enough','everybody','everyone','everything','few','he','her','hers','herself','him','his','I'\n",
    "                    ,'idem','it','its','itself','many','me','mine','most','my','myself','naught','neither','no one','nobody','none'\n",
    "                    ,'nothing','nought','one','one another','other','others','ought','our','ours','ourself','ourselves','several'\n",
    "                    ,'she','some','somebody','someone','something','somewhat','such','suchlike','that','thee','their','theirs'\n",
    "                    ,'theirself','theirselves','them','themself','themselves','there','these','they','thine','this','those','thou'\n",
    "                    ,'thy','thyself','us','we','what','whatever','whatnot','whatsoever','whence','where','whereby','wherefrom','wherein'\n",
    "                    ,'whereinto','whereof','whereon','wherever','wheresoever','whereto','whereunto','wherewith','wherewithal','whether'\n",
    "                    ,'which','whichever','whichsoever','who','whoever','whom','whomever','whomso','whomsoever','whose','whosever','whosesoever'\n",
    "                    ,'whoso','whosoever','ye','yon','yonder','you','your','yours','yourself','yourselves']\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    #print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    pronouns_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    pronouns_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_pronouns_ratio = round(pronouns_total_count/total_words * 100, 2)\n",
    "\n",
    "    #return result_pronouns_ratio, total_sentences, total_words, pronouns_total_count, char_count_, ext_sim_words_key\n",
    "    return result_pronouns_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:59: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "anaphoric_reference = pronouns_Anaphoric(input_text)\n",
    "anaphoric_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동사, 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('window', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('soul.For', 'NN'),\n",
       " ('most', 'JJS'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('eyes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('eyes', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('lie', 'VB'),\n",
       " (';', ':'),\n",
       " ('they', 'PRP'),\n",
       " ('often', 'RB'),\n",
       " ('tell', 'VBP'),\n",
       " ('more', 'JJR'),\n",
       " ('about', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('person', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('emotions', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('words', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('distinguishes', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('fake', 'JJ'),\n",
       " ('smile', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('genuine', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('?', '.'),\n",
       " ('The', 'DT'),\n",
       " ('eyes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('shows', 'VBZ'),\n",
       " ('sadness', 'NN'),\n",
       " ('?', '.'),\n",
       " ('The', 'DT'),\n",
       " ('eyes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('gives', 'VBZ'),\n",
       " ('away', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('liar', 'NN'),\n",
       " ('?', '.'),\n",
       " ('The', 'DT'),\n",
       " ('eyes.But', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('eyes', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('only', 'JJ'),\n",
       " ('window', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('soul', 'NN'),\n",
       " ('?', '.'),\n",
       " ('Recently', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('began', 'VBD'),\n",
       " ('painting', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('watercolors', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('With', 'IN'),\n",
       " ('watercolors', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('is', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('turning', 'VBG'),\n",
       " ('back', 'RB'),\n",
       " (':', ':'),\n",
       " ('if', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('section', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('too', 'RB'),\n",
       " ('dark', 'JJ'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('nearly', 'RB'),\n",
       " ('impossible', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('lighten', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('area', 'NN'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Every', 'NNP'),\n",
       " ('stroke', 'NN'),\n",
       " ('must', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('done', 'VBN'),\n",
       " ('purposefully', 'RB'),\n",
       " (',', ','),\n",
       " ('every', 'DT'),\n",
       " ('color', 'NN'),\n",
       " ('mixed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('its', 'PRP$'),\n",
       " ('exact', 'JJ'),\n",
       " ('value.I', 'NN'),\n",
       " ('laid', 'VBD'),\n",
       " ('my', 'PRP$'),\n",
       " ('materials', 'NNS'),\n",
       " ('before', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " (',', ','),\n",
       " ('preparing', 'VBG'),\n",
       " ('myself', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('worst', 'JJS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('checked', 'VBD'),\n",
       " ('my', 'PRP$'),\n",
       " ('list', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('supplies', 'NNS'),\n",
       " (',', ','),\n",
       " ('making', 'VBG'),\n",
       " ('sure', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('setup', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('perfect.I', 'JJ'),\n",
       " ('wet', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('brush', 'NN'),\n",
       " (',', ','),\n",
       " ('dipped', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('into', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('yellow', 'JJ'),\n",
       " ('ochre', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('dabbed', 'VBD'),\n",
       " ('off', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('excess', 'JJ'),\n",
       " ('paint', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Too', 'NNP'),\n",
       " ('little', 'JJ'),\n",
       " ('water', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('brush', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('dipped', 'VBD'),\n",
       " ('my', 'PRP$'),\n",
       " ('brush', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('into', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('trusty', 'JJ'),\n",
       " ('water', 'NN'),\n",
       " ('jar', 'NN'),\n",
       " (';', ':'),\n",
       " ('the', 'DT'),\n",
       " ('colors', 'NNS'),\n",
       " ('swirled', 'VBD'),\n",
       " ('beautifully', 'RB'),\n",
       " (',', ','),\n",
       " ('forming', 'VBG'),\n",
       " ('an', 'DT'),\n",
       " ('abstract', 'JJ'),\n",
       " ('art', 'NN'),\n",
       " ('piece', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('eyes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('—It', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('a', 'DT'),\n",
       " ('shame', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('appreciate', 'VB'),\n",
       " ('it.I', 'JJ'),\n",
       " ('continued', 'VBN'),\n",
       " ('mixing', 'VBG'),\n",
       " ('colors', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('their', 'PRP$'),\n",
       " ('exact', 'JJ'),\n",
       " ('value', 'NN'),\n",
       " ('.', '.'),\n",
       " ('More', 'JJR'),\n",
       " ('alizarin', 'JJ'),\n",
       " ('crimson', 'NN'),\n",
       " ('.', '.'),\n",
       " ('More', 'JJR'),\n",
       " ('water', 'NN'),\n",
       " ('.', '.'),\n",
       " ('More', 'JJR'),\n",
       " ('yellow', 'JJ'),\n",
       " ('ochre', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Less', 'NNP'),\n",
       " ('water', 'NN'),\n",
       " ('.', '.'),\n",
       " ('More', 'JJR'),\n",
       " ('phthalo', 'JJ'),\n",
       " ('blue', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('cycle', 'NN'),\n",
       " ('continued', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('Eventually', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('satisfied', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('colors', 'NNS'),\n",
       " ('looked', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('enough', 'JJ'),\n",
       " ('contrast', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('facial', 'JJ'),\n",
       " ('features', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('watercolors', 'NNS'),\n",
       " ('stayed', 'VBD'),\n",
       " ('inside', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lines.Craving', 'JJ'),\n",
       " ('feedback', 'NN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('posted', 'VBD'),\n",
       " ('my', 'PRP$'),\n",
       " ('art', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Snapchat', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('messages', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " (\"'wow\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " ('and', 'CC'),\n",
       " (\"'pretty\", 'CD'),\n",
       " (',', ','),\n",
       " (\"'\", \"''\"),\n",
       " ('but', 'CC'),\n",
       " ('one', 'CD'),\n",
       " ('message', 'NN'),\n",
       " ('stood', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('.', '.'),\n",
       " (\"'You\", 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('anxious', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('one', 'CD'),\n",
       " (',', ','),\n",
       " ('huh', 'NN'),\n",
       " ('?', '.'),\n",
       " ('Anyways', 'NNP'),\n",
       " (',', ','),\n",
       " ('love', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('hair', 'NN'),\n",
       " ('!', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('caught', 'VBN'),\n",
       " ('off', 'RP'),\n",
       " ('guard', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Was', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('lucky', 'JJ'),\n",
       " ('guess', 'NN'),\n",
       " ('?', '.'),\n",
       " ('Did', 'NNP'),\n",
       " ('they', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('something', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('?', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('immediately', 'RB'),\n",
       " ('responded', 'VBD'),\n",
       " (':', ':'),\n",
       " (\"'Haha\", 'NN'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('could', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('tell', 'VB'),\n",
       " ('?', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('No', 'DT'),\n",
       " ('response.What', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('response', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('come', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('later', 'RB'),\n",
       " ('while', 'IN'),\n",
       " ('babysitting', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('Since', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('girl', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('babysitting', 'VBG'),\n",
       " ('loved', 'JJ'),\n",
       " ('art', 'NN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('took', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('some', 'DT'),\n",
       " ('Crayola', 'NNP'),\n",
       " ('watercolors', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('watercolor', 'JJ'),\n",
       " ('paper', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('to', 'TO'),\n",
       " ('play', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('.', '.'),\n",
       " ('After', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('bathroom', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('came', 'VBD'),\n",
       " ('back', 'RB'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('watercolors', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('doused', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('water', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'You\", 'CC'),\n",
       " ('were', 'VBD'),\n",
       " ('impatient', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('one', 'CD'),\n",
       " (',', ','),\n",
       " ('huh', 'NN'),\n",
       " ('?', '.'),\n",
       " ('Anyways', 'NNP'),\n",
       " (',', ','),\n",
       " ('love', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('drew', 'VBD'),\n",
       " ('!', '.'),\n",
       " (\"'The\", 'POS'),\n",
       " ('little', 'JJ'),\n",
       " ('girl', 'NN'),\n",
       " ('looked', 'VBD'),\n",
       " ('up', 'RP'),\n",
       " ('at', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " (',', ','),\n",
       " ('confused', 'VBD'),\n",
       " ('.', '.'),\n",
       " (\"'How\", 'WRB'),\n",
       " ('could', 'MD'),\n",
       " ('you', 'PRP'),\n",
       " ('tell', 'VB'),\n",
       " ('?', '.'),\n",
       " (\"'\", \"''\"),\n",
       " (\"'You\", 'VBZ'),\n",
       " ('used', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('water', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('brighter', 'NN'),\n",
       " ('color', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('wait', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('slowly', 'VB'),\n",
       " ('soak', 'JJ'),\n",
       " ('in.', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('Oh', 'NNP'),\n",
       " ('.', '.'),\n",
       " (\"'Now\", 'CD'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('lying', 'VBG'),\n",
       " ('if', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('I', 'PRP'),\n",
       " ('realized', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('connection', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('two', 'CD'),\n",
       " ('events', 'NNS'),\n",
       " ('immediately.Instead', 'JJ'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('made', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('connection', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PRP'),\n",
       " ('decided', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('sit', 'VB'),\n",
       " ('down', 'RP'),\n",
       " ('one', 'CD'),\n",
       " ('day', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('objectively', 'RB'),\n",
       " ('critique', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('art', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('piece', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('once', 'RB'),\n",
       " ('loved', 'VBD'),\n",
       " ('now', 'RB'),\n",
       " ('seemed', 'VBN'),\n",
       " ('like', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nervous', 'JJ'),\n",
       " ('wreck', 'NN'),\n",
       " (':', ':'),\n",
       " ('the', 'DT'),\n",
       " ('paper', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('overworked', 'VBN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('brushstrokes', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('undecided', 'JJ'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('facial', 'JJ'),\n",
       " ('features', 'NNS'),\n",
       " ('blended', 'VBD'),\n",
       " ('together', 'RB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('each', 'DT'),\n",
       " ('drop', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('water', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('bound', 'VBN'),\n",
       " ('inside', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lines', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('prisoner', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('cage.From', 'NN'),\n",
       " ('then', 'RB'),\n",
       " ('on', 'IN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('started', 'VBD'),\n",
       " ('noticing', 'VBG'),\n",
       " ('pieces', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('personality', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('additional', 'JJ'),\n",
       " ('creations', 'NNS'),\n",
       " ('surrounding', 'VBG'),\n",
       " ('me', 'PRP'),\n",
       " (':', ':'),\n",
       " ('website', 'JJ'),\n",
       " ('designs', 'NNS'),\n",
       " (',', ','),\n",
       " ('solutions', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('math', 'VB'),\n",
       " ('problems', 'NNS'),\n",
       " (',', ','),\n",
       " ('code', 'NNS'),\n",
       " ('written', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('class', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('preparation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('meal.When', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('peer', 'VBP'),\n",
       " ('around', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " (\"'s\", 'POS'),\n",
       " ('projects', 'NNS'),\n",
       " ('during', 'IN'),\n",
       " ('Code', 'NNP'),\n",
       " ('Club', 'NNP'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('notice', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('clear', 'JJ'),\n",
       " ('differences', 'NNS'),\n",
       " ('between', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('code', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Some', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('break', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('up', 'RP'),\n",
       " ('by', 'IN'),\n",
       " ('commenting', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('possible', 'JJ'),\n",
       " ('section', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Others', 'NNS'),\n",
       " ('breeze', 'VBP'),\n",
       " ('through', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('project', 'NN'),\n",
       " (',', ','),\n",
       " ('not', 'RB'),\n",
       " ('caring', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('comment', 'VB'),\n",
       " ('or', 'CC'),\n",
       " ('organize', 'VB'),\n",
       " ('their', 'PRP$'),\n",
       " ('code', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('see', 'VB'),\n",
       " ('clear', 'JJ'),\n",
       " ('differences', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('personalities', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('our', 'PRP$'),\n",
       " ('club', 'NN'),\n",
       " ('members', 'NNS'),\n",
       " ('began', 'VBD'),\n",
       " ('coding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('Arduino', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Some', 'DT'),\n",
       " ('followed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('tutorials', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('letter', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('others', 'NNS'),\n",
       " ('immediately', 'RB'),\n",
       " ('started', 'VBD'),\n",
       " ('experimenting', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('different', 'JJ'),\n",
       " ('colored', 'VBN'),\n",
       " ('LEDs', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('ways', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('wiring', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('circuit.It', 'NN'),\n",
       " ('became', 'VBD'),\n",
       " ('clear', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('me', 'PRP'),\n",
       " ('that', 'RB'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('humans', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('leave', 'VBP'),\n",
       " ('pieces', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('souls', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('everything', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (',', ','),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('intend', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('.', '.'),\n",
       " ('If', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('entertain', 'VBP'),\n",
       " ('this', 'DT'),\n",
       " ('thought', 'NN'),\n",
       " (',', ','),\n",
       " ('perhaps', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('key', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('better', 'RBR'),\n",
       " ('understanding', 'VBG'),\n",
       " ('others', 'NNS'),\n",
       " ('around', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('simply', 'RB'),\n",
       " ('noticing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('subtler', 'NN'),\n",
       " ('clues', 'NNS'),\n",
       " ('under', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('noses', 'NNS'),\n",
       " ('?', '.'),\n",
       " ('Perhaps', 'RB'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('endless', 'JJ'),\n",
       " ('windows', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('soul', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('simply', 'RB'),\n",
       " ('need', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('peer', 'VB'),\n",
       " ('through', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('shakily', 'RB'),\n",
       " ('rose', 'VBD'),\n",
       " ('my', 'PRP$'),\n",
       " ('hand', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'We\", 'CC'),\n",
       " ('should', 'MD'),\n",
       " ('create', 'VB'),\n",
       " ('workshops', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " (',', ','),\n",
       " (\"'\", \"''\"),\n",
       " ('I', 'PRP'),\n",
       " ('suggested.I', 'VBP'),\n",
       " ('got', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('strange', 'JJ'),\n",
       " ('looks', 'NNS'),\n",
       " ('.', '.'),\n",
       " (\"'It\", 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('too', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " (\"'We\", 'JJ'),\n",
       " ('just', 'RB'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('enough', 'RB'),\n",
       " ('free', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('work', 'VB'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " (\"'Maybe\", 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('workshops', 'NNS'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('My', 'PRP$'),\n",
       " ('suggestion', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('shot', 'VBN'),\n",
       " ('down', 'RB'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('shuffled', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('seat', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('I', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('A', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('stared', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('disbelief', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('glanced', 'VBD'),\n",
       " ('over', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('club', 'NN'),\n",
       " ('advisor', 'NN'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('C', 'NNP'),\n",
       " (',', ','),\n",
       " ('nervous', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('hear', 'VB'),\n",
       " ('his', 'PRP$'),\n",
       " ('response', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'If\", 'CC'),\n",
       " ('you', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('willing', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('work', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('try', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " (\"'\", \"''\"),\n",
       " ('Mr.', 'NNP'),\n",
       " ('C', 'NNP'),\n",
       " ('replied', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('embarked', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('quest', 'JJS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('researched', 'VBD'),\n",
       " ('different', 'JJ'),\n",
       " ('workshops', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('internet', 'NN'),\n",
       " (',', ','),\n",
       " ('learning', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('myself', 'PRP'),\n",
       " ('at', 'IN'),\n",
       " ('first', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Then', 'RB'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('transitioned', 'VBD'),\n",
       " ('into', 'IN'),\n",
       " ('creating', 'VBG'),\n",
       " ('workshops', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " (',', ','),\n",
       " ('making', 'VBG'),\n",
       " ('sure', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('easy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('understand', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('even', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('beginner', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('exhausted', 'VBN'),\n",
       " (';', ':'),\n",
       " ('my', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('workshop', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('16', 'CD'),\n",
       " ('cumulative', 'JJ'),\n",
       " ('hours', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('create', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(input_text)\n",
    "pos_tagged = nltk.pos_tag(text)\n",
    "pos_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = list(filter(lambda x:x[1]=='NN',pos_tagged))\n",
    "nouns_no = len(nouns)\n",
    "nouns_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbzs = list(filter(lambda x:x[1]=='VBZ',pos_tagged))\n",
    "vbzs_no  = len(vbzs)\n",
    "vbzs_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connectives analysis\n",
    "def connecitve_words_ratio(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    \n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #OVERLAP 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = [after a while\n",
    "afterwards\n",
    "at once\n",
    "at this moment\n",
    "at this point\n",
    "before that\n",
    "finally\n",
    "first (second third etc...)\n",
    "here\n",
    "in the end\n",
    "lastly\n",
    "later on\n",
    "meanwhile\n",
    "next\n",
    "next time\n",
    "now\n",
    "on another occasion\n",
    "previously\n",
    "since\n",
    "soon\n",
    "straightaway\n",
    "then\n",
    "until then\n",
    "when\n",
    "whenever\n",
    "while\n",
    "besides\n",
    "e.g.\n",
    "for example\n",
    "for instance\n",
    "i.e.\n",
    "in other words\n",
    "in that\n",
    "that is to say\n",
    "first \n",
    "second\n",
    "firstly \n",
    "secondly\n",
    "first of all\n",
    "finally\n",
    "lastly\n",
    "for one thing\n",
    "for another\n",
    "in the first place\n",
    "to begin with\n",
    "next\n",
    "in summation\n",
    "to conclude\n",
    "additionally\n",
    "also\n",
    "as well\n",
    "even\n",
    "furthermore\n",
    "in addition\n",
    "indeed\n",
    "let alone\n",
    "moreover\n",
    "not only\n",
    "accordingly\n",
    "all the same\n",
    "an effect of\n",
    "an outcome of\n",
    "an upshot of\n",
    "as a consequence of\n",
    "as a result of\n",
    "because\n",
    "caused by\n",
    "consequently\n",
    "despite this\n",
    "even though\n",
    "hence\n",
    "however\n",
    "in that case\n",
    "moreover\n",
    "nevertheless\n",
    "otherwise\n",
    "so\n",
    "so as\n",
    "stemmed from\n",
    "still\n",
    "then\n",
    "therefore\n",
    "though\n",
    "under the circumstances\n",
    "yet\n",
    "alternatively\n",
    "anyway\n",
    "but\n",
    "by contrast\n",
    "differs from\n",
    "elsewhere\n",
    "even so\n",
    "however\n",
    "in contrast\n",
    "in fact\n",
    "in other respects\n",
    "in spite of this\n",
    "in that respect\n",
    "instead\n",
    "nevertheless\n",
    "on the contrary\n",
    "on the other hand\n",
    "rather\n",
    "though\n",
    "whereas\n",
    "accordingly\n",
    "as a result\n",
    "as exemplified by\n",
    "consequently\n",
    "for example\n",
    "for instance\n",
    "for one thing\n",
    "including\n",
    "provided that\n",
    "since\n",
    "so\n",
    "such as\n",
    "then\n",
    "therefore\n",
    "these include\n",
    "through\n",
    "unless\n",
    "without\n",
    "                     ]\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    #print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "\n",
    "    #return result_char_ratio, total_sentences, total_words, char_total_count, char_count_, ext_sim_words_key\n",
    "    return result_char_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
