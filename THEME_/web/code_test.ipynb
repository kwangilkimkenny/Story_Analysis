{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ques_one = ['A','B','C','D','E']\n",
    "input_data_preprocessed = ['A', 'a', 'b' ,'c', 'B', 'b', 'c', 'd' ,'C', 'c', 'd' ,'e' ,'E', 'e' ,'f', 'g']\n",
    "que_no_one_sim_words_ratio_result = ['melodious',\n",
    " 'heritage',\n",
    " 'peculiarity',\n",
    " 'circumspection',\n",
    " 'enlightenments',\n",
    " 'barriers',\n",
    " 'accord',\n",
    " 'generational',\n",
    " 'moretraditional',\n",
    " 'guarantees',\n",
    " 'persons',\n",
    " 'divider',\n",
    " 'consulate',\n",
    " 'flavors',\n",
    " 'uninhibited',\n",
    " 'advantageous',\n",
    " 'multiplicity',\n",
    " 'wasbrought',\n",
    " 'thatmy',\n",
    " 'inferiority',\n",
    " 'traditions',\n",
    " 'uncompartmentalizable',\n",
    " 'heterogeneous',\n",
    " 'background',\n",
    " 'polarisation',\n",
    " 'equalizer',\n",
    " 'lithuania',\n",
    " 'linguistic',\n",
    " 'begets',\n",
    " 'unnecessary',\n",
    " 'seller',\n",
    " 'cravea',\n",
    " 'ethnic',\n",
    " 'regrettably',\n",
    " 'unlikelymenagerie',\n",
    " 'inhibition',\n",
    " 'accommodating',\n",
    " 'cuisines',\n",
    " 'confucianist',\n",
    " 'combination_of',\n",
    " 'sworn',\n",
    " 'authorities',\n",
    " 'meto',\n",
    " 'partof',\n",
    " 'colonization',\n",
    " 'cuisine',\n",
    " 'conduit',\n",
    " 'prominence',\n",
    " 'every_aspect',\n",
    " 'articulate']\n",
    "\n",
    "\n",
    "in_text = ['melodious',\n",
    " 'heritage',\n",
    " 'peculiarity',\n",
    " 'circumspection',\n",
    " 'enlightenments',\n",
    " 'barriers',\n",
    " 'accord',\n",
    " 'generational',\n",
    " 'moretraditional',\n",
    " 'guarantees',\n",
    " 'persons',\n",
    " 'divider',\n",
    " 'consulate',\n",
    " 'flavors',\n",
    " 'uninhibited',\n",
    " 'advantageous',\n",
    " 'multiplicity',\n",
    " 'wasbrought',\n",
    " 'thatmy',\n",
    " 'inferiority',\n",
    " 'traditions',\n",
    " 'uncompartmentalizable',\n",
    " 'heterogeneous',\n",
    " 'background',\n",
    " 'polarisation',\n",
    " 'equalizer',\n",
    " 'lithuania',\n",
    " 'linguistic',\n",
    " 'begets',\n",
    " 'unnecessary',\n",
    " 'seller',\n",
    " 'cravea',\n",
    " 'ethnic',\n",
    " 'regrettably',\n",
    " 'unlikelymenagerie',\n",
    " 'inhibition',\n",
    " 'accommodating',\n",
    " 'cuisines',\n",
    " 'confucianist',\n",
    " 'combination_of',\n",
    " 'sworn',\n",
    " 'authorities',\n",
    " 'meto',\n",
    " 'partof',\n",
    " 'colonization',\n",
    " 'cuisine',\n",
    " 'conduit',\n",
    " 'prominence',\n",
    " 'every_aspect',\n",
    " 'articulate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doctovec_run(text):\n",
    "    print(\"processsssing......\")\n",
    "    print('in_text:', in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j A\n",
      "input_data_preprocessed.index(k): 0\n",
      "len(que_no_one_sim_words_ratio_result)+1: 51\n",
      "processsssing......\n",
      "in_text: ['A', 'a', 'b', 'c', 'B', 'b', 'c', 'd', 'C', 'c', 'd', 'e', 'E', 'e', 'f', 'g']\n",
      "j B\n",
      "input_data_preprocessed.index(k): 4\n",
      "len(que_no_one_sim_words_ratio_result)+1: 51\n",
      "processsssing......\n",
      "in_text: ['B', 'b', 'c', 'd', 'C', 'c', 'd', 'e', 'E', 'e', 'f', 'g']\n",
      "j C\n",
      "input_data_preprocessed.index(k): 8\n",
      "len(que_no_one_sim_words_ratio_result)+1: 51\n",
      "processsssing......\n",
      "in_text: ['C', 'c', 'd', 'e', 'E', 'e', 'f', 'g']\n",
      "j E\n",
      "input_data_preprocessed.index(k): 12\n",
      "len(que_no_one_sim_words_ratio_result)+1: 51\n",
      "processsssing......\n",
      "in_text: ['E', 'e', 'f', 'g']\n"
     ]
    }
   ],
   "source": [
    "count_ = 1\n",
    "while count_ != len(result_ques_one):\n",
    "    for j in result_ques_one: #학생데이터를 하나씩 가져와서\n",
    "        for k in input_data_preprocessed: # 합친데이터를 하나씩 꺼내서\n",
    "            if j == k: #같으면, 그 위치로부터 시작해서 비교 구간까지의 데이터를 꺼내온다.\n",
    "                print('j',j)\n",
    "                print('input_data_preprocessed.index(k):', input_data_preprocessed.index(k))\n",
    "                print('len(que_no_one_sim_words_ratio_result)+1:',len(que_no_one_sim_words_ratio_result)+1)\n",
    "                in_text = input_data_preprocessed[input_data_preprocessed.index(k):len(que_no_one_sim_words_ratio_result)+1]\n",
    "                 # 첫 계산을 하고, 다음 구간으로 넘어가자\n",
    "                count_ += 1\n",
    "                doctovec_run(in_text) #함수실행\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
