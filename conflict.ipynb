{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cacki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cacki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from mpld3 import plugins, fig_to_html, save_html, fig_to_dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"A window into the soul.For most people, this would be the eyes. The eyes cannot lie; they often tell more about a person's emotions than their words. What distinguishes a fake smile from a genuine one? The eyes. What shows sadness? The eyes. What gives away a liar? The eyes.But are the eyes the only window into the soul?Recently, I began painting with watercolors. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again. Every stroke must be done purposefully, every color mixed to its exact value.I laid my materials before me, preparing myself for the worst. I checked my list of supplies, making sure my setup was perfect.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint. Too little water on my brush. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes. \\u2014It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. More alizarin crimson. More water. More yellow ochre. Less water. More phthalo blue. The cycle continued. Eventually, I was satisfied. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.Craving feedback, I posted my art to Snapchat. I got a few messages such as 'wow' and 'pretty,' but one message stood out. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.What I didn't know at the time was that my response would come a few months later while babysitting. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with. After I went to the bathroom and came back, the watercolors were doused with water. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.''Oh.'Now, I would be lying if I said I realized the connection between the two events immediately.Instead, I made the connection when I decided to sit down one day and objectively critique my art. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.When I peer around at people's projects during Code Club, I notice the clear differences between their code. Some people break it up by commenting in every possible section. Others breeze through the project, not caring to comment or organize their code. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. I shakily rose my hand. 'We should create workshops of our own,' I suggested.I got a few strange looks. 'It's a good idea, but it's too much work.' 'We just don't have enough free time to make it work.' 'Maybe we could, but I don't know how to make workshops.' My suggestion was shot down. I shuffled in my seat. 'I could make them.' A few people stared at me in disbelief. I glanced over at the club advisor, Mr. C, nervous to hear his response.'If you're willing to take on the work, we can try it.' Mr. C replied. And so I embarked on my quest. I researched different workshops on the internet, learning the information myself at first. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner. I was exhausted; my first workshop took 16 cumulative hours to create.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list_str = text_to_word_sequence(contents) #tokenize\n",
    "\n",
    "confict_words_list = ['clash', 'incompatible', 'inconsistent', 'incongruous', 'opposition', 'variance','vary', 'odds', \n",
    "                        'differ', 'diverge', 'disagree', 'contrast', 'collide', 'contradictory', 'incompatible', 'conflict',\n",
    "                        'inconsistent','irreconcilable','incongruous','contrary','opposite','opposing','opposed',\n",
    "                        'antithetical','clashing','discordant','differing','different','divergent','discrepant',\n",
    "                        'varying','disagreeing','contrasting','at odds','in opposition','at variance' ]\n",
    "\n",
    "count_conflict_list = []\n",
    "for i in token_list_str:\n",
    "    for j in confict_words_list:\n",
    "        if i == j:\n",
    "            count_conflict_list.append(j)\n",
    "                \n",
    "len(count_conflict_list)#한 문장에 들어있는 conflict 단어 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 5924.29it/s]\n"
     ]
    }
   ],
   "source": [
    "list_str = contents.split(\".\")  #문장별로 분리한다. 분리는 .를 기준으로 한다.   \n",
    "\n",
    "\n",
    "listSentiment = []\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "i=0\n",
    "for sentence in tqdm(list_str): #한문장식 가져와서 처리한다.\n",
    "    ss = sid.polarity_scores(sentence) #긍정, 부정, 중립, 혼합점수 계산\n",
    "    #print(ss.keys())\n",
    "    #print('{}: neg:{},neu:{},pos:{},compound:{}'.format(i,ss['neg'],ss['neu'],ss['pos'],ss['compound']))\n",
    "    #print('{}: neg:{}'.format(i,ss['neg']))\n",
    "    i +=1\n",
    "    listSentiment.append([ss['neg'],ss['neu'],ss['pos'],ss['compound']])\n",
    "\n",
    "listSentiment\n",
    "df = pd.DataFrame(listSentiment)\n",
    "df.columns = ['neg', 'neu', 'pos','compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg    neu    pos  compound\n",
       "0   0.000  1.000  0.000    0.0000\n",
       "1   0.000  1.000  0.000    0.0000\n",
       "2   0.000  1.000  0.000    0.0000\n",
       "3   0.246  0.556  0.198   -0.1531\n",
       "4   0.420  0.580  0.000   -0.4404\n",
       "..    ...    ...    ...       ...\n",
       "60  0.000  1.000  0.000    0.0000\n",
       "61  0.000  1.000  0.000    0.0000\n",
       "62  0.000  0.697  0.303    0.7506\n",
       "63  0.184  0.662  0.154   -0.1027\n",
       "64  0.000  0.000  0.000    0.0000\n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound comp_score\n",
       "0  0.000  1.000  0.000    0.0000        pos\n",
       "1  0.000  1.000  0.000    0.0000        pos\n",
       "2  0.000  1.000  0.000    0.0000        pos\n",
       "3  0.246  0.556  0.198   -0.1531        neg\n",
       "4  0.420  0.580  0.000   -0.4404        neg\n",
       "5  0.398  0.602  0.000   -0.5106        neg\n",
       "6  0.000  1.000  0.000    0.0000        pos\n",
       "7  0.095  0.905  0.000   -0.2960        neg\n",
       "8  0.000  0.833  0.167    0.3400        pos\n",
       "9  0.313  0.687  0.000   -0.6249        neg"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0  else 'neg')\n",
    "\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    52\n",
       "neg    13\n",
       "Name: comp_score, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comp_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_ratio = df['comp_score'].value_counts(normalize=True) #상대적 비율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    0.8\n",
       "neg    0.2\n",
       "Name: comp_score, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### 입력받은 데이터 처리 실행 메소드 story_structure_anaysis() #######\n",
    "def story_stucture_anaysis(text):\n",
    "    contents = str(text)\n",
    "    contents_ = contents.lower()\n",
    "    list_str = contents_.split(\".\")  #문장별로 분리한다. 분리는 .를 기준으로 한다.   \n",
    "    \n",
    "    #등장인물 추출\n",
    "    #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                      'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                    'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                    'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                    'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                    'twin','uncle','widow','widower','wife','ex-wife']\n",
    "    \n",
    "    token_list_str = tokenize(list_str) #tokenize\n",
    "    count_char_list = []\n",
    "    for i in token_list_str:\n",
    "        for j character_list:\n",
    "            if i == j:\n",
    "                count_char_list.append(j)\n",
    "    \n",
    "    len(count_char_list)#한 문장에 들어있는 등장인물 수 \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    listSentiment = []\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    i=0\n",
    "    for sentence in tqdm(list_str): #한문장식 가져와서 처리한다.\n",
    "        ss = sid.polarity_scores(sentence) #긍정, 부정, 중립, 혼합점수 계산\n",
    "        print(ss.keys())\n",
    "        print('{}: neg:{},neu:{},pos:{},compound:{}'.format(i,ss['neg'],ss['neu'],ss['pos'],ss['compound']))\n",
    "        i +=1\n",
    "        listSentiment.append([ss['neg'],ss['neu'],ss['pos']])\n",
    "\n",
    "\n",
    "    maxlistSentment = []\n",
    "\n",
    "    for sentiment in listSentiment :\n",
    "        maxlistSentment.append(np.argmax(sentiment)-1)\n",
    "        \n",
    "    print(maxlistSentment) \n",
    "    print(len(maxlistSentment))\n",
    "    \n",
    "    return maxlistSentment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 2736.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "0: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "1: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "2: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "3: neg:0.246,neu:0.556,pos:0.198,compound:-0.1531\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "4: neg:0.42,neu:0.58,pos:0.0,compound:-0.4404\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "5: neg:0.398,neu:0.602,pos:0.0,compound:-0.5106\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "6: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "7: neg:0.095,neu:0.905,pos:0.0,compound:-0.296\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "8: neg:0.0,neu:0.833,pos:0.167,compound:0.34\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "9: neg:0.313,neu:0.687,pos:0.0,compound:-0.6249\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "10: neg:0.0,neu:0.6,pos:0.4,compound:0.7184\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "11: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "12: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "13: neg:0.0,neu:0.734,pos:0.266,compound:0.7845\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "14: neg:0.573,neu:0.427,pos:0.0,compound:-0.6551\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "15: neg:0.0,neu:0.714,pos:0.286,compound:0.34\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "16: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "17: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "18: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "19: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "20: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "21: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "22: neg:0.0,neu:0.417,pos:0.583,compound:0.4215\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "23: neg:0.0,neu:0.854,pos:0.146,compound:0.4404\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "24: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "25: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "26: neg:0.103,neu:0.667,pos:0.23,compound:0.5411\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "27: neg:0.102,neu:0.743,pos:0.155,compound:0.2824\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "28: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "29: neg:0.0,neu:0.751,pos:0.249,compound:0.743\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "30: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "31: neg:0.178,neu:0.667,pos:0.156,compound:0.2481\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "32: neg:0.0,neu:0.921,pos:0.079,compound:0.2023\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "33: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "34: neg:0.207,neu:0.793,pos:0.0,compound:-0.5267\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "35: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "36: neg:0.241,neu:0.636,pos:0.123,compound:-0.6249\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "37: neg:0.082,neu:0.788,pos:0.13,compound:0.1531\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "38: neg:0.0,neu:0.852,pos:0.148,compound:0.3818\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "39: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "40: neg:0.18,neu:0.82,pos:0.0,compound:-0.3875\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "41: neg:0.0,neu:0.874,pos:0.126,compound:0.3818\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "42: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "43: neg:0.048,neu:0.847,pos:0.105,compound:0.34\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "44: neg:0.0,neu:0.874,pos:0.126,compound:0.6369\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "45: neg:0.246,neu:0.29,pos:0.464,compound:0.3612\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "46: neg:0.0,neu:0.769,pos:0.231,compound:0.2732\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "47: neg:0.375,neu:0.625,pos:0.0,compound:-0.2023\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "48: neg:0.0,neu:0.782,pos:0.218,compound:0.2382\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "49: neg:0.213,neu:0.787,pos:0.0,compound:-0.4023\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "50: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "51: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "52: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "53: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "54: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "55: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "56: neg:0.296,neu:0.704,pos:0.0,compound:-0.2732\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "57: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "58: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "59: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "60: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "61: neg:0.0,neu:1.0,pos:0.0,compound:0.0\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "62: neg:0.0,neu:0.697,pos:0.303,compound:0.7506\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "63: neg:0.184,neu:0.662,pos:0.154,compound:-0.1027\n",
      "dict_keys(['neg', 'neu', 'pos', 'compound'])\n",
      "64: neg:0.0,neu:0.0,pos:0.0,compound:0.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_re = story_stucture_anaysis(input_text__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentiment_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = []\n",
    "for i in sentiment_re:\n",
    "    if i == -1:\n",
    "        conflict.append(i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conflict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장별로 구분을 .로 하고나서\n",
    "\n",
    "#문장에 몇명의 인물들이 등장하는지 확인할 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
