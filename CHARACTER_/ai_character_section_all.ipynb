{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cacki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import multiprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from gensim.models import Phrases\n",
    "from textblob import TextBlob\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text= \"\"\"A window into the soul.For most people, this would be the eyes. The eyes cannot lie; they often tell more about a person's emotions than their words. What distinguishes a fake smile from a genuine one? The eyes. What shows sadness? The eyes. What gives away a liar? The eyes.But are the eyes the only window into the soul?Recently, I began painting with watercolors. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again. Every stroke must be done purposefully, every color mixed to its exact value.I laid my materials before me, preparing myself for the worst. I checked my list of supplies, making sure my setup was perfect.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint. Too little water on my brush. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes. \\u2014It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. More alizarin crimson. More water. More yellow ochre. Less water. More phthalo blue. The cycle continued. Eventually, I was satisfied. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.Craving feedback, I posted my art to Snapchat. I got a few messages such as 'wow' and 'pretty,' but one message stood out. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.What I didn't know at the time was that my response would come a few months later while babysitting. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with. After I went to the bathroom and came back, the watercolors were doused with water. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.''Oh.'Now, I would be lying if I said I realized the connection between the two events immediately.Instead, I made the connection when I decided to sit down one day and objectively critique my art. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.When I peer around at people's projects during Code Club, I notice the clear differences between their code. Some people break it up by commenting in every possible section. Others breeze through the project, not caring to comment or organize their code. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. I shakily rose my hand. 'We should create workshops of our own,' I suggested.I got a few strange looks. 'It's a good idea, but it's too much work.' 'We just don't have enough free time to make it work.' 'Maybe we could, but I don't know how to make workshops.' My suggestion was shot down. I shuffled in my seat. 'I could make them.' A few people stared at me in disbelief. I glanced over at the club advisor, Mr. C, nervous to hear his response.'If you're willing to take on the work, we can try it.' Mr. C replied. And so I embarked on my quest. I researched different workshops on the internet, learning the information myself at first. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner. I was exhausted; my first workshop took 16 cumulative hours to create.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종합분석 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_character_sim_words(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                      'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                    'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                    'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                    'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                    'twin','uncle','widow','widower','wife','ex-wife']\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "    return result_char_ratio, total_sentences, total_words, char_total_count, char_count_, ext_sim_words_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'them', 'they', 'you', 'her', 'me', 'it', 'my', 'their', 'myself']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'them', 'they', 'you', 'her', 'me', 'it', 'my', 'their', 'myself']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>charter ratio</th>\n",
       "      <td>9.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sentences</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toral words</th>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_total_count</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext_chatacter_no</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext_similar_words</th>\n",
       "      <td>[(learning, 0.9752081632614136), (preparing, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0\n",
       "charter ratio                                                   9.87\n",
       "total sentences                                                   60\n",
       "toral words                                                      932\n",
       "char_total_count                                                  92\n",
       "ext_chatacter_no                                                  10\n",
       "ext_similar_words  [(learning, 0.9752081632614136), (preparing, 0..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_character_sim_words(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "\n",
    "df = ext_character_sim_words(input_text)\n",
    "df_ = pd.DataFrame(df, index = ['charter ratio','total sentences', 'toral words', 'char_total_count', 'ext_chatacter_no', 'ext_similar_words'])\n",
    "df_ # 이 겨래과에서는 92라는 숫자만 의미가 있지 >>> 총 문장에 캐릭터를 표현한 수가 총 몇개인지 추출한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Characters\n",
    " of characters -> 합격 에세이 평균 내서 (3명?) 그것보다 큰지 작은지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumberofCharacters(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                      'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                    'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                    'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                    'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                    'twin','uncle','widow','widower','wife','ex-wife']\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "    return char_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'them', 'they', 'you', 'her', 'me', 'it', 'my', 'their', 'myself']\n",
      "=============================================\n",
      "Number of Characters : 92\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    }
   ],
   "source": [
    "number_of_characters = NumberofCharacters(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "number_of_characters\n",
    "print ('=============================================')\n",
    "print ('Number of Characters :', number_of_characters)\n",
    "print ('=============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emphasis on YOU \n",
    "'i'가 얼마나 들어갔는지, 평균대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmphasisOnYou(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['i', 'I', 'my', 'me', 'mine']\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "    return char_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'i', 'my']\n",
      "=============================================\n",
      "Emphasis on You : 60\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    }
   ],
   "source": [
    "EmphasisOnYou_ = EmphasisOnYou(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "EmphasisOnYou_\n",
    "print ('=============================================')\n",
    "print ('Emphasis on You :', EmphasisOnYou_)\n",
    "print ('=============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emphasis on others\n",
    "다른이들이 얼마나 들어갔는지, 평균대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmphasisOnOthers(text):\n",
    "\n",
    "    essay_input_corpus = str(text) #문장입력\n",
    "    essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "    sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "    total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "    total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "        words = processed.split()\n",
    "        split_sentences.append(words)\n",
    "\n",
    "    skip_gram = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "    model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "    model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "    \n",
    "    #모델 설계 완료\n",
    "\n",
    "    #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "    character_list = ['you', 'your', 'they','them',\n",
    "                      'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                    'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                    'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                    'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                    'twin','uncle','widow','widower','wife','ex-wife']\n",
    "    \n",
    "    ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "    #우선 토큰화한다.\n",
    "    retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "    token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "    #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "    #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "    filtered_chr_text = []\n",
    "    for k in token_input_text:\n",
    "        for j in character_list:\n",
    "            if k == j:\n",
    "                filtered_chr_text.append(j)\n",
    "    \n",
    "    #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "    \n",
    "    filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "    filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "    print (filtered_chr_text__) # 중복값 제거 확인\n",
    "    \n",
    "    for i in filtered_chr_text__:\n",
    "        ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "    \n",
    "    char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "    char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "        \n",
    "    result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "    return char_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['them', 'they', 'you', 'her', 'it', 'their', 'myself']\n",
      "=============================================\n",
      "Emphasis on Others : 32\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    }
   ],
   "source": [
    "EmphasisOnOthers_ = EmphasisOnOthers(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "EmphasisOnOthers_\n",
    "print ('=============================================')\n",
    "print ('Emphasis on Others :', EmphasisOnOthers_)\n",
    "print ('=============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Descriptiveness\n",
    "이건 character 설명 문장에 showing이 얼마나 들어가 있는지… 평균대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "#cuda 메모리에 여유를 주기 위해서 잠시 딜레이를 시키자\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 단어가 들어간 문장 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSentence(input_sentence):\n",
    "    result = []\n",
    "\n",
    "    data = str(input_sentence)\n",
    "    #data = input_sentence.splitlines()\n",
    "    \n",
    "    findText = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                'twin','uncle','widow','widower','wife','ex-wife']\n",
    "\n",
    "    sentences = data.split(\".\")\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for item in findText:\n",
    "            if item in sentence:\n",
    "                result.append(sentence)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" What distinguishes a fake smile from a genuine one? The eyes. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. C replied. I got a few messages such as 'wow' and 'pretty,' but one message stood out. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes.Instead, I made the connection when I decided to sit down one day and objectively critique my art. What gives away a liar? The eyes. Too little water on my brush. Others breeze through the project, not caring to comment or organize their code.' My suggestion was shot down. I researched different workshops on the internet, learning the information myself at first. —It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Every stroke must be done purposefully, every color mixed to its exact value. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.I laid my materials before me, preparing myself for the worst. Some people break it up by commenting in every possible section. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner.For most people, this would be the eyes. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.'Now, I would be lying if I said I realized the connection between the two events immediately. I shuffled in my seat. The eyes cannot lie; they often tell more about a person's emotions than their words.Craving feedback, I posted my art to Snapchat. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. I was exhausted; my first workshop took 16 cumulative hours to create. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit. I shakily rose my hand.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. What shows sadness? The eyes. I glanced over at the club advisor, Mr. The cycle continued.A window into the soul.When I peer around at people's projects during Code Club, I notice the clear differences between their code.What I didn't know at the time was that my response would come a few months later while babysitting. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.'If you're willing to take on the work, we can try it. More alizarin crimson. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with.' 'We just don't have enough free time to make it work. C, nervous to hear his response. 'I could make them. Eventually, I was satisfied. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. 'It's a good idea, but it's too much work. After I went to the bathroom and came back, the watercolors were doused with water.' A few people stared at me in disbelief. I checked my list of supplies, making sure my setup was perfect. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage. And so I embarked on my quest.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint.But are the eyes the only window into the soul?Recently, I began painting with watercolors\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sent_included_character = findSentence(input_text) \n",
    "input_sent_chr = set(input_sent_included_character) #중복값을 제거해보자\n",
    "input_sent_chr = '.'.join(input_sent_chr) #하나의 문자열로 합쳐야 원본 문장처럼 변환되고, 이것을 show/tell 분석코드에 넣게됨\n",
    "input_sent_chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력된 전체 문장을 개별문장으로 분리하여 전처리 처리함\n",
    "def sentence_to_df(input_sentence):\n",
    "\n",
    "    input_text_df = nltk.tokenize.sent_tokenize(input_sentence)\n",
    "    test = []\n",
    "\n",
    "    for i in range(0,len(input_text_df)):\n",
    "        new_label = np.random.randint(0,2)  # 개별문장(input_text_df) 수만큼 0 또는 1 난수 생성\n",
    "        data = [new_label, input_text_df[i]]\n",
    "        test.append(data)\n",
    "\n",
    "    #print(test)\n",
    "    dataf = pd.DataFrame(test, columns=['label', 'text'])\n",
    "    #print(dataf)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STDataset(Dataset):\n",
    "    ''' Showing Telling Corpus Dataset '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = int(self.df.iloc[idx, 0])\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########입력받은 데이터 처리 실행하는 메소드 showtell_classfy() ###############\n",
    "#result_all.html에서 입력받을 text를 contents에 넣고 전처리 후 데이터프레임에 넣어줌\n",
    "def showtell_classfy(text):\n",
    "    contents = str(text)\n",
    "    preprossed_contents_df = sentence_to_df(contents)\n",
    "\n",
    "    preprossed_contents_df.dropna(inplace=True)\n",
    "    #전처리된 데이터를 확인(데이터프레임으로 가공됨)\n",
    "    preprossed_contents_df__ = preprossed_contents_df.sample(frac=1, random_state=999)\n",
    "    \n",
    "\n",
    "    #파이토치에 입력하기 위해서 로딩...\n",
    "    ST_test_dataset = STDataset(preprossed_contents_df__)\n",
    "    test_loader = DataLoader(ST_test_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "    #로딩되는지 확인\n",
    "    ST_test_dataset.__getitem__(1)\n",
    "\n",
    "    #time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "    #check whether cuda is available\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "    device = torch.device(\"cpu\")  \n",
    "    #device = torch.device(\"cuda\")\n",
    "    #tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-large-cased')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # for text, label in test_loader :\n",
    "    #     print(\"text:\",text)\n",
    "    #     print(\"label:\",label)\n",
    "\n",
    "\n",
    "    #저장된 모델을 불러온다.\n",
    "    #J:\\Django\\EssayFit_Django\\essayfitaiproject\\essayfitapp\\model.pt\n",
    "    #time.sleep(1)\n",
    "    #model = torch.load(\"/Users/jongphilkim/Desktop/Django_WEB/essayfitaiproject/essayai/model.pt\", map_location=torch.device('cpu'))\n",
    "    model = torch.load(\"model.pt\", map_location=torch.device('cpu'))\n",
    "    print(\"model loadling~\")\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    pred_loader = test_loader\n",
    "    print(\"pred_loader:\", pred_loader)\n",
    "    total_loss = 0\n",
    "    total_len = 0\n",
    "    total_showing__ = 0\n",
    "    total_telling__ = 0\n",
    "\n",
    "    showing_conunter = [] #문장에 해당하는 SHOWING을 계산한다.\n",
    "    \n",
    "    print(\"check!\")\n",
    "    for text, label in pred_loader:\n",
    "        print(\"text:\",text)\n",
    "        #print(\"label:\",label)\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text] #text to tokenize\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list] #padding\n",
    "        sample = torch.tensor(padded_list) #torch tensor로 변환\n",
    "        sample, label = sample.to(device), label.to(device) #tokenized text에 label을 넣어서 Device(gpu/cpu)에 넣기 위해 준비\n",
    "        labels = torch.tensor(label) #레이블을 텐서로 변환\n",
    "        #time.sleep(1)\n",
    "        outputs = model(sample,labels=labels) #모델을 통해서 샘플텍스트와 레이블 입력데이터를 출력 output에 넣음\n",
    "        #시간 딜레이를 주자\n",
    "        #time.sleep(1)\n",
    "        _, logits = outputs #outputs를 로짓에 넣음 이것을 softmax에 넣으면 0~1 사이로 결과가 출력됨\n",
    "        \n",
    "        pred = torch.argmax(F.softmax(logits), dim=1) #드디어 예측한다. argmax는 리스트(계산된 값)에서 가장 큰 값을 추출하여 pred에 넣는다. 0 ~1 사이의 값이 나올거임\n",
    "        print('pred :', pred)\n",
    "        # correct = pred.eq(labels) \n",
    "        showing__ = pred.eq(1) # 예측한 결과가 1과 같으면 showing이다   >> TRUE   SHOWING을 추출하려면 이것만 카운드하면 된다. \n",
    "        telling__ = pred.eq(0) # 예측한 결과가 0과 같으면 telling이다   >> FALSE\n",
    "        \n",
    "        #print('showing : ', showing__)\n",
    "        #print('telling : ', telling__)\n",
    "        \n",
    "        \n",
    "        showing_conunter.append(text)        \n",
    "        #pred_ = round(float(pred))\n",
    "        showing_conunter.append(pred)\n",
    "\n",
    "\n",
    "\n",
    "    return showing_conunter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" What distinguishes a fake smile from a genuine one? The eyes. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. C replied. I got a few messages such as 'wow' and 'pretty,' but one message stood out. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes.Instead, I made the connection when I decided to sit down one day and objectively critique my art. What gives away a liar? The eyes. Too little water on my brush. Others breeze through the project, not caring to comment or organize their code.' My suggestion was shot down. I researched different workshops on the internet, learning the information myself at first. —It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Every stroke must be done purposefully, every color mixed to its exact value. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.I laid my materials before me, preparing myself for the worst. Some people break it up by commenting in every possible section. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner.For most people, this would be the eyes. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.'Now, I would be lying if I said I realized the connection between the two events immediately. I shuffled in my seat. The eyes cannot lie; they often tell more about a person's emotions than their words.Craving feedback, I posted my art to Snapchat. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. I was exhausted; my first workshop took 16 cumulative hours to create. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit. I shakily rose my hand.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. What shows sadness? The eyes. I glanced over at the club advisor, Mr. The cycle continued.A window into the soul.When I peer around at people's projects during Code Club, I notice the clear differences between their code.What I didn't know at the time was that my response would come a few months later while babysitting. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.'If you're willing to take on the work, we can try it. More alizarin crimson. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with.' 'We just don't have enough free time to make it work. C, nervous to hear his response. 'I could make them. Eventually, I was satisfied. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. 'It's a good idea, but it's too much work. After I went to the bathroom and came back, the watercolors were doused with water.' A few people stared at me in disbelief. I checked my list of supplies, making sure my setup was perfect. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage. And so I embarked on my quest.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint.But are the eyes the only window into the soul?Recently, I began painting with watercolors\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sent_chr # 입력값 다시 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_text= \"\"\"A window into the soul.For most people, this would be the eyes. The eyes cannot lie; they often tell more about a person's emotions than their words. What distinguishes a fake smile from a genuine one? The eyes. What shows sadness? The eyes. What gives away a liar? The eyes.But are the eyes the only window into the soul?Recently, I began painting with watercolors. With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again. Every stroke must be done purposefully, every color mixed to its exact value.I laid my materials before me, preparing myself for the worst. I checked my list of supplies, making sure my setup was perfect.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint. Too little water on my brush. I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes. \\u2014It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value. More alizarin crimson. More water. More yellow ochre. Less water. More phthalo blue. The cycle continued. Eventually, I was satisfied. The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.Craving feedback, I posted my art to Snapchat. I got a few messages such as 'wow' and 'pretty,' but one message stood out. 'You were anxious with this one, huh? Anyways, love the hair!'I was caught off guard. Was it a lucky guess? Did they know something I didn't? I immediately responded: 'Haha, how could you tell?' No response.What I didn't know at the time was that my response would come a few months later while babysitting. Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with. After I went to the bathroom and came back, the watercolors were doused with water. 'You were impatient with this one, huh? Anyways, love the little dog you drew!'The little girl looked up at me, confused. 'How could you tell?' 'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.''Oh.'Now, I would be lying if I said I realized the connection between the two events immediately.Instead, I made the connection when I decided to sit down one day and objectively critique my art. The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.When I peer around at people's projects during Code Club, I notice the clear differences between their code. Some people break it up by commenting in every possible section. Others breeze through the project, not caring to comment or organize their code. I could also see clear differences in personalities when our club members began coding the Arduino for the first time. Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to. If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them. I shakily rose my hand. 'We should create workshops of our own,' I suggested.I got a few strange looks. 'It's a good idea, but it's too much work.' 'We just don't have enough free time to make it work.' 'Maybe we could, but I don't know how to make workshops.' My suggestion was shot down. I shuffled in my seat. 'I could make them.' A few people stared at me in disbelief. I glanced over at the club advisor, Mr. C, nervous to hear his response.'If you're willing to take on the work, we can try it.' Mr. C replied. And so I embarked on my quest. I researched different workshops on the internet, learning the information myself at first. Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner. I was exhausted; my first workshop took 16 cumulative hours to create.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x000001ACEBA15EC8>\n",
      "check!\n",
      "text: ('With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: (\"'We just don't have enough free time to make it work.\",)\n",
      "pred : tensor([0])\n",
      "text: ('Some people break it up by commenting in every possible section.',)\n",
      "pred : tensor([1])\n",
      "text: ('I was exhausted; my first workshop took 16 cumulative hours to create.',)\n",
      "pred : tensor([1])\n",
      "text: ('I researched different workshops on the internet, learning the information myself at first.',)\n",
      "pred : tensor([1])\n",
      "text: ('More alizarin crimson.',)\n",
      "pred : tensor([0])\n",
      "text: ('No response.I laid my materials before me, preparing myself for the worst.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Did they know something I didn't?\",)\n",
      "pred : tensor([0])\n",
      "text: ('Every stroke must be done purposefully, every color mixed to its exact value.',)\n",
      "pred : tensor([1])\n",
      "text: ('I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes.Instead, I made the connection when I decided to sit down one day and objectively critique my art.',)\n",
      "pred : tensor([1])\n",
      "text: ('I checked my list of supplies, making sure my setup was perfect.',)\n",
      "pred : tensor([1])\n",
      "text: ('I glanced over at the club advisor, Mr.',)\n",
      "pred : tensor([1])\n",
      "text: ('Anyways, love the hair!',)\n",
      "pred : tensor([1])\n",
      "text: (\"'You were impatient with this one, huh?\",)\n",
      "pred : tensor([0])\n",
      "text: (\"'It's a good idea, but it's too much work.\",)\n",
      "pred : tensor([1])\n",
      "text: ('The eyes.',)\n",
      "pred : tensor([0])\n",
      "text: (\"'Now, I would be lying if I said I realized the connection between the two events immediately.\",)\n",
      "pred : tensor([1])\n",
      "text: ('What shows sadness?',)\n",
      "pred : tensor([0])\n",
      "text: ('Too little water on my brush.',)\n",
      "pred : tensor([0])\n",
      "text: ('A few people stared at me in disbelief.',)\n",
      "pred : tensor([1])\n",
      "text: ('My suggestion was shot down.',)\n",
      "pred : tensor([0])\n",
      "text: (\"—It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value.\",)\n",
      "pred : tensor([1])\n",
      "text: ('And so I embarked on my quest.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint.But are the eyes the only window into the soul?Recently, I began painting with watercolors',)\n",
      "pred : tensor([1])\n",
      "text: (\"I got a few messages such as 'wow' and 'pretty,' but one message stood out.\",)\n",
      "pred : tensor([1])\n",
      "text: ('C replied.',)\n",
      "pred : tensor([0])\n",
      "text: ('Eventually, I was satisfied.',)\n",
      "pred : tensor([0])\n",
      "text: (\"'You were anxious with this one, huh?\",)\n",
      "pred : tensor([0])\n",
      "text: (' What distinguishes a fake smile from a genuine one?',)\n",
      "pred : tensor([1])\n",
      "text: (\"'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I shakily rose my hand.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I immediately responded: 'Haha, how could you tell?'\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with.'\",)\n",
      "pred : tensor([1])\n",
      "text: ('The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.',)\n",
      "pred : tensor([1])\n",
      "text: ('I shuffled in my seat.',)\n",
      "pred : tensor([1])\n",
      "text: ('The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.',)\n",
      "pred : tensor([1])\n",
      "text: (\"'How could you tell?'\",)\n",
      "pred : tensor([0])\n",
      "text: ('I could also see clear differences in personalities when our club members began coding the Arduino for the first time.',)\n",
      "pred : tensor([1])\n",
      "text: (\"'I could make them.\",)\n",
      "pred : tensor([0])\n",
      "text: (\"'I was caught off guard.\",)\n",
      "pred : tensor([0])\n",
      "text: ('If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them.',)\n",
      "pred : tensor([1])\n",
      "text: ('C, nervous to hear his response.',)\n",
      "pred : tensor([0])\n",
      "text: (\"The eyes cannot lie; they often tell more about a person's emotions than their words.Craving feedback, I posted my art to Snapchat.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Anyways, love the little dog you drew!',)\n",
      "pred : tensor([1])\n",
      "text: (\"Others breeze through the project, not caring to comment or organize their code.'\",)\n",
      "pred : tensor([1])\n",
      "text: ('What gives away a liar?',)\n",
      "pred : tensor([0])\n",
      "text: ('Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.',)\n",
      "pred : tensor([1])\n",
      "text: ('Was it a lucky guess?',)\n",
      "pred : tensor([0])\n",
      "text: ('Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner.For most people, this would be the eyes.',)\n",
      "pred : tensor([1])\n",
      "text: ('The eyes.',)\n",
      "pred : tensor([0])\n",
      "text: (\"'The little girl looked up at me, confused.\",)\n",
      "pred : tensor([1])\n",
      "text: ('The eyes.',)\n",
      "pred : tensor([0])\n",
      "text: (\"The cycle continued.A window into the soul.When I peer around at people's projects during Code Club, I notice the clear differences between their code.What I didn't know at the time was that my response would come a few months later while babysitting.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"After I went to the bathroom and came back, the watercolors were doused with water.'\",)\n",
      "pred : tensor([1])\n",
      "text: (\"'If you're willing to take on the work, we can try it.\",)\n",
      "pred : tensor([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('With watercolors, there is no turning back: if one section is too dark, it is nearly impossible to lighten the area again.From then on, I started noticing pieces of personality in additional creations surrounding me: website designs, solutions to math problems, code written for class, and even the preparation of a meal.',),\n",
       " tensor([1]),\n",
       " (\"'We just don't have enough free time to make it work.\",),\n",
       " tensor([0]),\n",
       " ('Some people break it up by commenting in every possible section.',),\n",
       " tensor([1]),\n",
       " ('I was exhausted; my first workshop took 16 cumulative hours to create.',),\n",
       " tensor([1]),\n",
       " ('I researched different workshops on the internet, learning the information myself at first.',),\n",
       " tensor([1]),\n",
       " ('More alizarin crimson.',),\n",
       " tensor([0]),\n",
       " ('No response.I laid my materials before me, preparing myself for the worst.',),\n",
       " tensor([1]),\n",
       " (\"Did they know something I didn't?\",),\n",
       " tensor([0]),\n",
       " ('Every stroke must be done purposefully, every color mixed to its exact value.',),\n",
       " tensor([1]),\n",
       " ('I dipped my brush back into my trusty water jar; the colors swirled beautifully, forming an abstract art piece before my eyes.Instead, I made the connection when I decided to sit down one day and objectively critique my art.',),\n",
       " tensor([1]),\n",
       " ('I checked my list of supplies, making sure my setup was perfect.',),\n",
       " tensor([1]),\n",
       " ('I glanced over at the club advisor, Mr.',),\n",
       " tensor([1]),\n",
       " ('Anyways, love the hair!',),\n",
       " tensor([1]),\n",
       " (\"'You were impatient with this one, huh?\",),\n",
       " tensor([0]),\n",
       " (\"'It's a good idea, but it's too much work.\",),\n",
       " tensor([1]),\n",
       " ('The eyes.',),\n",
       " tensor([0]),\n",
       " (\"'Now, I would be lying if I said I realized the connection between the two events immediately.\",),\n",
       " tensor([1]),\n",
       " ('What shows sadness?',),\n",
       " tensor([0]),\n",
       " ('Too little water on my brush.',),\n",
       " tensor([0]),\n",
       " ('A few people stared at me in disbelief.',),\n",
       " tensor([1]),\n",
       " ('My suggestion was shot down.',),\n",
       " tensor([0]),\n",
       " (\"—It's a shame that I couldn't appreciate it.I continued mixing colors to their exact value.\",),\n",
       " tensor([1]),\n",
       " ('And so I embarked on my quest.I wet my brush, dipped it into some yellow ochre, and dabbed off the excess paint.But are the eyes the only window into the soul?Recently, I began painting with watercolors',),\n",
       " tensor([1]),\n",
       " (\"I got a few messages such as 'wow' and 'pretty,' but one message stood out.\",),\n",
       " tensor([1]),\n",
       " ('C replied.',),\n",
       " tensor([0]),\n",
       " ('Eventually, I was satisfied.',),\n",
       " tensor([0]),\n",
       " (\"'You were anxious with this one, huh?\",),\n",
       " tensor([0]),\n",
       " (' What distinguishes a fake smile from a genuine one?',),\n",
       " tensor([1]),\n",
       " (\"'You used a lot of water for a brighter color, but you couldn't wait for it to slowly soak in.\",),\n",
       " tensor([1]),\n",
       " ('I shakily rose my hand.It became clear to me that, as humans, we leave pieces of our souls in everything we do, more than we intend to.',),\n",
       " tensor([1]),\n",
       " (\"I immediately responded: 'Haha, how could you tell?'\",),\n",
       " tensor([1]),\n",
       " (\"Since the girl I was babysitting loved art, I took out some Crayola watercolors and some watercolor paper for her to play with.'\",),\n",
       " tensor([1]),\n",
       " ('The piece that I once loved now seemed like a nervous wreck: the paper was overworked, the brushstrokes were undecided, the facial features blended together, and each drop of water was bound inside the lines as if it was a prisoner in a cage.',),\n",
       " tensor([1]),\n",
       " ('I shuffled in my seat.',),\n",
       " tensor([1]),\n",
       " ('The colors looked good, there was enough contrast between facial features, and the watercolors stayed inside the lines.',),\n",
       " tensor([1]),\n",
       " (\"'How could you tell?'\",),\n",
       " tensor([0]),\n",
       " ('I could also see clear differences in personalities when our club members began coding the Arduino for the first time.',),\n",
       " tensor([1]),\n",
       " (\"'I could make them.\",),\n",
       " tensor([0]),\n",
       " (\"'I was caught off guard.\",),\n",
       " tensor([0]),\n",
       " ('If we entertain this thought, perhaps the key to better understanding others around us is simply noticing the subtler clues under our noses?Perhaps there are endless windows to the soul, and we simply need to peer through them.',),\n",
       " tensor([1]),\n",
       " ('C, nervous to hear his response.',),\n",
       " tensor([0]),\n",
       " (\"The eyes cannot lie; they often tell more about a person's emotions than their words.Craving feedback, I posted my art to Snapchat.\",),\n",
       " tensor([1]),\n",
       " ('Anyways, love the little dog you drew!',),\n",
       " tensor([1]),\n",
       " (\"Others breeze through the project, not caring to comment or organize their code.'\",),\n",
       " tensor([1]),\n",
       " ('What gives away a liar?',),\n",
       " tensor([0]),\n",
       " ('Some followed the tutorials to the letter, while others immediately started experimenting with different colored LEDs and ways of wiring the circuit.',),\n",
       " tensor([1]),\n",
       " ('Was it a lucky guess?',),\n",
       " tensor([0]),\n",
       " ('Then, I transitioned into creating workshops of my own, making sure that the information was easy to understand for even a beginner.For most people, this would be the eyes.',),\n",
       " tensor([1]),\n",
       " ('The eyes.',),\n",
       " tensor([0]),\n",
       " (\"'The little girl looked up at me, confused.\",),\n",
       " tensor([1]),\n",
       " ('The eyes.',),\n",
       " tensor([0]),\n",
       " (\"The cycle continued.A window into the soul.When I peer around at people's projects during Code Club, I notice the clear differences between their code.What I didn't know at the time was that my response would come a few months later while babysitting.\",),\n",
       " tensor([1]),\n",
       " (\"After I went to the bathroom and came back, the watercolors were doused with water.'\",),\n",
       " tensor([1]),\n",
       " (\"'If you're willing to take on the work, we can try it.\",),\n",
       " tensor([1])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#st_re = showtell_classfy(input_text) # 캐릭터거 포함된 문장(전처리 완료된) 입력\n",
    "st_re = showtell_classfy(str(input_sent_chr)) # 캐릭터거 포함된 문장(전처리 완료된) 입력\n",
    "st_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(st_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With watercolors, there is no turning back: if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'We just don't have enough free time to make i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people break it up by commenting in every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>After I went to the bathroom and came back, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>'If you're willing to take on the work, we can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    With watercolors, there is no turning back: if...\n",
       "1                                            tensor(1)\n",
       "2    'We just don't have enough free time to make i...\n",
       "3                                            tensor(0)\n",
       "4    Some people break it up by commenting in every...\n",
       "..                                                 ...\n",
       "103                                          tensor(1)\n",
       "104  After I went to the bathroom and came back, th...\n",
       "105                                          tensor(1)\n",
       "106  'If you're willing to take on the work, we can...\n",
       "107                                          tensor(1)\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(st_re)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With watercolors, there is no turning back: if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'We just don't have enough free time to make i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people break it up by commenting in every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I was exhausted; my first workshop took 16 cum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I researched different workshops on the intern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  With watercolors, there is no turning back: if...\n",
       "2  'We just don't have enough free time to make i...\n",
       "4  Some people break it up by commenting in every...\n",
       "6  I was exhausted; my first workshop took 16 cum...\n",
       "8  I researched different workshops on the intern..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df[0::2]\n",
    "df_[:5] # 글만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1    tensor(1)\n",
       "3    tensor(0)\n",
       "5    tensor(1)\n",
       "7    tensor(1)\n",
       "9    tensor(1)\n",
       "11   tensor(0)\n",
       "13   tensor(1)\n",
       "15   tensor(0)\n",
       "17   tensor(1)\n",
       "19   tensor(1)\n",
       "21   tensor(1)\n",
       "23   tensor(1)\n",
       "25   tensor(1)\n",
       "27   tensor(0)\n",
       "29   tensor(1)\n",
       "31   tensor(0)\n",
       "33   tensor(1)\n",
       "35   tensor(0)\n",
       "37   tensor(0)\n",
       "39   tensor(1)\n",
       "41   tensor(0)\n",
       "43   tensor(1)\n",
       "45   tensor(1)\n",
       "47   tensor(1)\n",
       "49   tensor(0)\n",
       "51   tensor(0)\n",
       "53   tensor(0)\n",
       "55   tensor(1)\n",
       "57   tensor(1)\n",
       "59   tensor(1)\n",
       "61   tensor(1)\n",
       "63   tensor(1)\n",
       "65   tensor(1)\n",
       "67   tensor(1)\n",
       "69   tensor(1)\n",
       "71   tensor(0)\n",
       "73   tensor(1)\n",
       "75   tensor(0)\n",
       "77   tensor(0)\n",
       "79   tensor(1)\n",
       "81   tensor(0)\n",
       "83   tensor(1)\n",
       "85   tensor(1)\n",
       "87   tensor(1)\n",
       "89   tensor(0)\n",
       "91   tensor(1)\n",
       "93   tensor(0)\n",
       "95   tensor(1)\n",
       "97   tensor(0)\n",
       "99   tensor(1)\n",
       "101  tensor(0)\n",
       "103  tensor(1)\n",
       "105  tensor(1)\n",
       "107  tensor(1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = df[1::2]\n",
    "df_label # 레이블만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.reset_index(drop=True, inplace=True) #데이터를 합치기 위해서 초기화\n",
    "df_label.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With watercolors, there is no turning back: if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'We just don't have enough free time to make i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some people break it up by commenting in every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was exhausted; my first workshop took 16 cum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I researched different workshops on the intern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  With watercolors, there is no turning back: if...\n",
       "1  'We just don't have enough free time to make i...\n",
       "2  Some people break it up by commenting in every...\n",
       "3  I was exhausted; my first workshop took 16 cum...\n",
       "4  I researched different workshops on the intern..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  tensor(1)\n",
       "1  tensor(0)\n",
       "2  tensor(1)\n",
       "3  tensor(1)\n",
       "4  tensor(1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With watercolors, there is no turning back: if...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'We just don't have enough free time to make i...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some people break it up by commenting in every...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was exhausted; my first workshop took 16 cum...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I researched different workshops on the intern...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>More alizarin crimson.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No response.I laid my materials before me, pre...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Did they know something I didn't?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Every stroke must be done purposefully, every ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I dipped my brush back into my trusty water ja...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I checked my list of supplies, making sure my ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I glanced over at the club advisor, Mr.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Anyways, love the hair!</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'You were impatient with this one, huh?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'It's a good idea, but it's too much work.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The eyes.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'Now, I would be lying if I said I realized th...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What shows sadness?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Too little water on my brush.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A few people stared at me in disbelief.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>My suggestion was shot down.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>—It's a shame that I couldn't appreciate it.I ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>And so I embarked on my quest.I wet my brush, ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I got a few messages such as 'wow' and 'pretty...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C replied.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Eventually, I was satisfied.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'You were anxious with this one, huh?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What distinguishes a fake smile from a genuin...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'You used a lot of water for a brighter color,...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I shakily rose my hand.It became clear to me t...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0          0\n",
       "0   With watercolors, there is no turning back: if...  tensor(1)\n",
       "1   'We just don't have enough free time to make i...  tensor(0)\n",
       "2   Some people break it up by commenting in every...  tensor(1)\n",
       "3   I was exhausted; my first workshop took 16 cum...  tensor(1)\n",
       "4   I researched different workshops on the intern...  tensor(1)\n",
       "5                              More alizarin crimson.  tensor(0)\n",
       "6   No response.I laid my materials before me, pre...  tensor(1)\n",
       "7                   Did they know something I didn't?  tensor(0)\n",
       "8   Every stroke must be done purposefully, every ...  tensor(1)\n",
       "9   I dipped my brush back into my trusty water ja...  tensor(1)\n",
       "10  I checked my list of supplies, making sure my ...  tensor(1)\n",
       "11            I glanced over at the club advisor, Mr.  tensor(1)\n",
       "12                            Anyways, love the hair!  tensor(1)\n",
       "13            'You were impatient with this one, huh?  tensor(0)\n",
       "14         'It's a good idea, but it's too much work.  tensor(1)\n",
       "15                                          The eyes.  tensor(0)\n",
       "16  'Now, I would be lying if I said I realized th...  tensor(1)\n",
       "17                                What shows sadness?  tensor(0)\n",
       "18                      Too little water on my brush.  tensor(0)\n",
       "19            A few people stared at me in disbelief.  tensor(1)\n",
       "20                       My suggestion was shot down.  tensor(0)\n",
       "21  —It's a shame that I couldn't appreciate it.I ...  tensor(1)\n",
       "22  And so I embarked on my quest.I wet my brush, ...  tensor(1)\n",
       "23  I got a few messages such as 'wow' and 'pretty...  tensor(1)\n",
       "24                                         C replied.  tensor(0)\n",
       "25                       Eventually, I was satisfied.  tensor(0)\n",
       "26              'You were anxious with this one, huh?  tensor(0)\n",
       "27   What distinguishes a fake smile from a genuin...  tensor(1)\n",
       "28  'You used a lot of water for a brighter color,...  tensor(1)\n",
       "29  I shakily rose my hand.It became clear to me t...  tensor(1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.concat([df_,df_label],axis=1)\n",
    "df_result[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>show/tell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With watercolors, there is no turning back: if...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'We just don't have enough free time to make i...</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some people break it up by commenting in every...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was exhausted; my first workshop took 16 cum...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I researched different workshops on the intern...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>More alizarin crimson.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No response.I laid my materials before me, pre...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Did they know something I didn't?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Every stroke must be done purposefully, every ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I dipped my brush back into my trusty water ja...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I checked my list of supplies, making sure my ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I glanced over at the club advisor, Mr.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Anyways, love the hair!</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'You were impatient with this one, huh?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'It's a good idea, but it's too much work.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The eyes.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'Now, I would be lying if I said I realized th...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What shows sadness?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Too little water on my brush.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A few people stared at me in disbelief.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>My suggestion was shot down.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>—It's a shame that I couldn't appreciate it.I ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>And so I embarked on my quest.I wet my brush, ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I got a few messages such as 'wow' and 'pretty...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C replied.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Eventually, I was satisfied.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'You were anxious with this one, huh?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What distinguishes a fake smile from a genuin...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'You used a lot of water for a brighter color,...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I shakily rose my hand.It became clear to me t...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I immediately responded: 'Haha, how could you ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Since the girl I was babysitting loved art, I ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The piece that I once loved now seemed like a ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I shuffled in my seat.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The colors looked good, there was enough contr...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>'How could you tell?'</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I could also see clear differences in personal...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>'I could make them.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>'I was caught off guard.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>If we entertain this thought, perhaps the key ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>C, nervous to hear his response.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The eyes cannot lie; they often tell more abou...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Anyways, love the little dog you drew!</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Others breeze through the project, not caring ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What gives away a liar?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Some followed the tutorials to the letter, whi...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Was it a lucky guess?</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Then, I transitioned into creating workshops o...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>The eyes.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>'The little girl looked up at me, confused.</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>The eyes.</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>The cycle continued.A window into the soul.Whe...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>After I went to the bathroom and came back, th...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>'If you're willing to take on the work, we can...</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  show/tell\n",
       "0   With watercolors, there is no turning back: if...  tensor(1)\n",
       "1   'We just don't have enough free time to make i...  tensor(0)\n",
       "2   Some people break it up by commenting in every...  tensor(1)\n",
       "3   I was exhausted; my first workshop took 16 cum...  tensor(1)\n",
       "4   I researched different workshops on the intern...  tensor(1)\n",
       "5                              More alizarin crimson.  tensor(0)\n",
       "6   No response.I laid my materials before me, pre...  tensor(1)\n",
       "7                   Did they know something I didn't?  tensor(0)\n",
       "8   Every stroke must be done purposefully, every ...  tensor(1)\n",
       "9   I dipped my brush back into my trusty water ja...  tensor(1)\n",
       "10  I checked my list of supplies, making sure my ...  tensor(1)\n",
       "11            I glanced over at the club advisor, Mr.  tensor(1)\n",
       "12                            Anyways, love the hair!  tensor(1)\n",
       "13            'You were impatient with this one, huh?  tensor(0)\n",
       "14         'It's a good idea, but it's too much work.  tensor(1)\n",
       "15                                          The eyes.  tensor(0)\n",
       "16  'Now, I would be lying if I said I realized th...  tensor(1)\n",
       "17                                What shows sadness?  tensor(0)\n",
       "18                      Too little water on my brush.  tensor(0)\n",
       "19            A few people stared at me in disbelief.  tensor(1)\n",
       "20                       My suggestion was shot down.  tensor(0)\n",
       "21  —It's a shame that I couldn't appreciate it.I ...  tensor(1)\n",
       "22  And so I embarked on my quest.I wet my brush, ...  tensor(1)\n",
       "23  I got a few messages such as 'wow' and 'pretty...  tensor(1)\n",
       "24                                         C replied.  tensor(0)\n",
       "25                       Eventually, I was satisfied.  tensor(0)\n",
       "26              'You were anxious with this one, huh?  tensor(0)\n",
       "27   What distinguishes a fake smile from a genuin...  tensor(1)\n",
       "28  'You used a lot of water for a brighter color,...  tensor(1)\n",
       "29  I shakily rose my hand.It became clear to me t...  tensor(1)\n",
       "30  I immediately responded: 'Haha, how could you ...  tensor(1)\n",
       "31  Since the girl I was babysitting loved art, I ...  tensor(1)\n",
       "32  The piece that I once loved now seemed like a ...  tensor(1)\n",
       "33                             I shuffled in my seat.  tensor(1)\n",
       "34  The colors looked good, there was enough contr...  tensor(1)\n",
       "35                              'How could you tell?'  tensor(0)\n",
       "36  I could also see clear differences in personal...  tensor(1)\n",
       "37                                'I could make them.  tensor(0)\n",
       "38                           'I was caught off guard.  tensor(0)\n",
       "39  If we entertain this thought, perhaps the key ...  tensor(1)\n",
       "40                   C, nervous to hear his response.  tensor(0)\n",
       "41  The eyes cannot lie; they often tell more abou...  tensor(1)\n",
       "42             Anyways, love the little dog you drew!  tensor(1)\n",
       "43  Others breeze through the project, not caring ...  tensor(1)\n",
       "44                            What gives away a liar?  tensor(0)\n",
       "45  Some followed the tutorials to the letter, whi...  tensor(1)\n",
       "46                              Was it a lucky guess?  tensor(0)\n",
       "47  Then, I transitioned into creating workshops o...  tensor(1)\n",
       "48                                          The eyes.  tensor(0)\n",
       "49        'The little girl looked up at me, confused.  tensor(1)\n",
       "50                                          The eyes.  tensor(0)\n",
       "51  The cycle continued.A window into the soul.Whe...  tensor(1)\n",
       "52  After I went to the bathroom and came back, th...  tensor(1)\n",
       "53  'If you're willing to take on the work, we can...  tensor(1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.columns = ['sentence','show/tell']\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)    0.648148\n",
       "tensor(0)    0.203704\n",
       "tensor(0)    0.148148\n",
       "Name: show/tell, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = df_result['show/tell'].value_counts(normalize=True)\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6481481481481481, 0.2037037037037037, 0.14814814814814814]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이건 character 설명 문장에 showing이 얼마나 들어가 있는지… 평균대비\n",
    "\n",
    "showing_sentence_with_char = max(round(df_fin*100))\n",
    "showing_sentence_with_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char_Showing Ratio in Sentence :  65.0\n"
     ]
    }
   ],
   "source": [
    "print ('Char_Showing Ratio in Sentence : ', showing_sentence_with_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
