{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import multiprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from gensim.models import Phrases\n",
    "from textblob import TextBlob\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_all_section(text):\n",
    "\n",
    "\n",
    "    # Number of Characters\n",
    "    def NumberofCharacters(text):\n",
    "\n",
    "        essay_input_corpus = str(text) #문장입력\n",
    "        essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "        sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "        total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "        total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "        split_sentences = []\n",
    "        for sentence in sentences:\n",
    "            processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "            words = processed.split()\n",
    "            split_sentences.append(words)\n",
    "\n",
    "        skip_gram = 1\n",
    "        workers = multiprocessing.cpu_count()\n",
    "        bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "        model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "        model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "        \n",
    "        #모델 설계 완료\n",
    "\n",
    "        #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "        character_list = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                        'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                        'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                        'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                        'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                        'twin','uncle','widow','widower','wife','ex-wife','aunt',\n",
    "                        'baby', 'beget', 'brother', 'buddy', 'conserve', 'counterpart', 'cousin', 'daughter', 'don', 'duplicate', 'ex',\n",
    "                        'father', 'forefather', 'founder', 'gemini', 'grandchild', 'granddaughter', 'grandfather', 'grandma', 'he', 'helium',\n",
    "                        'husband', 'i', 'in', 'iodine', 'law', 'maine', 'match', 'mine', 'mother', 'nephew', 'niece', 'one', 'parent', 'person',\n",
    "                        'rear', 'sister', 'son', 'stepdaughter', 'stepfather', 'stepmother', 'stepson', 'twin', 'uncle', 'widow', 'widower', 'wife']\n",
    "        \n",
    "        ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "        #우선 토큰화한다.\n",
    "        retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "        token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "        #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "        #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "        filtered_chr_text = []\n",
    "        for k in token_input_text:\n",
    "            for j in character_list:\n",
    "                if k == j:\n",
    "                    filtered_chr_text.append(j)\n",
    "        \n",
    "        #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "        \n",
    "        filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "        filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "        print (filtered_chr_text__) # 중복값 제거 확인\n",
    "        \n",
    "        for i in filtered_chr_text__:\n",
    "            ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "        \n",
    "        char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "        char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "            \n",
    "        result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "        return char_total_count\n",
    "\n",
    "\n",
    "\n",
    "    # number_of_characters = NumberofCharacters(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "    # number_of_characters\n",
    "    # print ('=============================================')\n",
    "    # print ('Number of Characters :', number_of_characters)\n",
    "    # print ('=============================================')\n",
    "\n",
    "    ####################################\n",
    "    #### Character Descriptiveness #####\n",
    "    ####################################\n",
    "\n",
    "    def character_descrip(text):\n",
    "\n",
    "        input_sentence = text\n",
    "\n",
    "        def findSentence(input_sentence):\n",
    "            result = []\n",
    "\n",
    "            data = str(input_sentence)\n",
    "            #data = input_sentence.splitlines()\n",
    "            \n",
    "            findText = ['i', 'my', 'me', 'mine', 'you', 'your', 'they','them',\n",
    "                        'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                        'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                        'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                        'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                        'twin','uncle','widow','widower','wife','ex-wife','aunt',\n",
    "                        'baby', 'beget', 'brother', 'buddy', 'conserve', 'counterpart', 'cousin', 'daughter', 'don', 'duplicate', 'ex',\n",
    "                        'father', 'forefather', 'founder', 'gemini', 'grandchild', 'granddaughter', 'grandfather', 'grandma', 'he', 'helium',\n",
    "                        'husband', 'i', 'in', 'iodine', 'law', 'maine', 'match', 'mine', 'mother', 'nephew', 'niece', 'one', 'parent', 'person',\n",
    "                        'rear', 'sister', 'son', 'stepdaughter', 'stepfather', 'stepmother', 'stepson', 'twin', 'uncle', 'widow', 'widower', 'wife']\n",
    "\n",
    "            sentences = data.split(\".\")\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                for item in findText:\n",
    "                    if item in sentence:\n",
    "                        result.append(sentence)\n",
    "\n",
    "            return result\n",
    "\n",
    "        input_sent_included_character = findSentence(text) \n",
    "        input_sent_chr = set(input_sent_included_character) #중복값을 제거해보자\n",
    "        input_sent_chr = '.'.join(input_sent_chr) #하나의 문자열로 합쳐야 원본 문장처럼 변환되고, 이것을 show/tell 분석코드에 넣게됨\n",
    "\n",
    "\n",
    "\n",
    "        #입력된 전체 문장을 개별문장으로 분리하여 전처리 처리함\n",
    "        def sentence_to_df(input_sentence):\n",
    "\n",
    "            input_text_df = nltk.tokenize.sent_tokenize(input_sentence)\n",
    "            test = []\n",
    "\n",
    "            for i in range(0,len(input_text_df)):\n",
    "                new_label = np.random.randint(0,2)  # 개별문장(input_text_df) 수만큼 0 또는 1 난수 생성\n",
    "                data = [new_label, input_text_df[i]]\n",
    "                test.append(data)\n",
    "\n",
    "            #print(test)\n",
    "            dataf = pd.DataFrame(test, columns=['label', 'text'])\n",
    "            #print(dataf)\n",
    "            return dataf\n",
    "\n",
    "\n",
    "        class STDataset(Dataset):\n",
    "            ''' Showing Telling Corpus Dataset '''\n",
    "            def __init__(self, df):\n",
    "                self.df = df\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.df)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                text = self.df.iloc[idx, 1]\n",
    "                label = int(self.df.iloc[idx, 0])\n",
    "                return text, label\n",
    "\n",
    "\n",
    "        ###########입력받은 데이터 처리 실행하는 메소드 showtell_classfy() ###############\n",
    "        #result_all.html에서 입력받을 text를 contents에 넣고 전처리 후 데이터프레임에 넣어줌\n",
    "        def showtell_classfy(text):\n",
    "            contents = str(text)\n",
    "            preprossed_contents_df = sentence_to_df(contents)\n",
    "\n",
    "            preprossed_contents_df.dropna(inplace=True)\n",
    "            #전처리된 데이터를 확인(데이터프레임으로 가공됨)\n",
    "            preprossed_contents_df__ = preprossed_contents_df.sample(frac=1, random_state=999)\n",
    "            \n",
    "\n",
    "            #파이토치에 입력하기 위해서 로딩...\n",
    "            ST_test_dataset = STDataset(preprossed_contents_df__)\n",
    "            test_loader = DataLoader(ST_test_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "            #로딩되는지 확인\n",
    "            ST_test_dataset.__getitem__(1)\n",
    "\n",
    "            #time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "            #check whether cuda is available\n",
    "            #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "            device = torch.device(\"cpu\")  \n",
    "            #device = torch.device(\"cuda\")\n",
    "            #tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "            model = BertForSequenceClassification.from_pretrained('bert-large-cased')\n",
    "            model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "            # for text, label in test_loader :\n",
    "            #     print(\"text:\",text)\n",
    "            #     print(\"label:\",label)\n",
    "\n",
    "\n",
    "            #저장된 모델을 불러온다.\n",
    "            #J:\\Django\\EssayFit_Django\\essayfitaiproject\\essayfitapp\\model.pt\n",
    "            #time.sleep(1)\n",
    "            #model = torch.load(\"/Users/jongphilkim/Desktop/Django_WEB/essayfitaiproject/essayai/model.pt\", map_location=torch.device('cpu'))\n",
    "            model = torch.load(\"model.pt\", map_location=torch.device('cpu'))\n",
    "            print(\"model loadling~\")\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            pred_loader = test_loader\n",
    "            print(\"pred_loader:\", pred_loader)\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_showing__ = 0\n",
    "            total_telling__ = 0\n",
    "\n",
    "            showing_conunter = [] #문장에 해당하는 SHOWING을 계산한다.\n",
    "            \n",
    "            print(\"check!\")\n",
    "            for text, label in pred_loader:\n",
    "                print(\"text:\",text)\n",
    "                #print(\"label:\",label)\n",
    "                encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text] #text to tokenize\n",
    "                padded_list =  [e + [0] * (512-len(e)) for e in encoded_list] #padding\n",
    "                sample = torch.tensor(padded_list) #torch tensor로 변환\n",
    "                sample, label = sample.to(device), label.to(device) #tokenized text에 label을 넣어서 Device(gpu/cpu)에 넣기 위해 준비\n",
    "                labels = torch.tensor(label) #레이블을 텐서로 변환\n",
    "                #time.sleep(1)\n",
    "                outputs = model(sample,labels=labels) #모델을 통해서 샘플텍스트와 레이블 입력데이터를 출력 output에 넣음\n",
    "                #시간 딜레이를 주자\n",
    "                #time.sleep(1)\n",
    "                _, logits = outputs #outputs를 로짓에 넣음 이것을 softmax에 넣으면 0~1 사이로 결과가 출력됨\n",
    "                \n",
    "                pred = torch.argmax(F.softmax(logits), dim=1) #드디어 예측한다. argmax는 리스트(계산된 값)에서 가장 큰 값을 추출하여 pred에 넣는다. 0 ~1 사이의 값이 나올거임\n",
    "                print('pred :', pred)\n",
    "                # correct = pred.eq(labels) \n",
    "                showing__ = pred.eq(1) # 예측한 결과가 1과 같으면 showing이다   >> TRUE   SHOWING을 추출하려면 이것만 카운드하면 된다. \n",
    "                telling__ = pred.eq(0) # 예측한 결과가 0과 같으면 telling이다   >> FALSE\n",
    "                \n",
    "                #print('showing : ', showing__)\n",
    "                #print('telling : ', telling__)\n",
    "                \n",
    "                \n",
    "                showing_conunter.append(text)        \n",
    "                #pred_ = round(float(pred))\n",
    "                showing_conunter.append(pred)\n",
    "\n",
    "\n",
    "\n",
    "            return showing_conunter \n",
    "\n",
    "\n",
    "        st_re = showtell_classfy(str(input_sent_chr)) # 캐릭터거 포함된 문장(전처리 완료된) 입력\n",
    "\n",
    "        df = DataFrame(st_re)\n",
    "        df_ = df[0::2] # 글만 추출\n",
    "        df_label = df[1::2] # 레이블만 추출\n",
    "\n",
    "        df_.reset_index(drop=True, inplace=True) #데이터를 합치기 위해서 초기화\n",
    "        df_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_result = pd.concat([df_,df_label],axis=1) #합치기\n",
    "\n",
    "        df_result.columns = ['sentence','show/tell']\n",
    "\n",
    "        df_fin = df_result['show/tell'].value_counts(normalize=True)\n",
    "        list(df_fin)\n",
    "        showing_sentence_with_char = max(round(df_fin*100))\n",
    "\n",
    "        # print(\"===============================================================\")\n",
    "        # print ('Character Descriptiveness : ', showing_sentence_with_char)\n",
    "        # print(\"===============================================================\")\n",
    "\n",
    "        return showing_sentence_with_char\n",
    "\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    #############  Emphasis on YOU  ################\n",
    "    ################################################\n",
    "    def EmphasisOnYou(text):\n",
    "\n",
    "        essay_input_corpus = str(text) #문장입력\n",
    "        essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "        sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "        total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "        total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "        split_sentences = []\n",
    "        for sentence in sentences:\n",
    "            processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "            words = processed.split()\n",
    "            split_sentences.append(words)\n",
    "\n",
    "        skip_gram = 1\n",
    "        workers = multiprocessing.cpu_count()\n",
    "        bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "        model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "        model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "        \n",
    "        #모델 설계 완료\n",
    "\n",
    "        #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "        character_list = ['i', 'I', 'my', 'me', 'mine', 'one']\n",
    "        \n",
    "        ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "        #우선 토큰화한다.\n",
    "        retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "        token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "        #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "        #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "        filtered_chr_text = []\n",
    "        for k in token_input_text:\n",
    "            for j in character_list:\n",
    "                if k == j:\n",
    "                    filtered_chr_text.append(j)\n",
    "        \n",
    "        #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "        \n",
    "        filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "        filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "        print (filtered_chr_text__) # 중복값 제거 확인\n",
    "        \n",
    "        for i in filtered_chr_text__:\n",
    "            ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "        \n",
    "        char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "        char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "            \n",
    "        result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "        return char_total_count\n",
    "\n",
    "\n",
    "    # EmphasisOnYou_ = EmphasisOnYou(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "    # EmphasisOnYou_\n",
    "    # print ('=============================================')\n",
    "    # print ('Emphasis on You :', EmphasisOnYou_)\n",
    "    # print ('=============================================')\n",
    "\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ######### Emphasis on others  ###########\n",
    "    #########################################\n",
    "    def EmphasisOnOthers(text):\n",
    "\n",
    "        essay_input_corpus = str(text) #문장입력\n",
    "        essay_input_corpus = essay_input_corpus.lower()#소문자 변환\n",
    "\n",
    "        sentences  = sent_tokenize(essay_input_corpus) #문장 토큰화\n",
    "        total_sentences = len(sentences)#토큰으로 처리된 총 문장 수\n",
    "        total_words = len(word_tokenize(essay_input_corpus))# 총 단어수\n",
    "        split_sentences = []\n",
    "        for sentence in sentences:\n",
    "            processed = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "            words = processed.split()\n",
    "            split_sentences.append(words)\n",
    "\n",
    "        skip_gram = 1\n",
    "        workers = multiprocessing.cpu_count()\n",
    "        bigram_transformer = Phrases(split_sentences)\n",
    "\n",
    "        model = gensim.models.word2vec.Word2Vec(bigram_transformer[split_sentences], workers=workers, sg=skip_gram, min_count=1)\n",
    "\n",
    "        model.train(split_sentences, total_examples=sum([len(sentence) for sentence in sentences]), epochs=100)\n",
    "        \n",
    "        #모델 설계 완료\n",
    "\n",
    "        #캐릭터 표현하는 단어들을 리스트에 넣어서 필터로 만들고\n",
    "        character_list = ['you', 'your', 'they','them',\n",
    "                        'yours', 'he','him','his' 'she','her','it','someone','their', 'myself', 'aunt',\n",
    "                        'brother','cousin','daughter','father','grandchild','granddaughter','granddson','grandfather',\n",
    "                        'grandmother','great-grandchild','husband','ex-husband','son-in-law', 'daughter-in-law','mother',\n",
    "                        'niece','nephew','parents','sister','son','stepfather','stepmother','stepdaughter', 'stepson',\n",
    "                        'twin','uncle','widow','widower','wife','ex-wife','aunt',\n",
    "                        'baby', 'beget', 'brother', 'buddy', 'conserve', 'counterpart', 'cousin',\n",
    "                        'daughter', 'don', 'duplicate', 'ex', 'father', 'forefather', 'founder', 'gemini',\n",
    "                        'grandchild', 'granddaughter', 'grandfather', 'grandma', 'he', 'helium', 'husband',\n",
    "                        'in', 'law', 'match', 'mother', 'nephew', 'niece', 'parent', 'person', 'rear',\n",
    "                        'sister', 'son', 'stepdaughter', 'stepfather', 'stepmother', 'stepson', 'twin', 'uncle', 'widow',\n",
    "                        'widower', 'wife']\n",
    "        \n",
    "        ####문장에 char_list의 단어들이 있는지 확인하고, 있다면 유사단어를 추출한다.\n",
    "        #우선 토큰화한다.\n",
    "        retokenize = RegexpTokenizer(\"[\\w]+\") #줄바꿈 제거하여 한줄로 만들고\n",
    "        token_input_text = retokenize.tokenize(essay_input_corpus)\n",
    "        #print (token_input_text) #토큰화 처리 확인.. 토큰들이 리스트에 담김\n",
    "        #리트스로 정리된 개별 토큰을 char_list와 비교해서 존재하는 것만 추출한다.\n",
    "        filtered_chr_text = []\n",
    "        for k in token_input_text:\n",
    "            for j in character_list:\n",
    "                if k == j:\n",
    "                    filtered_chr_text.append(j)\n",
    "        \n",
    "        #print (filtered_chr_text) # 유사단어 비교 추출 완료, 겹치는 단어는 제거하자.\n",
    "        \n",
    "        filtered_chr_text_ = set(filtered_chr_text) #중복제거\n",
    "        filtered_chr_text__ = list(filtered_chr_text_) #다시 리스트로 변환\n",
    "        print (filtered_chr_text__) # 중복값 제거 확인\n",
    "        \n",
    "        for i in filtered_chr_text__:\n",
    "            ext_sim_words_key = model.most_similar_cosmul(i) #모델적용\n",
    "        \n",
    "        char_total_count = len(filtered_chr_text) # 중복이 제거되지 않은 에세이 총 문장에 사용된 캐릭터 표현 수\n",
    "        char_count_ = len(filtered_chr_text__) #중복제거된 캐릭터 표현 총 수\n",
    "            \n",
    "        result_char_ratio = round(char_total_count/total_words * 100, 2)\n",
    "    \n",
    "    \n",
    "        return char_total_count\n",
    "\n",
    "\n",
    "    # EmphasisOnOthers_ = EmphasisOnOthers(input_text) # 문장에서 키워드와 관련된 단어을 모두 추출하면 이런 결과가 나옴, 이 결과를 모두 합쳐서 캐릭터 총 값 계산해서 숫자로 출력\n",
    "    # EmphasisOnOthers_\n",
    "    # print ('=============================================')\n",
    "    # print ('Emphasis on Others :', EmphasisOnOthers_)\n",
    "    # print ('=============================================')\n",
    "\n",
    "\n",
    "    character_descriptiveness = character_descrip(text)\n",
    "    print(\"===============================================================\")\n",
    "    print ('Character Descriptiveness : ' , character_descriptiveness)\n",
    "    print(\"===============================================================\")\n",
    "\n",
    "\n",
    "    number_of_characters = NumberofCharacters(text) \n",
    "    print ('=============================================')\n",
    "    print ('Number of Characters :' , number_of_characters)\n",
    "    print ('=============================================')\n",
    "\n",
    "\n",
    "    EmphasisOnYou_ = EmphasisOnYou(text)\n",
    "    print ('=============================================')\n",
    "    print ('Emphasis on You :' , EmphasisOnYou_)\n",
    "    print ('=============================================')\n",
    "\n",
    "\n",
    "    EmphasisOnOthers_ = EmphasisOnOthers(text) \n",
    "    print ('=============================================')\n",
    "    print ('Emphasis on Others :' , EmphasisOnOthers_)\n",
    "    print ('=============================================')\n",
    "\n",
    "\n",
    "    return character_descriptiveness, number_of_characters, EmphasisOnYou_, EmphasisOnOthers_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['each_personal_essay_0.json',\n",
       " 'each_personal_essay_1.json',\n",
       " 'each_personal_essay_10.json',\n",
       " 'each_personal_essay_11.json',\n",
       " 'each_personal_essay_12.json',\n",
       " 'each_personal_essay_13.json',\n",
       " 'each_personal_essay_14.json',\n",
       " 'each_personal_essay_15.json',\n",
       " 'each_personal_essay_2.json',\n",
       " 'each_personal_essay_21.json',\n",
       " 'each_personal_essay_22.json',\n",
       " 'each_personal_essay_23.json',\n",
       " 'each_personal_essay_24.json',\n",
       " 'each_personal_essay_25.json',\n",
       " 'each_personal_essay_26.json',\n",
       " 'each_personal_essay_27.json',\n",
       " 'each_personal_essay_28.json',\n",
       " 'each_personal_essay_29.json',\n",
       " 'each_personal_essay_3.json',\n",
       " 'each_personal_essay_30.json',\n",
       " 'each_personal_essay_4.json',\n",
       " 'each_personal_essay_5.json',\n",
       " 'each_personal_essay_6.json',\n",
       " 'each_personal_essay_7.json',\n",
       " 'each_personal_essay_8.json',\n",
       " 'each_personal_essay_9.json']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"C:\\\\Users\\\\cacki\\\\Projects\\\\008_AI\\\\Story_Analysis-master8\\\\Story_Analysis-master\\\\CHARACTER_\\\\ps_data_test\\\\\"\n",
    "file_list = os.listdir(path)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x0000023841B4C788>\n",
      "check!\n",
      "text: ('I also follow many different fashion accounts on instagram and like to see what other people are wearing and their style.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('After looking through the Columbia Spectator, I noticed an article about the native presence at Columbia, or rather lack thereof.',)\n",
      "pred : tensor([1])\n",
      "text: ('The only thing other than stubbornness that my parents have in common is their devotion to academics.',)\n",
      "pred : tensor([1])\n",
      "text: ('\"}, {\"index\": 1, \"personal_essay\": \"My ideal college is a combination of challenging and supportive.',)\n",
      "pred : tensor([1])\n",
      "text: ('I also need a community that will support me and my needs, allowing me to flourish in an otherwise challenging environment.',)\n",
      "pred : tensor([1])\n",
      "text: (\"These racist comments highlight the battle I've been in for a lifetime.A white classmate recently questioned my authenticity as a Native, and another in the same week told me with envy that I was a 'check-box' for colleges.\",)\n",
      "pred : tensor([1])\n",
      "text: ('My parents have been divorced for five years and have been at war ever since.',)\n",
      "pred : tensor([0])\n",
      "text: ('I hope to have challenging academics and social interactions that push me and what I currently believe, expanding my world view.',)\n",
      "pred : tensor([1])\n",
      "text: ('I use social media to inspire my own life, fashion sense, and artistic projects.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have also always loved science and math, and they have always been my favorite classes.',)\n",
      "pred : tensor([1])\n",
      "text: ('I think the history of native people is critical in amending the atrocities committed against them.',)\n",
      "pred : tensor([1])\n",
      "text: ('If you are currently undecided, please write about any field or fields in which you may have an interest at this time.',)\n",
      "pred : tensor([1])\n",
      "text: ('I now unapologetically take ownership over every aspect of my life.',)\n",
      "pred : tensor([1])\n",
      "text: ('To me, growing up meant the disillusionment of my parents as heros, and the struggle of not being able to rely on them anymore.',)\n",
      "pred : tensor([1])\n",
      "text: (\"It's hard to know what to focus on to keep myself from getting motion sick.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I have had to practically wrestle the pride out of my parents to get them to communicate on every little aspect of my life.',)\n",
      "pred : tensor([1])\n",
      "text: (\"My identity and insecurities won't go away, but in my life of reconciling, I have found confidence and peace in myself.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Myschool has become my safe place, the window where I can see my reflection, despite the blurring trees in the background.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have a sick aunt with a currently incurable disease and I wish I could use my knowledge of math and science to help her and others in her situation.',)\n",
      "pred : tensor([1])\n",
      "text: ('I know currently tribes still struggle with maintaining and regaining sovereignty.',)\n",
      "pred : tensor([0])\n",
      "text: ('For applicants to Columbia College, please tell us what from your current and past experiences (either academic or personal) attracts you specifically to the field or fields of study that you noted in the Member Questions section.',)\n",
      "pred : tensor([1])\n",
      "text: (\"(150 words or less)*Some of my favorite books from the past year in school were Station Eleven, The Round House, Residue Years, and Shakespeare's Sonnets.\",)\n",
      "pred : tensor([1])\n",
      "text: ('While I move between the two houses, shuffling back and forth by court order, I never feel at home in either house, with either parent, or in either half of my identity; I can float back and forth but never touch the ground.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have always been in the middle between two people I love the most who cannot manage to love each other.',)\n",
      "pred : tensor([1])\n",
      "text: ('The article also mentioned College Horizons, which I would be attending in 2 months at the time.',)\n",
      "pred : tensor([1])\n",
      "text: ('An entire ocean has always separated the two halves of my identity, but a divorce drove them further away.',)\n",
      "pred : tensor([1])\n",
      "text: ('(150 words or less)*List the titles of the films, concerts, shows, exhibits, lectures and other entertainment you enjoyed most in the past year.',)\n",
      "pred : tensor([1])\n",
      "text: ('I am not sure how my future will include all of them, but I know it will, and I know I will also find new interests along the way.',)\n",
      "pred : tensor([1])\n",
      "text: ('Now, those comments are just part of the blur; trees whizzing past me as I continue towards my horizon.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I feel like I'm in a long car ride, looking at the trees become a blur.My favorite movie I saw recently is Someone Great.\",)\n",
      "pred : tensor([1])\n",
      "text: ('At school I can work hard and dream about a future where there is stillness, my horizon.Please tell us what you value most about Columbia and why.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I use pinterest and instagram to save other people's art, and images I would like to paint or draw.\",)\n",
      "pred : tensor([1])\n",
      "text: ('My interests all feel very different from each other, but all three areas are important to me.',)\n",
      "pred : tensor([1])\n",
      "text: (\"(150 words or less)*When I first saw Columbia, my Grandma's friend toured us around the campus.\",)\n",
      "pred : tensor([1])\n",
      "text: ('While I immediately loved the beautiful libraries and city campus, something else stuck out to me.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I carry both of my parents' identities: Danish and Native.\",)\n",
      "pred : tensor([1])\n",
      "text: ('To survive in my circumstance, I had to mature into the person that takes care of things.',)\n",
      "pred : tensor([1])\n",
      "text: ('(150 words or less)*List the titles of the books you read for pleasure that you enjoyed most in the past year.',)\n",
      "pred : tensor([1])\n",
      "text: ('I studied the progression of government relations with tribal sovereignty.',)\n",
      "pred : tensor([1])\n",
      "text: ('From that article I knew that not only would Columbia have a native community I could join, but the native community there was strong enough to stand up for itself.',)\n",
      "pred : tensor([1])\n",
      "text: ('One of my main interests is Native American studies.',)\n",
      "pred : tensor([0])\n",
      "text: ('When I am in a rut I will look at my saved photos and copy or riff off of them.',)\n",
      "pred : tensor([1])\n",
      "text: ('I liked piecing together the progression of tribal sovereignty, despite the tragic deterioration over time.',)\n",
      "pred : tensor([1])\n",
      "text: ('Another interest I have is art.',)\n",
      "pred : tensor([0])\n",
      "text: ('I would love to go to a school that not only has a native presence, but continues to push itself to be better and expand that presence.',)\n",
      "pred : tensor([1])\n",
      "text: ('Being Native American, I am looking for a school that will have a strong cultural center that I can be a part of.List the titles of the required readings from courses during the school year or summer that you enjoyed most in the past year.',)\n",
      "pred : tensor([1])\n",
      "text: ('Two of my favorite art galleries I visit regularly are the Yale art gallery and the New Museum.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I'm in motion, heading forwards.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I also think the annual Powwow seems fun.',)\n",
      "pred : tensor([1])\n",
      "text: ('They have always encouraged my education and been able to agree on that.',)\n",
      "pred : tensor([0])\n",
      "text: ('As I am whipped around and pulled between my parents, I\\'ve had to find a horizon to look at: something in the distance that from far enough away seems still.0\"}, \"data\": [{\"index\": 0, \"personal_essay\": \" In my life and family, I have always felt in the middle between two warring halves of my identity: my mother and my father.I hope to find a community where I can be Native on my own terms; a community where I can also be Danish; a community where I won\\'t feel shame in one identity because of the other; a community that can be a home where I don\\'t have to pack up and leave every Tuesday and Thursday.',)\n",
      "pred : tensor([1])\n",
      "text: ('Most of the material I consume electronically is social media based.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have realized that the beauty of my circumstance is that I must work so hard to keep my halves together and the perseverance and initiative I have learned are invaluable.',)\n",
      "pred : tensor([1])\n",
      "text: ('{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"personal_essay\", \"type\": \"string\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.',)\n",
      "pred : tensor([1])\n",
      "text: ('(300 words or less)*Currently I am undecided in my major.',)\n",
      "pred : tensor([1])\n",
      "text: (' While I will always have a personal love of art and literature and will continue to read and paint regardless of my major or career, I hope to have some artistic component in my future.While my parents gave me my two identity halves, I have had to work to keep them together; ensuring they do not split apart like the parents they come from.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('I am currently reading Between the World and Me by Ta-Nehisi Coates.',)\n",
      "pred : tensor([1])\n",
      "text: ('(150 words or less)*List the titles of the print, electronic publications and websites you read regularly.',)\n",
      "pred : tensor([1])\n",
      "text: ('I also recently re-read Jane Eyre by Charlotte Bronte and The Perks of Being a Wallflower by Stephen Chbosky, my two favorite books ever.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have also been enjoying documentaries such as The Mars Generation, Reversing Roe, Forks over Knives, and Take your Pills.',)\n",
      "pred : tensor([1])\n",
      "text: (\"The article, written by a member of Columbia's cultural center, pointed out that the school should do a better job of recruiting native students from many different tribes, socio economic backgrounds, and regions.\",)\n",
      "pred : tensor([1])\n",
      "text: ('If my Danish mom and Native dad cannot be together, how can those two aspects of my identity be together in me?In my life constantly moving between houses, it is hard to feel at home; hard to feel at rest.',)\n",
      "pred : tensor([1])\n",
      "text: ('I hope that at Columbia I can aid this effort and that I will be pushed to be a better version of myself as well.',)\n",
      "pred : tensor([1])\n",
      "text: ('Some of my favorite concerts I saw this year were Kendrick Lamar and Brockhampton.',)\n",
      "pred : tensor([0])\n",
      "text: ('List a few words or phrases that describe your ideal college community',)\n",
      "pred : tensor([1])\n",
      "text: (\"I have written three research papers in high school on the history of Native American law.When I first saw Columbia, my Grandma's friend toured us around the campus.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I regularly reread books and enjoy reading one of my favorite books with a new perspective.',)\n",
      "pred : tensor([1])\n",
      "text: ('My mom is Danish and her entire family still lives in Denmark.',)\n",
      "pred : tensor([0])\n",
      "text: ('I also have been watching two TV shows recently: On My Block and American Horror story.',)\n",
      "pred : tensor([1])\n",
      "text: ('With my own personal ties to Native communities, I feel a duty to help them.',)\n",
      "pred : tensor([1])\n",
      "text: ('Although the environment of my school can feel constricting, it is also freeing.',)\n",
      "pred : tensor([1])\n",
      "text: ('My family jokes how I am the odd one out because I actually understand and enjoy it.My two favorite  most recent reads were The Poet X by Elizabeth Acevedo and Becoming by Michelle Obama.',)\n",
      "pred : tensor([1])\n",
      "text: ('I like how biology relates to everyone and hope that through my studies I can help other people.',)\n",
      "pred : tensor([1])\n",
      "text: ('My dad is Native American and is a Native American history professor.',)\n",
      "pred : tensor([0])\n",
      "text: ('I also read the Wall Street Journal, New York Times, and other news websites to stay updated on political issues.If I can make my parents compromise, and make peace between my warring halves, not only can I finally exist peacefully as myself, but I can reconcile any situation.',)\n",
      "pred : tensor([1])\n",
      "text: (\"My Grandma's friend told me her greatest advice looking at colleges was to read the student newspapers to better gauge the students at the school, and how the school allows students to express themselves.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I see myself most likely studying something related to Biology.',)\n",
      "pred : tensor([0])\n",
      "text: ('I use many different social media platforms to connect with my friends and for inspiration.',)\n",
      "pred : tensor([1])\n",
      "===============================================================\n",
      "Character Descriptiveness :  88.0\n",
      "===============================================================\n",
      "['they', 'it', 'person', 'in', 'myself', 'me', 'parent', 'don', 'her', 'their', 'aunt', 'your', 'father', 'you', 'grandma', 'parents', 'them', 'mother', 'someone', 'law', 'my', 'one', 'i']\n",
      "=============================================\n",
      "Number of Characters : 388\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'my', 'one', 'me']\n",
      "=============================================\n",
      "Emphasis on You : 185\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:310: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:387: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "  4%|▍         | 1/26 [02:41<1:07:29, 161.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'it', 'person', 'in', 'myself', 'parent', 'don', 'her', 'their', 'aunt', 'your', 'father', 'you', 'grandma', 'parents', 'them', 'mother', 'someone', 'law']\n",
      "=============================================\n",
      "Emphasis on Others : 101\n",
      "=============================================\n",
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x00000238398E1EC8>\n",
      "check!\n",
      "text: (\"From the complex historical backdrop of WWII to Rodgers and Hammerstein's beautiful score, this movie-musical encapsulates the kind of masterful storytelling I wish to accomplish in my own aspirations as a writer and actress.\",)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('The first year was filled with trial and error, leading to many valuable questions about how a school should run.',)\n",
      "pred : tensor([1])\n",
      "text: ('Now, as I journey towards another campus, I yearn to maintain the hope that God often reveals Himself through the simplest signs: a kind word of a friend, a particular song that strikes the soul, or the majesty of the morning sky.',)\n",
      "pred : tensor([1])\n",
      "text: ('I can write stories and poems and enjoy lending a listening ear to the often dramatic storytelling of those around me',)\n",
      "pred : tensor([1])\n",
      "text: ('In the winter of our first year, we performed the inaugural play, bringing together a diverse group of both athletes and artists who recited their lines with gusto and flair, despite our small audience.Years later, in my junior year of high school, the most academically and socially strenuous of my life, I was provided a chance to place my faith in God and His plan once again.',)\n",
      "pred : tensor([1])\n",
      "text: ('How has faith influenced your life thus far and what will you add to the continued conversation of faith on campus?',)\n",
      "pred : tensor([0])\n",
      "text: ('We were treated like adults, and in return, the atmosphere at school was one of mutual respect and ease of conversation.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Add the glorious collection of show stopping songs and I'm in heaven.\",)\n",
      "pred : tensor([1])\n",
      "text: ('There were just forty-five of us.',)\n",
      "pred : tensor([0])\n",
      "text: ('Students, faculty, and staff members of all faith traditions are welcome to become part of the Pepperdine University community.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Before high school, being a 'good student' consisted of sitting quietly in my chair, listening to the teacher, and dutifully following instructions.\",)\n",
      "pred : tensor([1])\n",
      "text: ('These past years have been full of immense growth, both academically and emotionally.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Before high school, being a 'good student' consisted of sitting quietly in my chair, listening to the teacher, and following instructions dutifully.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I could masterfully compose poems and enjoyed lending a listening ear to the continuous storytelling of those around me.',)\n",
      "pred : tensor([1])\n",
      "text: ('If I refused to carry with me the empathy and compassion I learned through Socratic dialogue, countless hours of discussion and teaching would be lost.',)\n",
      "pred : tensor([1])\n",
      "text: ('That first year was a dream.',)\n",
      "pred : tensor([0])\n",
      "text: ('During lunch, students and teachers sat together and talked about class literature as well as our favorite TV shows.',)\n",
      "pred : tensor([1])\n",
      "text: (\"SPU's vision means that you can pursue an education that helps you change the world for the better.\",)\n",
      "pred : tensor([1])\n",
      "text: ('(50-300 words)\"}]}.',)\n",
      "pred : tensor([1])\n",
      "text: ('With our large stack of new books in hand and little real idea of what was yet to come, we stepped onto the small campus to start our new adventure.',)\n",
      "pred : tensor([1])\n",
      "text: ('Peeking through my fingers at the dark auditorium to see if anyone else was going to heed the call, I shakily raised my hand.',)\n",
      "pred : tensor([1])\n",
      "text: ('As a founding member of a private Christian high school that follows a college preparatory liberal arts curriculum, I have had the opportunity to study a plethora of literary and philosophical classics in Socratic seminars.',)\n",
      "pred : tensor([1])\n",
      "text: ('These traits, upon reflection, were not in short supply.',)\n",
      "pred : tensor([0])\n",
      "text: ('In classes like English and World History, I engaged in hours of the Socratic method, discussing fictions, primary sources, philosophy, and poetry.',)\n",
      "pred : tensor([1])\n",
      "text: (\"How does Seattle Pacific's vision align with your desires for college?\",)\n",
      "pred : tensor([0])\n",
      "text: ('I signed up for student government and successfully helped lead my school as a Prefect for two years.',)\n",
      "pred : tensor([0])\n",
      "text: (\"I had always had a bit of social anxiety growing up, I thought, but doesn't everyone, at least to a certain extent?\",)\n",
      "pred : tensor([1])\n",
      "text: ('Rather, it is the mistrust in my own abilities that hinders my confidence.',)\n",
      "pred : tensor([1])\n",
      "text: ('As a ninth grader, I suddenly found myself transported to an environment where verbal participation was graded, and the quiet, studious persona I had cultivated was forced to shift into something bolder.',)\n",
      "pred : tensor([1])\n",
      "text: ('Additionally, through my passionate study of literature, I understand the great value in personally interacting with people whose backgrounds and worldviews differ from my own.',)\n",
      "pred : tensor([1])\n",
      "text: ('This has provided a wonderful foundation in my pursuit to think critically about the history of ideas that shape our present world.',)\n",
      "pred : tensor([1])\n",
      "text: ('But being bold, verbalizing my inner thoughts, is a separate challenge.',)\n",
      "pred : tensor([1])\n",
      "text: ('We instituted a student government, and quickly realized how valuable it was to allow input from each member, instead of an authoritarian head.',)\n",
      "pred : tensor([1])\n",
      "text: ('Forty five timid yet daring freshman and sophomores who took the courageous first step into building culture and tradition.',)\n",
      "pred : tensor([1])\n",
      "text: ('I auditioned and was cast as the lead in the school musical.',)\n",
      "pred : tensor([1])\n",
      "text: ('Maria is a woman of empowerment, who wrestles with her devotion to God amidst a desire to explore a courageous life beyond the abbey walls.',)\n",
      "pred : tensor([1])\n",
      "text: ('In these moments of stress, I recognized the necessity to depend in One endlessly more capable than I.',)\n",
      "pred : tensor([1])\n",
      "text: ('We founded sports teams, including indoor and beach volleyball, soccer, basketball, cross country and track, and performed surprisingly well at our various matches and meets.',)\n",
      "pred : tensor([1])\n",
      "text: ('When faced with a question or concern, I could knock on the Head of School\\'s door and begin a personal dialogue.0\"}, \"data\": [{\"index\": 0, \"personal_essay\": \"High school has been full of immense growth, both academically and emotionally.',)\n",
      "pred : tensor([1])\n",
      "text: ('I believe we desperately need other people, to see ourselves, our vocations,, our respective vocations, and the world with clarity and hope.',)\n",
      "pred : tensor([1])\n",
      "text: ('At first, I struggled to find and maintain this boldness.',)\n",
      "pred : tensor([1])\n",
      "text: ('I signed up for student government and successfully helped lead my school as a prefect for two years.',)\n",
      "pred : tensor([0])\n",
      "text: ('In them, main characters struggle with their individuality and eventually come to the conclusion that consolation is found in community.',)\n",
      "pred : tensor([1])\n",
      "text: ('It was a time of excitement and beginnings.',)\n",
      "pred : tensor([1])\n",
      "text: ('Lewis, I have spent a substantial amount of time discussing and purposefully reflecting on my own philosophy of life.',)\n",
      "pred : tensor([1])\n",
      "text: ('At Seattle Pacific, we encourage all students to explore or go deeper in Christian faith and to be inspired to make a difference.',)\n",
      "pred : tensor([1])\n",
      "text: ('(250-500)Sitting in elementary school chapel with lights dimmed, our speaker requested we close our eyes and raise our hands if we desired to join him in a prayer to accept Jesus Christ.',)\n",
      "pred : tensor([1])\n",
      "text: ('In an attempt to organize my cluttered brain, I reflected on the times when I had stepped out in courage, and was immediately struck with how rewarding those moments had been.',)\n",
      "pred : tensor([1])\n",
      "text: ('It is the vein through which truth is reached, action steps are identified, and the world can be made a better place.',)\n",
      "pred : tensor([1])\n",
      "text: (\"She demonstrates emotional vulnerability and determination in the face of Baron von Trapp and his children, representing holistic traits that often go amiss in female protagonists.'\",)\n",
      "pred : tensor([1])\n",
      "text: ('Rather, it was the mistrust in my own abilities that hindered my confidence.',)\n",
      "pred : tensor([1])\n",
      "text: ('While my skills as a writer blossomed into prose I was immensely proud of, discussions proved much more difficult.',)\n",
      "pred : tensor([0])\n",
      "text: ('The confidence I needed to lead, to be a good student and a faithful friend, and to speak boldly when I had something to say.',)\n",
      "pred : tensor([1])\n",
      "text: ('Because I had attended this school since before kindergarten, chapels of this sort were commonplace.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([0])\n",
      "text: ('The confidence I need to lead, to be a good student and a faithful friend, and to be a founding member of a high school.',)\n",
      "pred : tensor([1])\n",
      "text: ('Instead, I resolve to hold loosely to judgments and tightly to the lessons literature has taught me.',)\n",
      "pred : tensor([1])\n",
      "text: ('As a ninth grader, I suddenly found myself in an environment where verbal participation was graded, and the quiet, studious persona I once upheld needed to shift into something more bold.',)\n",
      "pred : tensor([1])\n",
      "text: ('While my skills as a writer blossomed into prose that I was proud to call my own, the discussions proved much more difficult for me.',)\n",
      "pred : tensor([1])\n",
      "text: ('If you could star in any movie, what movie would you pick and why?I absolutely love to read.',)\n",
      "pred : tensor([1])\n",
      "text: (\"The words of Psalm 94:19 brought me consolation; 'When I said, \\\\\\\\\\\\u2018My foot is slipping,' your unfailing love, Lord, supported me.\",)\n",
      "pred : tensor([1])\n",
      "text: ('In classes like English and World History, I engaged in the Socratic method to discuss great works of fiction, philosophy, and poetry.',)\n",
      "pred : tensor([1])\n",
      "text: ('During my junior year, finding myself frustrated at my lackluster participation, I decided, like introverts often do, to take a step back and examine why I felt this fear.',)\n",
      "pred : tensor([1])\n",
      "text: ('I have struggled with finding and maintaining this boldness.',)\n",
      "pred : tensor([1])\n",
      "text: ('With only forty five kids and seven teachers on campus, everything and everyone was accessible.',)\n",
      "pred : tensor([1])\n",
      "text: ('As an introvert, I am confident in my own abilities to read with a critical eye and make intertextual connections.',)\n",
      "pred : tensor([1])\n",
      "text: ('In turn, I grow more secure in my perception of our world in both what is good, and what needs to be changed.',)\n",
      "pred : tensor([1])\n",
      "text: ('Taking on the role of Maria would bring me great joy.',)\n",
      "pred : tensor([1])\n",
      "text: ('Simultaneously, God provided hope that renewed my strength.',)\n",
      "pred : tensor([0])\n",
      "text: ('Pepperdine is a Christian university committed to the highest standards of academic excellence and Christian values, where students are strengthened for lives of purpose, service, and leadership.',)\n",
      "pred : tensor([1])\n",
      "text: ('When anxiety was great within me, your consolation brought me joy.',)\n",
      "pred : tensor([0])\n",
      "text: ('But, on that day, my nine-year-old heart began to understand the weight of this decision, this prayer.',)\n",
      "pred : tensor([1])\n",
      "text: ('{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"personal_essay\", \"type\": \"string\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.',)\n",
      "pred : tensor([1])\n",
      "text: ('\"}, {\"index\": 1, \"personal_essay\": \"I would love to star as Maria in The Sound of Music.',)\n",
      "pred : tensor([1])\n",
      "text: ('I can picture the first scene, opening on Julie Andrews, or in this case myself, twirling on a lush Austrian hilltop until the bells of the abbey bring me back to reality.',)\n",
      "pred : tensor([1])\n",
      "text: (' During my junior year, still frustrated at my lackluster participation, I decided, as introverts often do, to take a step back and examine my fear.',)\n",
      "pred : tensor([1])\n",
      "text: ('I was confident in my own abilities to read literature with a critical eye and make intertextual connections.',)\n",
      "pred : tensor([1])\n",
      "text: ('Because the classrooms were still being finished when school began, my Honors Biology class conducted experiments and discussions outside, without desks.',)\n",
      "pred : tensor([1])\n",
      "text: ('I wish to run with a mixture of apprehension and fervor toward the von Trapp home, reaffirming my confidence each step of the way.',)\n",
      "pred : tensor([1])\n",
      "text: ('By attending a college like Seattle Pacific, where growing my faith and engaging with the outside community and transforming the world are central focuses, I hope to broaden my worldview alongside peers who may differ religiously and politically from myself.',)\n",
      "pred : tensor([1])\n",
      "text: ('I auditioned and was cast as the lead in the musical.',)\n",
      "pred : tensor([1])\n",
      "text: (\"During the fall, I quickly became overwhelmed attempting to balance a challenging course load, Varsity volleyball, and my role as a founding member of my new school's Performing Arts department.\",)\n",
      "pred : tensor([1])\n",
      "text: ('On August 26, 2015 we opened Pacifica Christian High School.',)\n",
      "pred : tensor([0])\n",
      "text: ('These beautiful traits, upon reflection, have not been in short supply in me.',)\n",
      "pred : tensor([0])\n",
      "text: (\"The mere notion of exploring Maria's well-developed characterization, her fear of failure, desire for romance and strength as a governess, is a dream.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Three books that have specifically touched my heart are Rasselas, Jane Eyre, and Gilead.',)\n",
      "pred : tensor([1])\n",
      "text: ('I was a founding member of a high school.',)\n",
      "pred : tensor([0])\n",
      "text: (\"I couldn't carry the weight of all that needed to be done on my shoulders, and I began to cautiously release the control I had so carefully wrapped around my life.\",)\n",
      "pred : tensor([1])\n",
      "text: ('By reading authors from distant time periods such as Homer, Dante, and Bunyan, and analyzing points of view as varied as Nietzsche and C. With this hope to guide my steps, I will continue to heed His call.',)\n",
      "pred : tensor([1])\n",
      "text: ('We were a small but mighty group, who saw first year challenges as opportunities to pause and contemplate, in order that we might build a school with firm foundations.',)\n",
      "pred : tensor([1])\n",
      "text: ('How does your own faith perspective or personal story intersect with our vision?',)\n",
      "pred : tensor([0])\n",
      "text: ('But being bold, verbalizing what was going on in my head, this was a separate challenge.',)\n",
      "pred : tensor([1])\n",
      "===============================================================\n",
      "Character Descriptiveness :  84.0\n",
      "===============================================================\n",
      "['me', 'it', 'them', 'your', 'her', 'in', 'my', 'one', 'you', 'i', 'their', 'him', 'myself']\n",
      "=============================================\n",
      "Number of Characters : 258\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'my', 'one', 'me']\n",
      "=============================================\n",
      "Emphasis on You : 122\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:310: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:387: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "  8%|▊         | 2/26 [05:48<1:07:44, 169.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'them', 'your', 'in', 'you', 'her', 'their', 'him', 'myself']\n",
      "=============================================\n",
      "Emphasis on Others : 73\n",
      "=============================================\n",
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x0000023841B1A4C8>\n",
      "check!\n",
      "text: (\"Throughout the semester, both my understanding of philosophy and myself stretched to encompass new ideas.After being mistaken for her several times, I could not help but view Francesca as a standard of what the 'female Filipino jazz guitarist' should embody.\",)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('And through that 100-level class, I found not only that I loved the struggle to understand the universals of life but also that I could lean back on these pillars of philosophy to study what truly interests me.',)\n",
      "pred : tensor([1])\n",
      "text: ('Collaborative, featuring a dedicated core of musicians and jazz ensembles on campus who gather for jam sessions or gigs at nearby venues, constituting a supportive, close-knit community.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Yet with each successive playthrough, I found myself becoming more enthralled by not just the music, but Ocean's lyrics.So when I discovered the technical demand of bebop, the triplet groove, and the intricacies of chordal harmony after ten years of grueling classical piano, I was fascinated by the music's novelty.\",)\n",
      "pred : tensor([1])\n",
      "text: (' Prompt #1: In 150 words or fewer, please list a few words or phrases that describe your ideal college community.',)\n",
      "pred : tensor([1])\n",
      "text: ('As class approached, I began doubting myself, wondering if I had made a mistake in choosing the treatises of Plato over the practicality of polar coordinates.',)\n",
      "pred : tensor([1])\n",
      "text: ('Jazz guitar was not only evocative and creative, but also strangely liberating.',)\n",
      "pred : tensor([0])\n",
      "text: (\"Plato's syllogisms offered poignant insights about the virtuous life: though our desires often conflicted, they have the potential to bring about unparalleled personal fulfillment if mastered.\",)\n",
      "pred : tensor([1])\n",
      "text: ('(Yale)<br /><br />What is something about yourself that is essential to understanding you?',)\n",
      "pred : tensor([1])\n",
      "text: ('Sometimes I actually sleep, but other times I lie with my eyes closed and my mind drifting aimlessly.',)\n",
      "pred : tensor([1])\n",
      "text: ('It was through Channel Orange that I first understood the power of truly listening when someone speaks and the stirring empathy which comes as a result.',)\n",
      "pred : tensor([1])\n",
      "text: ('{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"personal_essay\", \"type\": \"string\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0',)\n",
      "pred : tensor([1])\n",
      "text: ('Cafes like Intelligentsia, Verve, and the world-famous Stumptown dot the city.',)\n",
      "pred : tensor([1])\n",
      "text: ('Songs like these have taught me to truly consider music not only as its own entity but also as an extension of a deeper relationship with the world.',)\n",
      "pred : tensor([1])\n",
      "text: ('Music has since become essential to my understanding of these narratives of the world that are so raw and painfully human.',)\n",
      "pred : tensor([1])\n",
      "text: ('A lot of people can vividly describe the first time they listened to their favorite album.',)\n",
      "pred : tensor([1])\n",
      "text: ('Ever since I listened to Channel Orange, I have had the impulse to explore quietly while asking piercing questions to understand the voices of as many people as possible.',)\n",
      "pred : tensor([1])\n",
      "text: (\"There's some moment of cathartic release when everything clicks and the music feels so closely like home.\",)\n",
      "pred : tensor([1])\n",
      "text: ('\"}, {\"index\": 1, \"personal_essay\": \"Characterized by constant academic and cultural exploration, where students discover groundbreaking ideas and culture by attending a guest speaker lecture or a Sofar Sounds Concert in an unfamiliar borough.',)\n",
      "pred : tensor([1])\n",
      "text: ('Nevertheless, as Francesca and I continued to play together, it was not long before we connected through our creative pursuit.Recently when I visited the Museum of Failure, one product stood out to me: Colgate brand Lasagna.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Though the pressure to conform was still present\\\\u2014and will likely remain present in my life no matter what genre I'm playing or what pursuits I engage in\\\\u2014I learned to eschew its corrosive influence and enjoy the rewards that it brings.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I began to explore different pedagogical methods, transcribe solos from the greats, and experiment with various approaches until my own unique sound began to develop.',)\n",
      "pred : tensor([1])\n",
      "text: (\"It's cathartic to let my brain roam freely and process whatever fascinations (like toothpaste-branded lasagna) have bottled up throughout my faster-paced days.\",)\n",
      "pred : tensor([1])\n",
      "text: ('These memories sustain me through the day by reminding me of the things I love most when dealing with the mundane means that are a part of everyday life.',)\n",
      "pred : tensor([1])\n",
      "text: (\"And, although I did not know what would be the 'best' route for me to follow as a musician, the freedom to forge whatever path I felt was right seemed to be exactly what I needed; there were no expectations for me to continue in any particular way\\\\u2014only the way that suited my own desires.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Delving further, I finally heard Channel Orange against the backdrop of the world.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Never before had I been immersed in an environment so conducive to musical growth: I was surrounded by people intensely passionate about pursuing all kinds of art with no regard for ideas of what art 'should' be.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Each song reads like an entry in a diary, poignant empathy propelling forward his plunge into struggles with his sexuality, tales of black history and criticisms of LA decadence.0\"}, \"data\": [{\"index\": 0, \"personal_essay\": \"Bloomington Normal is almost laughably clich\\\\u00e9 for a midwestern city.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Some even went as far as calling me 'other-Francesca.'\",)\n",
      "pred : tensor([0])\n",
      "text: ('Yet, underlying the trite norms of Normal is the prescriptive force of tradition\\\\u2014the expectation to fulfill my role as a female Filipino by playing Debussy in the yearly piano festival and enrolling in multivariable calculus instead of political philosophy.',)\n",
      "pred : tensor([1])\n",
      "text: ('At first I simply liked how it sounded.',)\n",
      "pred : tensor([1])\n",
      "text: ('Though the lyrics floated through my periphery at first, I was enthralled once I truly listened.',)\n",
      "pred : tensor([1])\n",
      "text: ('I ultimately found that I can embrace this warmth while still rejecting the pressure to succumb to expectations, and that, in the careful balance between these elements, I can grow in a way that feels both like discovery and home at once.',)\n",
      "pred : tensor([1])\n",
      "text: (\"By junior year, my developing interest in philosophy manifested in a decision to take Political Theory over Calc 3 as my first college class at ISU\\\\u2014something that perplexed my math teachers and made classmates question why I was 'throwing away' a leg up in math for some 100-level philosophy class.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Yet, these political ideas are stated with the understanding that the Republic Plato speaks of serves as a parallel to the human soul.',)\n",
      "pred : tensor([1])\n",
      "text: ('Yet the LP spans decades and encompass a wide cast of characters from latchkey kids to cocaine addicts, and speak to universal topics of love, loss, addiction, and memory.',)\n",
      "pred : tensor([1])\n",
      "text: ('Through Republic, I discovered that I could find balance in philosophy.',)\n",
      "pred : tensor([0])\n",
      "text: ('Write a note to your future roommate that reveals something about you or that will help your roommate\\\\u2014and us\\\\u2014know you better.',)\n",
      "pred : tensor([1])\n",
      "text: ('(Carnegie Mellon)\"}]}.',)\n",
      "pred : tensor([0])\n",
      "text: ('There is some moment of cathartic release when everything clicks and the music feels so closely like home.',)\n",
      "pred : tensor([1])\n",
      "text: ('Engaged, offering opportunities to write for insightful publications that examine both issues on campus and in the city with a critical eye.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Virtually all of Stanford's undergraduates live on campus.\",)\n",
      "pred : tensor([1])\n",
      "text: ('My infatuation with Channel Orange, though, was a gradual development.',)\n",
      "pred : tensor([1])\n",
      "text: (\"(USC)<br /><br />What do you personally want to emphasize about your application for the admission committee's consideration?\",)\n",
      "pred : tensor([1])\n",
      "text: (\"See, it's not the caffeine that brings me to life, but the act of drinking itself; it is this ritual that connects me to my moments of sipping coffee while scoring music, of dusty loose grounds on my books, and caffeinated late night jam sessions.\",)\n",
      "pred : tensor([1])\n",
      "text: ('And listening manifests in far more than just parsing the music around me\\\\u2014now, when meeting new people, I am sure to take in the geography of their personalities before assuming I have already mapped out the topography of their character.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('I knew immediately that this would be a perfect opportunity to cultivate my sound, unbounded by the limits of confining tradition.',)\n",
      "pred : tensor([1])\n",
      "text: ('Plato states that the just soul seeks truth, but to do so they must first find balance between its desires.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I'll cherish both kinds\\\\u2026 as long as I have my cup of coffee first.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"To think of the book as political philosophy is understandable; after all, it's called Republic.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Yet even during that period of silence, I could still listen to his mellow croon overlaying every nuance of prosaic beauty in everyday life.',)\n",
      "pred : tensor([1])\n",
      "text: (\"The album is a work of sonic decadence\\\\u2014Frank Ocean's mellow croon overlays a swirl of glittering analogue synths where every nuance of warm mids and crisp highs meld together to produce a beautifully hazy soundscape.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I laughed at the oxymoronic nature of the product, but I realized the only difference between me and poor Colgate Lasagna man is that I have a pressure valve to let off my weirder ideas: my naps.',)\n",
      "pred : tensor([1])\n",
      "text: ('On the first day of camp, I found that my peer guitarist in big band was another Filipino girl from Illinois.',)\n",
      "pred : tensor([1])\n",
      "text: ('Another thing - LA has amazing coffee.',)\n",
      "pred : tensor([0])\n",
      "text: ('Her improvisatory language, comping style and even personal qualities loomed above me as something I had to live up to.',)\n",
      "pred : tensor([1])\n",
      "text: ('Challenging, nurturing edifying discourse through which students of all backgrounds interrogate their own viewpoints as they learn about issues of the day.',)\n",
      "pred : tensor([1])\n",
      "text: ('Like the admittedly trite conditions of my hometown, the resemblances between us provided comfort to me through their familiarity.',)\n",
      "pred : tensor([1])\n",
      "text: ('(Staford)<br /><br />Write on something you would like us to know about you that you have not conveyed elsewhere in your application.',)\n",
      "pred : tensor([1])\n",
      "text: ('I was eager to play with her, but while I quickly recognized a slew of differences between us\\\\u2014different heights, guitars, and even playing styles\\\\u2014others seemed to have trouble making that distinction during performances.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Thus, amidst the glittering lakes and musky pine needles of Interlochen, I once again confronted Bloomington's frustrating expectations.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Professor Rankin said he viewed the book not as a template for the perfect society but as a guide to living well.',)\n",
      "pred : tensor([1])\n",
      "text: ('Happiness, I have learned, comes not from succumbing to the status quo but, rather, from finding my own truth.',)\n",
      "pred : tensor([1])\n",
      "text: (\"As roommates, we'll have a lot of mundane moments, and we'll have some exciting ones too.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"(250 words or fewer)A lot of people can vividly describe the first time they listened to their favorite album.Interdisciplinary, encouraging students to study subjects through both traditional and innovative lenses, whether by discussing literature perspective on weapons of mass destruction or deconstructing the brain's neurological responses to music.Tell us something that is meaningful to you, and why?\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Frank Ocean's mellow croon overlays a swirl of glittering analogue synths where every nuance of warm mids and crisp highs meld together to produce a beautifully hazy soundscape.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I found that I grew because of, rather than in spite of, her presence; I could find solace in our similarities and even a sense of comfort in an unfamiliar environment without being trapped by expectation.',)\n",
      "pred : tensor([1])\n",
      "text: ('Each song brought cutting narratives that dug into something raw and painfully human.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I listened to Ocean's struggles with his sexuality, stories of black history, and criticisms of LA decadence all against the context of American homophobia, racial tensions, and culture of luxurious excess prevalent in society today.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Vast swathes of corn envelop winding roads and the heady smell of BBQ smoke pervades the countryside every summer.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Many debate whether Plato's Republic is more important to political philosophy or ethics.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Until that moment, my endeavors in jazz guitar had been a solitary effort; I had no one with whom to collaborate and no one against whom I could compare myself, much less someone from a background mirroring my own.',)\n",
      "pred : tensor([1])\n",
      "text: ('And listening manifests itself in far more than just music\\\\u2014to consider more than just the face value and the first impressions of academic subjects, problems, and even people has become so important to me it feels almost inherent.While journeying this trail, I found myself at Interlochen Arts Camp the summer before my junior year.',)\n",
      "pred : tensor([1])\n",
      "text: ('A freshman year reading of The Stranger left me confused, and then intrigued, by the questions it raised.',)\n",
      "pred : tensor([1])\n",
      "text: (\"But when I was there, I barely drank it\\\\u2014if I didn't have my own musty brew from home, I was a verifiable zombie the rest of the day.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Highlight something that's important to you or something you haven't had a chance to share.The first lecture was illuminating.\",)\n",
      "pred : tensor([1])\n",
      "text: ('After Channel Orange, Ocean retreated from the public ear for an excruciating four years before his next release.',)\n",
      "pred : tensor([1])\n",
      "text: ('Considering more than just the face value and the first impressions of academic subjects, problems, and even people has become a core part of my identity and influenced the way I approach all aspects of my life.',)\n",
      "pred : tensor([1])\n",
      "text: ('When I first read Republic, I was sorely lacking this harmony.',)\n",
      "pred : tensor([0])\n",
      "text: ('Channel Orange taught me to truly consider music not only as its own entity but rather as an extension of a deeper relationship with the world.',)\n",
      "pred : tensor([1])\n",
      "text: ('While my encounter with Francesca at first sparked a feeling of pressure to conform in a setting where I never thought I would feel its presence, it also carried the warmth of finding someone with whom I could connect.',)\n",
      "pred : tensor([1])\n",
      "text: ('In time, I learned to draw inspiration from her instead of feeling pressured to follow whatever precedent I thought she set.',)\n",
      "pred : tensor([1])\n",
      "text: ('I was blindly throwing myself into math, a subject I had little passion for.',)\n",
      "pred : tensor([1])\n",
      "text: ('Delicious.',)\n",
      "pred : tensor([0])\n",
      "text: ('Although everyone always expected me to study math, philosophy offered an entirely different world.',)\n",
      "pred : tensor([0])\n",
      "===============================================================\n",
      "Character Descriptiveness :  91.0\n",
      "===============================================================\n",
      "['me', 'it', 'they', 'he', 'your', 'someone', 'her', 'my', 'in', 'one', 'you', 'i', 'their', 'myself']\n",
      "=============================================\n",
      "Number of Characters : 282\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'my', 'one', 'me']\n",
      "=============================================\n",
      "Emphasis on You : 125\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:310: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:387: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      " 12%|█▏        | 3/26 [08:52<1:06:34, 173.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'it', 'he', 'your', 'someone', 'in', 'you', 'her', 'their', 'myself']\n",
      "=============================================\n",
      "Emphasis on Others : 85\n",
      "=============================================\n",
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x00000238394C2A48>\n",
      "check!\n",
      "text: ('The community there fills the void of having no biological family in America.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([0])\n",
      "text: ('The MERGE curriculum fosters the same action-based mindset I use to succeed in dance and will propel me to start a career in international business consulting.',)\n",
      "pred : tensor([1])\n",
      "text: (\"However, once the app is full of regular users, the operating costs will remain low, as they will be focused on maintaining app security, managing technological issues, and adding to existing marketing strategies.\\\\u2014Inspired by Emily Driscoll, Class of 2018When I work with children, be it babysitting or volunteering, I am in a position to be a mentor but often find myself learning more from these children than they learn from me.'\",)\n",
      "pred : tensor([1])\n",
      "text: ('Ran\\\\u00e7o, as a slang noun, shifts from the unpleasant smell or taste of fatty food to unpleasantly describing feelings towards others.',)\n",
      "pred : tensor([1])\n",
      "text: ('As a fellow concrete jungle lover, doing research at Urban Labs will expose me to new understandings about how to improve urban life.',)\n",
      "pred : tensor([1])\n",
      "text: ('Further engagement will be augmented with a volunteer page focused on local opportunities to aid the special needs community, drawing volunteers to the app who could become interested in sitting as well.',)\n",
      "pred : tensor([1])\n",
      "text: ('Yet, an ordinary day of kindergarten turned that very phrase into a source of anxiety.',)\n",
      "pred : tensor([1])\n",
      "text: ('Once the business becomes locally profitable in Oakland County, the app can expand to other communities while leveraging existing partnerships and forging new ones.',)\n",
      "pred : tensor([1])\n",
      "text: ('Choose a word, tell us what it means, and then explain why it cannot (or should not) be translated from its original language.',)\n",
      "pred : tensor([1])\n",
      "text: ('I would study each of their movements and apply the specific stylistic and emotional choices I resonated most with into my own dancing.',)\n",
      "pred : tensor([1])\n",
      "text: ('The app Mizade, a play on the Portuguese word for friendship, will address this lack of access to at-home special needs assistants, along with the gap in resources to find potential sitters for special needs individuals.',)\n",
      "pred : tensor([1])\n",
      "text: ('Everyone belongs to many different communities and/or groups defined by (among other things) shared geography, religion, ethnicity, income, cuisine, interest, race, ideology, or intellectual heritage.',)\n",
      "pred : tensor([1])\n",
      "text: ('On Mizade, sitters create profiles specifying: the conditions and disorders they have experience working with, their certifications, their education, and any volunteer or related experiences.',)\n",
      "pred : tensor([1])\n",
      "text: ('On the weekends, these anxieties vanished.People-watching fanatics would get along great with the Brazilian Portuguese language, as it has many adjectives and nouns geared towards describing people.',)\n",
      "pred : tensor([1])\n",
      "text: ('With SMTD, I could study dance abroad at the Conservatoire de Paris, while also working towards my goal of learning all of the Romance languages.',)\n",
      "pred : tensor([1])\n",
      "text: ('Sitters charge their own price per hour, indicate how far they will travel, and set their availability.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Perhaps, hearing that person's voice sparks an eye roll of ran\\\\u00e7o.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Applying all of these learnings on stage through SMTD's many performance opportunities, be it on the iconic Power Center stage or with Ann Arbor Dance Works, will be extremely emotionally fulfilling.\",)\n",
      "pred : tensor([1])\n",
      "text: ('The fulfillment produced from working to please myself, without being consumed with perfecting the end result, inspires me to take risks and try out new experiences.',)\n",
      "pred : tensor([1])\n",
      "text: ('Ross School of Business.',)\n",
      "pred : tensor([0])\n",
      "text: ('Central to the success of the app is building credibility and having high engagement from qualified sitters and interested families.',)\n",
      "pred : tensor([1])\n",
      "text: ('Ran\\\\u00e7o is that inexplicable dislike towards someone without proper reason.',)\n",
      "pred : tensor([1])\n",
      "text: ('The chance to integrate both of my interests, business and dance, into an international environment is something I can only do through the opportunities at Michigan.',)\n",
      "pred : tensor([1])\n",
      "text: ('Please address with some specificity your own wishes and how they relate to UChicago.',)\n",
      "pred : tensor([1])\n",
      "text: ('Such experiences are the epitome of the small higher-math community at my school.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Perhaps, this time, we won't be drawn together by the findings of Newton and Leibniz, but instead by those of Plato and Homer in HUMA 12400.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"I'd plead my father not to bring up his love for Brazilian Jiu Jitsu in front of my friends.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Inspired by the pride this familial community showcases, I now enthusiastically share my culture and embrace my ethnicity around others.At the core of my dance practice is the idea of learning by doing, which is also a fundamental concept is at the Stephen M. During my junior year, my doctor informed me I needed to put dancing on hold for the sake of my health, as I had been diagnosed with growth hormone deficiency.',)\n",
      "pred : tensor([1])\n",
      "text: ('The mother expressed that easier access to such care inside of homes, not just at outside organizations, would be instrumental in allowing parents to take a break from the undivided attention many of these individuals require.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Another instance was volunteering as a contortionist at my school's haunted house.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Being a dancer at Valentina's School of Ballet and a student at Bloomfield Hills High School can merge into becoming a Wolverine.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Ross Business Portfolio: Choose a current event or issue in your community and discuss the business implications.'\",)\n",
      "pred : tensor([1])\n",
      "text: ('I was terrified to be cast as different in Carmel, Indiana, a town with a 2.',)\n",
      "pred : tensor([1])\n",
      "text: ('My family would meet up with the Brazilian immigrant community of Indiana, compromising of nearly every Brazilian in Metro Indianapolis.',)\n",
      "pred : tensor([1])\n",
      "text: ('This community celebrated Brazilian culture in the midst of being a minority.',)\n",
      "pred : tensor([1])\n",
      "text: ('\"}, {\"index\": 1, \"personal_essay\": \"End Facetime.',)\n",
      "pred : tensor([1])\n",
      "text: ('The review panel will look for creativity, drawing connections, and originality.',)\n",
      "pred : tensor([1])\n",
      "text: ('However, what most excites me about the Core is how UChicago students realize that obtaining a more profound understanding of the world itself is central to success in any field.',)\n",
      "pred : tensor([1])\n",
      "text: ('One-on-one lessons with my ballet teacher helped reveal how I would utilize my inspiration in conjunction with making sure the way I danced the piece was unique to myself.',)\n",
      "pred : tensor([1])\n",
      "text: (\"My gratitude for the art form skyrocketed as I'm simply appreciative to have a body healthy enough to perform such anatomically-defying positions.With my mother's cuisine already dissed, I feared my parents' English would be laughed at next.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"I had to awkwardly respond to my friends' reactions to having quit an activity so integral to my identity.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Or, that ran\\\\u00e7o all faded when the character you hated on Netflix at last bid their farewells and left the show.',)\n",
      "pred : tensor([1])\n",
      "text: ('To remain secure, communication, via messaging and voice calls, occurs solely through the app.',)\n",
      "pred : tensor([1])\n",
      "text: ('That day of AP US History, I performed a historical piece analyzing the life and legacy of Zumbi, an Afro-Brazilian hero of colonial Brazil.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I moved to a barre spot where I'm freed from the sight of a mirror, instead focused on translating such beautiful melodies into the character of a desperate, innocent swan.Though I still have days of 'blood, sweat, and tears,' these struggles motivate me to work harder, to cherish the pain of holding that leg up for one more second.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Portuguese is indeed the most similar language to Spanish.',)\n",
      "pred : tensor([0])\n",
      "text: ('I cannot even estimate the number of times I have been asked if Brazil speaks Spanish or Brazilian.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('watching the World Cup, giggling reading the comics Turma da Monica, or eating turkey with farofa on Thanksgiving, I felt content as my Latina self at each gathering.',)\n",
      "pred : tensor([1])\n",
      "text: ('Even engineering students will be compelled by the debate between Hobbes and Locke in SOSC 11400.',)\n",
      "pred : tensor([1])\n",
      "text: ('Yet, the strange stigma many of these engineering-bound students have towards learning humanities over STEM classes has puzzled me as a student loving to learn about topics ranging from Rasputin to differential equations.',)\n",
      "pred : tensor([1])\n",
      "text: ('Given the high cost associated with building brand loyalty and awareness, along with app development, the app is not expected to turn a profit in its first year of operation.',)\n",
      "pred : tensor([1])\n",
      "text: ('Mizade allows for meaningful personal relationships to form between special needs individuals and qualified, affordable sitters while helping parents destress in the place where they should feel most comfortable, home.',)\n",
      "pred : tensor([1])\n",
      "text: ('Not only will I engage with such programs enhancing my multicultural understandings, I will employ UChicago resources into finding my own place in the vibrant culture of Chicago.',)\n",
      "pred : tensor([1])\n",
      "text: ('Ross global practicum courses and internships will allow me to drive value for international businesses and enhance global competency.',)\n",
      "pred : tensor([1])\n",
      "text: ('Shocked, she pleaded me to try temporarily dancing once a week, but I refused.',)\n",
      "pred : tensor([1])\n",
      "text: ('I find his attention to detail to be both adorable and reciprocally motivating.',)\n",
      "pred : tensor([1])\n",
      "text: ('The projects and lessons in strategy electives like STRAT310 and STRAT445 will equip me with the skill-set I need to make an impact internationally.',)\n",
      "pred : tensor([1])\n",
      "text: ('was the highlight of my childhood day, being my Brazilian mother calling me down for dinner.',)\n",
      "pred : tensor([0])\n",
      "text: ('Families will be more likely to try an app suggested by these organizations already well-received in Oakland County.',)\n",
      "pred : tensor([1])\n",
      "text: ('Then, families and sitters find their matches through search filters.',)\n",
      "pred : tensor([1])\n",
      "text: ('{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"personal_essay\", \"type\": \"string\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.',)\n",
      "pred : tensor([1])\n",
      "text: ('These university students will be incentivized to join the app to gain experience for their profession while earning a side income.',)\n",
      "pred : tensor([1])\n",
      "text: (\"It provokes conversation about my perspective growing up speaking Portuguese in Indiana and my favorite Brazilian foods that are anything but 'yucky.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"But, I'll also dive into the unfamiliarity of Robin Wilson's Introduction to Afro-Caribbean Dance, where I'll come to a better sense of my own Brazilian identity through exploring Brazilian folkloric dances.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Growing up speaking Brazilian Portuguese, I always grow frustrated in English-speaking situations in wanting to describe somebody with that word too complex to translate into English, be it perua or sapeca.',)\n",
      "pred : tensor([1])\n",
      "text: ('Joining the Organization of Latin American Students lets me explore the intersection of my Brazilian identity with other Latinx cultures right on campus.',)\n",
      "pred : tensor([1])\n",
      "text: (\"The German word 'fremdsch\\\\u00e4men' encapsulates the feeling you get when you're embarrassed on behalf of someone else.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Yes, I'll feel comfortable in Bohuslava Jelinkova's ballet class, where her ballet-based background from the Czech Republic will remind me of the past decade spent with Eastern European ballet teachers.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Or what about that time I had to obtain a live elephant for the sole sake of a scavenger hunt?',)\n",
      "pred : tensor([1])\n",
      "text: ('I convinced myself keeping busy would let me forget about dance, so I tried a gym membership, new school clubs, volunteering more, and adding more challenging academic classes.',)\n",
      "pred : tensor([1])\n",
      "text: ('I felt empowered by creating a connection between my dance and academics for the first time, bringing two very separate worlds of my life together into one presentation.',)\n",
      "pred : tensor([1])\n",
      "text: ('I expressed to my ballet teacher that I was quitting ballet, my passion.',)\n",
      "pred : tensor([1])\n",
      "text: ('I will perceive movement in new interdisciplinary lights through courses like kinesiology and musicology.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I was peacefully munching on a typical Brazilian meal of rice, beans, and steak at lunch when a classmate glared down at me and exclaimed, 'That looks yucky!'\",)\n",
      "pred : tensor([1])\n",
      "text: (\"'Belinha, venha jantar!'\",)\n",
      "pred : tensor([0])\n",
      "text: (\"The stress of how I'd compare to others at that next performance, competition, or audition inhibited me from dancing for myself, having been so focused on perfecting what would be seen by the audience.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Yet, I still felt empty inside.',)\n",
      "pred : tensor([0])\n",
      "text: ('How would that curriculum support your interests?For the past year, I have been volunteering at Friendship Circle, a non-profit organization providing assistance to special needs individuals principally through a one-on-one buddy system.',)\n",
      "pred : tensor([1])\n",
      "text: ('His excitement for each number converted to a numeral inspires me to be curious, no matter how irrelevant the topic may seem.',)\n",
      "pred : tensor([1])\n",
      "text: ('I never expected the room I associate with Scantrons and textbooks to suddenly become a space for a dance performance.',)\n",
      "pred : tensor([1])\n",
      "text: ('However, through speaking with the mother of a girl I helped teach to ride a bike, I learned that although parents can find outlets for reliable care outside of the home through organizations like Friendship Circle, finding dependable, qualified people to come into their homes to help is challenging.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Students who perhaps would've never been friends suddenly found themselves growing close through the findings of Newton and Leibniz.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"In French, there is no difference between 'conscience' and 'consciousness.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Seven English words placed into one Brazilian Portuguese word.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Be it screaming 'GOALLLL!'\",)\n",
      "pred : tensor([0])\n",
      "text: ('I became consumed by the visuals in the mirror, eyes watering as I questioned if my relev\\\\u00e9 was high enough, knee straight enough, pli\\\\u00e9 deep enough.',)\n",
      "pred : tensor([1])\n",
      "text: ('All of these require explanation in order to properly communicate their meaning, and are, to varying degrees, untranslatable.',)\n",
      "pred : tensor([1])\n",
      "text: ('Ross Business Portfolio: Upload a document or artifact that represents something significant about your life to show your learning in action.',)\n",
      "pred : tensor([1])\n",
      "text: (\"We've grown up together from Algebra II freshman year to Calculus III senior year.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Payment also occurs through the app, as revenue will be generated through a percentage commission on the income of the sitters.Describe the unique qualities that attract you to the specific undergraduate College or School (including preferred admission and dual degree programs) to which you are applying at the University of Michigan.',)\n",
      "pred : tensor([1])\n",
      "text: ('Knowing I want to challenge my cultural awareness through living in many different countries post graduation, while pursuing a business career, treks are a perfect means of exposing myself to the business industries of different global cities, such as with the China trek to Shanghai and Beijing.',)\n",
      "pred : tensor([1])\n",
      "text: (\"If the school asked for parent volunteers, I'd beg my mother not to do it.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Once families and sitters encounter success on the app, a referral system will increase membership.',)\n",
      "pred : tensor([1])\n",
      "text: ('For the first time, my passions for dance and academics can be a part of the same institution.',)\n",
      "pred : tensor([1])\n",
      "text: ('As this style merging Indian culture, ballet, and contemporary was foreign to me, I found plentiful online inspiration to aid with employing my technique into displaying the focused, yearning emotion of trying to win over a snake.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('Not to be confused with the sweet sensations of chocolate fondue, this ballet exercise requires killer calf strength and mental stamina.',)\n",
      "pred : tensor([1])\n",
      "text: ('Such an experience includes celebrating Bathukamma with my Indian friend.',)\n",
      "pred : tensor([0])\n",
      "text: ('UChicago will further support my desire for this more profound understanding of the world through its many programs seamlessly combining my interests with my desire to become more culturally empathetic.',)\n",
      "pred : tensor([1])\n",
      "text: ('Or, at 1:19, I exaggerated the bend downwards because I wanted to better illuminate the transition into bending backwards.This solo, symbolizing an Indian snake charmer, was an exciting diversion away from the classical, Russian-based training I have received since six years old.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Whether it's helping special needs children ride bikes or teaching a young ballerina a new step, I couldn't imagine no longer working with children.Realizing this power of working for myself through overcoming the obstacles of my diagnosis has allowed me to redefine my perception of success as far beyond the external image.\",)\n",
      "pred : tensor([1])\n",
      "text: ('This 2 minute, 30 second piece also reveals the struggles I had in the hours of preparation.',)\n",
      "pred : tensor([1])\n",
      "text: ('Nothing could replace the satisfaction of hard work in the studio.',)\n",
      "pred : tensor([1])\n",
      "text: ('Such an understanding will carry me forward in any field.',)\n",
      "pred : tensor([1])\n",
      "text: ('Families similarly create their own profiles detailing the type of help they need, when they need it, and how much they will pay.',)\n",
      "pred : tensor([1])\n",
      "text: ('Even so, Spanish lacks such a word describing a feeling everybody can relate to.',)\n",
      "pred : tensor([1])\n",
      "text: ('Meanwhile, immersing myself in Parisian culture at the UChicago Center Abroad in Paris allows me to maintain such an enriching and collaborative education while pursuing my goal of learning all five main Romance Languages to near-native level fluency.',)\n",
      "pred : tensor([1])\n",
      "text: ('If you could only do one of the activities you have listed in the Activities section of your Common Application, which one would you keep doing?',)\n",
      "pred : tensor([1])\n",
      "text: (\"The most challenging part of the process wasn't the discomfort of giving myself a daily shot, but having to slow down in what I thrived in giving my all.\",)\n",
      "pred : tensor([1])\n",
      "text: ('To draw more qualified sitters, partnerships will be created with the special education departments of Oakland University, Baker College, and Wayne State University.',)\n",
      "pred : tensor([1])\n",
      "text: ('Eventually, I figured it was time to see if, even at this slower pace, reintroducing dance into my life would make me feel myself again.',)\n",
      "pred : tensor([1])\n",
      "text: ('Dante, a fireball of energy I regularly babysit, brings his all to each activity.',)\n",
      "pred : tensor([1])\n",
      "text: ('Yet, an English word should still be merited for the absence of a feeling.',)\n",
      "pred : tensor([1])\n",
      "text: ('When not engaging with the many dance organizations on campus, from Rhythmic Bodies in Motion to University Ballet, I will regularly watch the Joffrey Ballet, seizing upon the perks of UChicago discounts.',)\n",
      "pred : tensor([1])\n",
      "text: ('These organizations also have loyal volunteers that may be interested in generating an income on the app.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I am beyond excited for the interdisciplinary connections Michigan will expose me to in my passions for business and dance, coupled with the study abroad opportunities that will remind me of my dream of representing 'Go Blue!'\",)\n",
      "pred : tensor([1])\n",
      "text: ('In Japanese, there is a word that specifically refers to the splittable wooden chopsticks you get at restaurants.',)\n",
      "pred : tensor([1])\n",
      "text: ('Describe how your artifact demonstrates your learning in action.',)\n",
      "pred : tensor([0])\n",
      "text: ('The decision was beyond my control.',)\n",
      "pred : tensor([0])\n",
      "text: (\"At the School of Music, Theatre & Dance, I'll be more than another ballet bunhead; instead, I'll become a multi-faceted artist.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Returning to dance, although it took until senior year to be full-time again, made me treasure how precious the gifts of movement and artistic expression are.',)\n",
      "pred : tensor([1])\n",
      "text: ('I live for the reciprocal learning relationship provoked by their radiant energy.',)\n",
      "pred : tensor([1])\n",
      "text: ('How does the University of Chicago, as you know it now, satisfy your desire for a particular kind of learning, community, and future?',)\n",
      "pred : tensor([1])\n",
      "text: ('In the case that parents can find a qualified sitter, the niche labor supply brings them high costs.0\"}, \"data\": [{\"index\": 0, \"personal_essay\": \"Tchaikovsky filled the sweaty room of barres and mirrored walls as I plunged into battement fondu.',)\n",
      "pred : tensor([1])\n",
      "text: ('Carter, my favorite special needs child at Friendship Circle, is obsessed with Roman numerals.',)\n",
      "pred : tensor([0])\n",
      "text: (\"Even the popular 'So do you speak Spanish or Brazilian?\",)\n",
      "pred : tensor([0])\n",
      "text: ('Maybe, you pride yourself in rarely getting ran\\\\u00e7o.',)\n",
      "pred : tensor([1])\n",
      "text: ('Why?',)\n",
      "pred : tensor([0])\n",
      "text: (\"Hearing Odette's Act II Swan Lake variation no longer elicited pressure to have that perfect relev\\\\u00e9.\",)\n",
      "pred : tensor([1])\n",
      "text: ('While I may not have the stereotyped strong arms of a contortionist, I enjoyed exposing myself to a new art form with no pressure to be perfect.',)\n",
      "pred : tensor([1])\n",
      "text: (\"If I couldn't spend as many hours dancing in the pursuit of perfecting my craft, then I felt I didn't deserve to dance at all.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Stepping away from that reflection was invigorating.',)\n",
      "pred : tensor([0])\n",
      "text: ('Meeting the parents of my various buddies, I have viewed how grateful they are to have a safe space to send their children to.',)\n",
      "pred : tensor([1])\n",
      "text: ('For instance, at 1:16 and 1:51, my slight stumbles remind me of my difficulty in maintaining control coming out of positions, which I was working on improving for months.',)\n",
      "pred : tensor([1])\n",
      "text: ('For example, I chose at 2:04 to make a clear shift in my facial expression from seriousness to smiling so as to reflect the sudden change in tone of music.5% Latino population.',)\n",
      "pred : tensor([1])\n",
      "text: ('G\\\\u00edrias, which translates to slang, twist words once overlooked into all new, relevant meanings, especially enjoyed by younger generations.',)\n",
      "pred : tensor([1])\n",
      "text: (\"Prior to my break, I lost touch with the 'performing arts' definition of dance, overly concerning myself with the visual.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I intertwined speech with movement bringing a historical narrative to life.',)\n",
      "pred : tensor([1])\n",
      "text: (' The English adjective rancid, describing fatty foods that smell or taste unpleasant because of being old and stale, becomes rather useful once converted into its slang Brazilian Portuguese counterpart, ran\\\\u00e7o.',)\n",
      "pred : tensor([1])\n",
      "text: ('I decided creating this level change with my body would better convey the passionate yearning of enchanting a snake.',)\n",
      "pred : tensor([1])\n",
      "text: ('Sure, describing the french fries you were so excited to eat a few hours ago as rancid may be accurate, but I think everybody has ran into a situation where they get, or pega, ran\\\\u00e7o.',)\n",
      "pred : tensor([1])\n",
      "text: ('The eagerness of these students to stay up for hours on Facetime just to help out with that one problem makes me smile',)\n",
      "pred : tensor([0])\n",
      "text: ('Furthermore, I look forward to applying lessons learned in the classroom by taking on executive roles in on-campus clubs including the Emerging Markets Club and both business and artistic leadership roles in on-campus dance clubs, like Outrage Dance Group.',)\n",
      "pred : tensor([1])\n",
      "text: ('Total time: 2 hours and 7 minutes.',)\n",
      "pred : tensor([1])\n",
      "text: ('I outwardly giggled, but her silly words have carried with me.',)\n",
      "pred : tensor([1])\n",
      "text: ('At the University of Michigan, I am excited for the opportunity to continue to sense the power of creating interdisciplinary connections between the arts, social sciences, and business as I work towards a dual-degree in business and dance.',)\n",
      "pred : tensor([1])\n",
      "text: ('Choose one of the communities to which you belong, and describe that community and your place within it.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: ('Rancio in Spanish is confined to the fatty food definition.',)\n",
      "pred : tensor([1])\n",
      "text: (\"At the University of Chicago, I look forward to having many more tight-knit academic communities with the Core's discussion-based seminars capped at 19 students.\",)\n",
      "pred : tensor([1])\n",
      "text: ('Those weeks of not dancing felt uncomfortable and disorienting.',)\n",
      "pred : tensor([0])\n",
      "text: ('Bringing back dance surprisingly made me feel more connected to myself.',)\n",
      "pred : tensor([0])\n",
      "text: ('Propose a solution that incorporates business principles or practices.',)\n",
      "pred : tensor([1])\n",
      "text: ('Focusing on the feelings, not appearances, of movement was meditative, making me feel more present and alive.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I drew inspiration from ballet stars Zakharova, Obraztsova, and Vishneva in their interpretation of Nikiya's death, a solo similar in style to mine.If 'small minds discuss people', as Eleanor Roosevelt claimed, the English language sure isn't supporting those 'small-minded' thoughts we all, like it or not, do have.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I enjoyed the discomfort of being the only Latina in the Hindu celebration as I allowed myself to become engrossed in a vastly different culture.',)\n",
      "pred : tensor([1])\n",
      "text: ('As the app will begin in the special needs community of Oakland County, partnerships will be created with organizations prominent in this community like Wing Lake Developmental Center, FAR, The Detroit Institute for Children, and Friendship Circle.',)\n",
      "pred : tensor([1])\n",
      "text: ('in many countries post graduation.',)\n",
      "pred : tensor([0])\n",
      "text: (\"', sounding ignorant to some, has become my favorite question.\",)\n",
      "pred : tensor([0])\n",
      "text: ('When I challenge him to eat ten green beans, he will count fifty onto his plate.',)\n",
      "pred : tensor([1])\n",
      "text: ('The Core will inspire new friendships with students of diverse interests and backgrounds I may have never met had I been confined to my economics major courses.',)\n",
      "pred : tensor([1])\n",
      "text: ('My family still regularly visits Indiana since moving to Michigan in 2011.',)\n",
      "pred : tensor([0])\n",
      "text: (\"Those tears didn't actually fall until weeks later, with no Tchaikovsky's Swan Lake to accompany the frustrations this time.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Yet, maybe what I am actually most excited about in attending UChicago is being able to see my parents' surprise in informing them I now wake up at 5 am daily for Zumba just for Kuviasungnerk/Kangeiko.\",)\n",
      "pred : tensor([1])\n",
      "===============================================================\n",
      "Character Descriptiveness :  14.0\n",
      "===============================================================\n",
      "['they', 'it', 'person', 'in', 'myself', 'me', 'he', 'parent', 'her', 'their', 'him', 'your', 'father', 'buddy', 'you', 'mine', 'parents', 'them', 'counterpart', 'mother', 'someone', 'my', 'one', 'i']\n",
      "=============================================\n",
      "Number of Characters : 468\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'my', 'one', 'i', 'mine']\n",
      "=============================================\n",
      "Emphasis on You : 198\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:310: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:387: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      " 15%|█▌        | 4/26 [14:17<1:20:19, 219.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'it', 'person', 'in', 'myself', 'he', 'parent', 'her', 'their', 'him', 'your', 'father', 'buddy', 'you', 'parents', 'them', 'counterpart', 'mother', 'someone']\n",
      "=============================================\n",
      "Emphasis on Others : 177\n",
      "=============================================\n",
      "model loadling~\n",
      "pred_loader: <torch.utils.data.dataloader.DataLoader object at 0x0000023841B5EBC8>\n",
      "check!\n",
      "text: ('Doing work at 4:00 am is how I express my creative side.',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred : tensor([1])\n",
      "text: (\"I could now create substitutes for expensive, falsely advertised, 'all natural, free of parabens' products.\",)\n",
      "pred : tensor([1])\n",
      "text: ('As the notifications and reactions pour in, I am reminded of why I paint.',)\n",
      "pred : tensor([1])\n",
      "text: ('Should I do a song, film, script, poem, story, drama, music video, magazine cover or photo collage?',)\n",
      "pred : tensor([1])\n",
      "text: ('Squeezing out a tube of black paint, I use harsh brush strokes to reveal a girl about to get drugged at a fraternity party.',)\n",
      "pred : tensor([1])\n",
      "text: ('\"}, {\"index\": 1, \"personal_essay\": \"My interest in chemistry was sparked by my eczema.',)\n",
      "pred : tensor([1])\n",
      "text: ('An in-between that makes productivity seem so inviting.',)\n",
      "pred : tensor([0])\n",
      "text: (\"As I experimented with different products, I found that milky substances were moisturizing, eczema creams with '-H' after the name treated my itching overnight, and acne creams with a percentage on the front of the box made my face burn.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"Most of the time, 4:00 am is the perfect hour to create a painting.When I took chemistry, I learned that my 'potions' worked because of intermolecular forces, coulombic attraction, and atomic trends on the periodic table.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I create equations for my drawings, coming up with images setting the mood.',)\n",
      "pred : tensor([1])\n",
      "text: ('This begins the pink lemonade period: a time where exams, exhibitions, performances, and due dates seem far away.',)\n",
      "pred : tensor([1])\n",
      "text: ('When I needed to paint a pair of white leather boots for an art project, I knew that acrylic paint would not grip the smooth surface of the leather.0\"}, \"data\": [{\"index\": 0, \"personal_essay\": \"Should I do a song, film, script, poem, story, drama, music video, magazine cover, or photo collage?',)\n",
      "pred : tensor([1])\n",
      "text: ('It feels like the world has paused.',)\n",
      "pred : tensor([0])\n",
      "text: ('I used these observations to create my own skincare such as the strawberry facial I used during the dry summer.',)\n",
      "pred : tensor([1])\n",
      "text: ('The practice of expressing my opinions through art clarifies who I am and what I stand for.Think about an academic subject that inspires you.',)\n",
      "pred : tensor([1])\n",
      "text: ('Tapping my pen against the screen, I create a stipple drawing of a boy against a crimson red silhouette of Sudan.',)\n",
      "pred : tensor([1])\n",
      "text: ('Without other tasks occupying my mind, I have a clearer sense of composition.',)\n",
      "pred : tensor([1])\n",
      "text: ('{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"personal_essay\", \"type\": \"string\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.The Third StepWhen the sun comes out, I post my piece online to inspire allies in righting the wrongs depicted in my art.',)\n",
      "pred : tensor([1])\n",
      "text: ('Do I want people to feel it?',)\n",
      "pred : tensor([0])\n",
      "text: ('Most of the time, 4am births a painting.',)\n",
      "pred : tensor([1])\n",
      "text: (\"I also learned that the percentages on acne cream bottles are descriptions of peroxide levels, and that the '-H' meant there was an active hormone called cortisol that heals in hours.\",)\n",
      "pred : tensor([1])\n",
      "text: (\"At 4am, I am Georgia O'Keeffe; I am Frida Kahlo.\",)\n",
      "pred : tensor([1])\n",
      "text: ('It inspires me to penetrate past the surface on a molecular level.',)\n",
      "pred : tensor([1])\n",
      "text: ('It shows me how to make smarter choices regarding what I put in my body, on my skin, and even the materials I use for art projects.',)\n",
      "pred : tensor([1])\n",
      "text: ('When I work at 4am, I feel hopeful, optimistic, and sure of my ability to communicate what I feel.',)\n",
      "pred : tensor([1])\n",
      "text: ('I am thankful for my circadian rhythms that cause me to wake up at this hour.',)\n",
      "pred : tensor([1])\n",
      "text: ('Every choice I make feels more purposeful.',)\n",
      "pred : tensor([0])\n",
      "text: ('How intensely am I feeling it and how much do I want to convey?',)\n",
      "pred : tensor([0])\n",
      "text: ('The Third StepWhen the sun comes out, I post my piece online in hopes of inspiring allies to right the wrongs depicted in my art.',)\n",
      "pred : tensor([1])\n",
      "text: ('Instead of trying to scrape the glossy finish off the shoes, I decided to spray them with a product containing a pH between three and six because an acidic substance would burn the surface of the leather, making it rough enough for the paint to grip.',)\n",
      "pred : tensor([1])\n",
      "text: ('I slip out of bed and turn on my red lamp, allowing the pink hue to stretch over my room.',)\n",
      "pred : tensor([1])\n",
      "text: ('I am Banksy, painting in the middle of the night, making a statement without having to say anything at all.',)\n",
      "pred : tensor([1])\n",
      "text: ('Positive or negative, the responses remind me that I create to give my audience a magnifying glass to see crises for what they are and empower them to take action.',)\n",
      "pred : tensor([1])\n",
      "text: ('I learned that the strawberry facial I made was actually an enzyme facial that worked because of ellagic acid containing the compound polyphenol, a source of antioxidants.Chemistry empowers me to excel as a creative tinkerer.',)\n",
      "pred : tensor([1])\n",
      "text: ('The observational process has become a part of my daily routine; Chemistry continues to inspire me to gain a deeper understanding of the world around me.',)\n",
      "pred : tensor([1])\n",
      "text: ('The First StepWith a spoon full of peanut butter, I enter the pink lemonade portal and acknowledge my mood.',)\n",
      "pred : tensor([1])\n",
      "text: ('This hour is when I truly feel like myself.',)\n",
      "pred : tensor([0])\n",
      "text: ('I gravitate towards experimental color combinations and my hands draw with a thicker line weight.',)\n",
      "pred : tensor([1])\n",
      "text: ('As notifications and reactions pour in, they reaffirm why I paint.',)\n",
      "pred : tensor([1])\n",
      "text: ('I am looking into a rainbow abyss; seeing the great potential in the next three hours excites me.Chemistry has given me the superpower to look beyond the label.',)\n",
      "pred : tensor([1])\n",
      "text: ('Make them feel the opposite?',)\n",
      "pred : tensor([0])\n",
      "text: ('For example, if I am: Relaxed + untroubled = A smiling tortoise walking into the sunsetFeeling hungry + sluggish = baked beans slowly seeping out of a pair of Crocs Uncomfortable + homesick = spilled milk Stressed + unsatisfied = the crowded composition of competing articles on the front page of a newspaper  The Second StepAfter deciding what to paint, I begin.',)\n",
      "pred : tensor([1])\n",
      "text: ('Positive or negative, the reactions remind me that I create to give my audience a magnifying glass to see crises for what they are and empower them to do something about them.The First StepWith a spoon full of peanut butter, I create equations for my drawings, coming up with images that reflect my mood.',)\n",
      "pred : tensor([1])\n",
      "text: ('The conversation that was solely between my paintbrush and me is now open to interpretation.',)\n",
      "pred : tensor([1])\n",
      "text: ('For example:Relaxed + untroubled = A smiling tortoise walking into the sunsetFeeling hungry + sluggish = baked beans slowly seeping out of a pair of CrocsUncomfortable + homesick = spilled milkThe Second StepAfter deciding what to paint, I begin.',)\n",
      "pred : tensor([1])\n",
      "text: ('At 4:00 am, I gravitate towards experimental color combinations and draw with heavier line weight.',)\n",
      "pred : tensor([1])\n",
      "text: (\"The birds aren't even chirping yet and all I hear is my breathing and the hum of the air conditioning unit.\",)\n",
      "pred : tensor([1])\n",
      "text: ('At 4am, I pay closer attention to detail.',)\n",
      "pred : tensor([1])\n",
      "text: ('Describe how you have furthered this interest inside and/or outside of the classroom.',)\n",
      "pred : tensor([1])\n",
      "text: ('Going through this consistent, disciplined thought process every morning allows me to twist and wring the creative juices out of my brain and gives me the space to create art that reflects who I am',)\n",
      "pred : tensor([1])\n",
      "text: ('Unraveling old wires with pliers to place into burning candle wax, I create a statement piece about air quality in Pakistan.',)\n",
      "pred : tensor([1])\n",
      "text: (\"While I create art to shed light on issues I'm passionate about, this three-step creative process also results in a greater sense of self-understanding for me.\",)\n",
      "pred : tensor([1])\n",
      "text: ('I am an activist addressing the wrongs of the world.',)\n",
      "pred : tensor([0])\n",
      "===============================================================\n",
      "Character Descriptiveness :  85.0\n",
      "===============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'me', 'them', 'it', 'my', 'in', 'you', 'i', 'myself']\n",
      "=============================================\n",
      "Number of Characters : 211\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'my', 'me']\n",
      "=============================================\n",
      "Emphasis on You : 114\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:310: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      "C:\\Users\\cacki\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\ipykernel_launcher.py:387: DeprecationWarning: Call to deprecated `most_similar_cosmul` (Method will be removed in 4.0.0, use self.wv.most_similar_cosmul() instead).\n",
      " 19%|█▉        | 5/26 [16:11<1:08:01, 194.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'them', 'it', 'in', 'you', 'myself']\n",
      "=============================================\n",
      "Emphasis on Others : 32\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3e615722b415>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mps_input_each_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# JSON파일로 로드한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps_input_each_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mre_each_ess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcharacter_all_section\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0messay_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre_each_ess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-adfaef7b9853>\u001b[0m in \u001b[0;36mcharacter_all_section\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mcharacter_descriptiveness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcharacter_descrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"===============================================================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Character Descriptiveness : '\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcharacter_descriptiveness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-adfaef7b9853>\u001b[0m in \u001b[0;36mcharacter_descrip\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mst_re\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshowtell_classfy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sent_chr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 캐릭터거 포함된 문장(전처리 완료된) 입력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst_re\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-adfaef7b9853>\u001b[0m in \u001b[0;36mshowtell_classfy\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mST_test_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m#로딩되는지 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mST_test_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m#time.sleep(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-adfaef7b9853>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    871\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1444\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many indexers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1350\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m             \u001b[1;31m# a tuple should already have been caught by this point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37pytorch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "essay_results = []\n",
    "\n",
    "for file_name_raw in tqdm(file_list): # 파일이름을 하나씩 불러와서\n",
    "    file_name = path  + file_name_raw #경로를 추가하고\n",
    "    with open(file_name, 'r') as json_file : #JSON파일로 파일을 열어서\n",
    "        ps_input_each_data = json.load(json_file) # JSON파일로 로드한다.\n",
    "        input_data = json.dumps(ps_input_each_data)\n",
    "        re_each_ess = character_all_section(input_data)\n",
    "        essay_results.append(re_each_ess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88.0, 388, 185, 101),\n",
       " (84.0, 258, 122, 73),\n",
       " (91.0, 282, 125, 85),\n",
       " (14.0, 468, 198, 177),\n",
       " (85.0, 211, 114, 32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_desc</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>emph_you</th>\n",
       "      <th>emph_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>388</td>\n",
       "      <td>185</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.0</td>\n",
       "      <td>258</td>\n",
       "      <td>122</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>282</td>\n",
       "      <td>125</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>468</td>\n",
       "      <td>198</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.0</td>\n",
       "      <td>211</td>\n",
       "      <td>114</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_desc  num_chars  emph_you  emph_others\n",
       "0       88.0        388       185          101\n",
       "1       84.0        258       122           73\n",
       "2       91.0        282       125           85\n",
       "3       14.0        468       198          177\n",
       "4       85.0        211       114           32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r = pd.DataFrame(essay_results, columns =['char_desc', 'num_chars', 'emph_you', 'emph_others'])  #e데이터프레임에 넣기\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1000명 데이터의 각 값의 평균 계산\n",
    "char_desc_mean = df_r['char_desc'].mean()\n",
    "char_desc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chars_mean = df_r['num_chars'].mean()\n",
    "num_chars_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emph_you_mean = df_r['emph_you'].mean()\n",
    "emph_you_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emph_others_mean = df_r['emph_others'].mean()\n",
    "emph_others_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.4, 321.4, 148.8, 93.6]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30명의 최종 평균값 계산\n",
    "char_re_30 = [char_desc_mean, num_chars_mean, emph_you_mean, emph_others_mean]\n",
    "char_re_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
